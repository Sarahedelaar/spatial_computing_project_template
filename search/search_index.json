{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Spatial Computing Project 8bit hub This is the website for the final project of the minor Spatial Computing in Architectural Design at TU Delft, as given at the faculty of Architecture and the Built environment. We are a group of four students following the course BK7083: Computational Design Studio. On this site we show the proces and products of all the steps in our project towards making a final building. The progress is split up into four parts: Planning, Configuring, Massing and Forming. There is also a Final Deliveries given where there is a more in depth view of the code and other important info. Living conditions Design Challenge The objective is to design a housing complex incorporating several communal/public facilities for a cooperative live-work-play association. The housing complex is to accommodate students, young graduates (starters), and elderly. The complex also provides communal/public facilities, almost as a collective. Location Rotterdam, the block between Vijverhofstraat, Zomerhofstraat, Schoterbosstraat, and Teilingerstraat (see Figure 1). The location is split into compulsory and optional development. The part that has to be changed is the big multi-functional building. However, the old railway line, football park, restaurant and green park in the light green areas can be incorporated as well. If the optional parts are included, any streets or pathways crossing this region should be integrated into the design, without losing their original function. Location Program of requirements The program of requirements lists the spaces below: Housing: Student Housing 80 units Assisted Living 30 units Starter Housing 100 units Communal Spaces: Underground Parking (minimum of 0.5 parking lots per apartment) Vegetation (minimum 30% of the plot) Workshops/Fab-Labs/Co-working Space and Start-up Offices Library + Cinematheque + Caf\u00e9/Pub + [pinball] Arcade Co-cooking/Restaurant Community Centre Shop (grocery, tools and crafts) [electricity producing/odourless /geek-friendly] Gym Design Goals (quantitative & qualitative): Maximum Multi-scale Modularity (Qualitative) Excellent Ergonomics (Qualitative) Keeping at least the same amount of housing units as before (Quantitative) Not blocking direct light for neighbour buildings (Quantitative) Max solar gain potential (optional, Quantitative) Max greenery (Quantitative) Min noise (Quantitative) Social integration (Qualitative) Rational spectra of privacy and community (Qualitative)","title":"Home"},{"location":"#spatial-computing-project-8bit-hub","text":"This is the website for the final project of the minor Spatial Computing in Architectural Design at TU Delft, as given at the faculty of Architecture and the Built environment. We are a group of four students following the course BK7083: Computational Design Studio. On this site we show the proces and products of all the steps in our project towards making a final building. The progress is split up into four parts: Planning, Configuring, Massing and Forming. There is also a Final Deliveries given where there is a more in depth view of the code and other important info. Living conditions","title":"Spatial Computing Project  8bit hub"},{"location":"#design-challenge","text":"The objective is to design a housing complex incorporating several communal/public facilities for a cooperative live-work-play association. The housing complex is to accommodate students, young graduates (starters), and elderly. The complex also provides communal/public facilities, almost as a collective.","title":"Design Challenge"},{"location":"#location","text":"Rotterdam, the block between Vijverhofstraat, Zomerhofstraat, Schoterbosstraat, and Teilingerstraat (see Figure 1). The location is split into compulsory and optional development. The part that has to be changed is the big multi-functional building. However, the old railway line, football park, restaurant and green park in the light green areas can be incorporated as well. If the optional parts are included, any streets or pathways crossing this region should be integrated into the design, without losing their original function. Location","title":"Location"},{"location":"#program-of-requirements","text":"The program of requirements lists the spaces below: Housing: Student Housing 80 units Assisted Living 30 units Starter Housing 100 units Communal Spaces: Underground Parking (minimum of 0.5 parking lots per apartment) Vegetation (minimum 30% of the plot) Workshops/Fab-Labs/Co-working Space and Start-up Offices Library + Cinematheque + Caf\u00e9/Pub + [pinball] Arcade Co-cooking/Restaurant Community Centre Shop (grocery, tools and crafts) [electricity producing/odourless /geek-friendly] Gym Design Goals (quantitative & qualitative): Maximum Multi-scale Modularity (Qualitative) Excellent Ergonomics (Qualitative) Keeping at least the same amount of housing units as before (Quantitative) Not blocking direct light for neighbour buildings (Quantitative) Max solar gain potential (optional, Quantitative) Max greenery (Quantitative) Min noise (Quantitative) Social integration (Qualitative) Rational spectra of privacy and community (Qualitative)","title":"Program of requirements"},{"location":"a1_planning/","text":"Planning Here you should include the process and product of your 1st activity: Planning Title Planning (process): Programme of Requirements & Network (product) Objective Formulate the design problems, form a programme of requirements, form a network, formulate your design principles and the idea (spatial sequences/experience/stories visible in a network). Procedure Describe the hierarchy of design decisions, formulate design goals, define design principles, identify stages in the design process that could be supported by algorithms, draw a flowchart to reflect on these steps and their connections and update it every week. Develop a programme of requirements, an idea (encapsulating the added value of the building and what is going to be unique about it in terms of human experiences) and a corresponding network indicating the main trips inside the building to be facilitated by direct connections matching with the scenarios envisaged in the idea. Formulate the design principles indicating what is a good shape for the building given operational, climatic, or structural aspects.","title":"Planning"},{"location":"a1_planning/#planning","text":"Here you should include the process and product of your 1st activity: Planning Title Planning (process): Programme of Requirements & Network (product) Objective Formulate the design problems, form a programme of requirements, form a network, formulate your design principles and the idea (spatial sequences/experience/stories visible in a network). Procedure Describe the hierarchy of design decisions, formulate design goals, define design principles, identify stages in the design process that could be supported by algorithms, draw a flowchart to reflect on these steps and their connections and update it every week. Develop a programme of requirements, an idea (encapsulating the added value of the building and what is going to be unique about it in terms of human experiences) and a corresponding network indicating the main trips inside the building to be facilitated by direct connections matching with the scenarios envisaged in the idea. Formulate the design principles indicating what is a good shape for the building given operational, climatic, or structural aspects.","title":"Planning"},{"location":"a2_configuring/","text":"Configuring Here you should include the process and product of your 2nd activity: Configuring Title Configuring (process): Circulation Manifold (product) Objective Formulate a spatial (topological) concept, design a modular circulation manifold on a pixel/voxel grid. Procedure Construct a voxelated model of the site with a maximum height of 100 meters. Orient the voxel grid to a global coordinate system (e.g. geographical North-East-West-South). Size the voxels carefully based on the modular height of steps and the length of stair flights and ramps so that they fit in X/Y directions into multiple pixels. Choose the Z size of voxels according to step risers and choose the same size for X and Y as a whole multiple of step threads. There are three types of spaces in terms of pedestrian movement in buildings, metaphorically speaking, spaces to walk through (e.g. corridors, ramps, and stairs), spaces to stand on (e.g. platforms connecting doors to corridors and stairs) and spaces to sit on (functional rooms/spaces). Construct a simplified mesh model of all bridges (corridors, ramps, stairs) connected by standing platforms in a modular grid of voxels/pixels. Take into account the free-height necessary for all spaces and pack them into the bounding volume of the building. For every functional space, leave a single pixel as a standing platform and colour it with the corresponding colour.","title":"Configuring"},{"location":"a2_configuring/#configuring","text":"Here you should include the process and product of your 2nd activity: Configuring Title Configuring (process): Circulation Manifold (product) Objective Formulate a spatial (topological) concept, design a modular circulation manifold on a pixel/voxel grid. Procedure Construct a voxelated model of the site with a maximum height of 100 meters. Orient the voxel grid to a global coordinate system (e.g. geographical North-East-West-South). Size the voxels carefully based on the modular height of steps and the length of stair flights and ramps so that they fit in X/Y directions into multiple pixels. Choose the Z size of voxels according to step risers and choose the same size for X and Y as a whole multiple of step threads. There are three types of spaces in terms of pedestrian movement in buildings, metaphorically speaking, spaces to walk through (e.g. corridors, ramps, and stairs), spaces to stand on (e.g. platforms connecting doors to corridors and stairs) and spaces to sit on (functional rooms/spaces). Construct a simplified mesh model of all bridges (corridors, ramps, stairs) connected by standing platforms in a modular grid of voxels/pixels. Take into account the free-height necessary for all spaces and pack them into the bounding volume of the building. For every functional space, leave a single pixel as a standing platform and colour it with the corresponding colour.","title":"Configuring"},{"location":"a3_massing/","text":"Massing Here you should include the process and product of your 3rd activity: Massing Title Massing (process): Composition (product) Objective Logically place the functional spaces in between bridges within the building envelope. Procedure Compute a Solar Envelope, i.e. an envelope of cuboids/voxels, some of which are removed because they are in the way of the neighbouring buildings receiving some standard/minimum level of direct sunlight. Fit the circulation manifold into the solar envelope. From the standing platforms corresponding to functional spaces, grow them into voxel clouds within your voxelated envelope. Colour the voxel clouds according to their functionalities.","title":"Massing"},{"location":"a3_massing/#massing","text":"Here you should include the process and product of your 3rd activity: Massing Title Massing (process): Composition (product) Objective Logically place the functional spaces in between bridges within the building envelope. Procedure Compute a Solar Envelope, i.e. an envelope of cuboids/voxels, some of which are removed because they are in the way of the neighbouring buildings receiving some standard/minimum level of direct sunlight. Fit the circulation manifold into the solar envelope. From the standing platforms corresponding to functional spaces, grow them into voxel clouds within your voxelated envelope. Colour the voxel clouds according to their functionalities.","title":"Massing"},{"location":"a4_forming/","text":"Forming Here you should include the process and product of your 4th activity: Forming Title Forming (process): Form (product) Objective Document the process and products and provide explanations to ensure reusability of materials. Procedure Finalize the plans and the forms of all functional units. Optionally, choose a way to alter the jaggedness of voxels in the final form by partially bringing in contrasting curvy shapes, for instance as a shell around the building, e.g. through smoothing, relaxation, iso-surfaces, or topological transformation.","title":"Forming"},{"location":"a4_forming/#forming","text":"Here you should include the process and product of your 4th activity: Forming Title Forming (process): Form (product) Objective Document the process and products and provide explanations to ensure reusability of materials. Procedure Finalize the plans and the forms of all functional units. Optionally, choose a way to alter the jaggedness of voxels in the final form by partially bringing in contrasting curvy shapes, for instance as a shell around the building, e.g. through smoothing, relaxation, iso-surfaces, or topological transformation.","title":"Forming"},{"location":"a5_finaldelivery/","text":"Final Deliveries","title":"Final Deliveries"},{"location":"a5_finaldelivery/#final-deliveries","text":"","title":"Final Deliveries"},{"location":"about/","text":"About Name Studentnumber Role Joris Ghobrial 4957938 Diagrammer Youri Stoeller 5107490 Journalist Glenn Bommel\u00e9 4993993 Puzzle solver Sarah Edelaar 5038405 Puzzle solver Responsible instructor: Ir. P. Nourian (TU Delft, Design Informatics- PZN) Instructors: Ir. Shervin Azadi (TU Delft, Design Informatics - SAZ)","title":"About"},{"location":"about/#about","text":"Name Studentnumber Role Joris Ghobrial 4957938 Diagrammer Youri Stoeller 5107490 Journalist Glenn Bommel\u00e9 4993993 Puzzle solver Sarah Edelaar 5038405 Puzzle solver Responsible instructor: Ir. P. Nourian (TU Delft, Design Informatics- PZN) Instructors: Ir. Shervin Azadi (TU Delft, Design Informatics - SAZ)","title":"About"},{"location":"Configuring/a2_configuring_process/","text":"Configuring: process Voxelized envelope low res Shown beneath is the low resolution voxelized envelope. It visualizes each independent voxel in the envelope. (Fig. 1) Fig. 1 Voxelized envelope lowres Voxelized envelope high res Shown here is the high resolution voxelized envelope. (Fig. 2) Fig. 2 Voxelized envelope highres Voxel size The final voxel is 3.6*3.6*3.24 (w*d*h) meters. With the minivoxel being 0.9*0.9*0.54 (w*d*h) meters to represent a flight of three stairs. (Fig. 3) The standing platforms between the stairs are 0.90 meters in depth, ideally this would be 1.20 meters so that two people can pass at the same time. Fig. 3 Voxelsize Main entrance In this analysis our objective was to calculate the distance from every voxel to the main entrance. The main entrance was initialized by us prior to the analysis. For creating a distance field based on walking through the building, we first created two different neigbourhood stencils to work with. The first stencil shows that going one voxel sideways (in x- or y-direction) the value of the neighbours will increment with 1. However, when someone wants to go a level up or down, this costs more energy than walking on the same level. Therefore, the neighbours in the z-direction will increment with the value of 2. Distance to Ground Distance to Ground Distance to ground This analysis works in a similar way as the previous one. This time every voxel calculates the distance between itself and the ground floor. Distance to Ground Noise Noise is estimated by looking at the busiest roads surrounding the building site. Noise pollution gets reduced once you get further away from the sound source. So this analysis is also calculated by means of the distance between a certain point and a voxel. Noise Sun access For this analysis we had to take the annual path of the sun. From the points of this path the sun shoots rays of light that hit the voxels. The more hits, the higher the sun accessibility. Sun accessibility Shadow casting Shadow casting extends the previous analysis, by inverting the hits with the sun. The inverted hits are the shadows that cast a shadow over surrounded buildings. Shadow casting Sky view factor In the sky view analysis we calculated the amount of a sky a voxel can see without being blocked by surrounded structures. Sky view factor View on greenery This analysis was acquired by looking into the database of tree points made by the city council of Rotterdam. These points were clustered and they shot rays at the voxels. The more hits, means the higher the value for view on greenery. View on greenery","title":"Process"},{"location":"Configuring/a2_configuring_process/#configuring-process","text":"","title":"Configuring: process"},{"location":"Configuring/a2_configuring_process/#voxelized-envelope-low-res","text":"Shown beneath is the low resolution voxelized envelope. It visualizes each independent voxel in the envelope. (Fig. 1) Fig. 1 Voxelized envelope lowres","title":"Voxelized envelope low res"},{"location":"Configuring/a2_configuring_process/#voxelized-envelope-high-res","text":"Shown here is the high resolution voxelized envelope. (Fig. 2) Fig. 2 Voxelized envelope highres","title":"Voxelized envelope high res"},{"location":"Configuring/a2_configuring_process/#voxel-size","text":"The final voxel is 3.6*3.6*3.24 (w*d*h) meters. With the minivoxel being 0.9*0.9*0.54 (w*d*h) meters to represent a flight of three stairs. (Fig. 3) The standing platforms between the stairs are 0.90 meters in depth, ideally this would be 1.20 meters so that two people can pass at the same time. Fig. 3 Voxelsize","title":"Voxel size"},{"location":"Configuring/a2_configuring_process/#main-entrance","text":"In this analysis our objective was to calculate the distance from every voxel to the main entrance. The main entrance was initialized by us prior to the analysis. For creating a distance field based on walking through the building, we first created two different neigbourhood stencils to work with. The first stencil shows that going one voxel sideways (in x- or y-direction) the value of the neighbours will increment with 1. However, when someone wants to go a level up or down, this costs more energy than walking on the same level. Therefore, the neighbours in the z-direction will increment with the value of 2. Distance to Ground Distance to Ground","title":"Main entrance"},{"location":"Configuring/a2_configuring_process/#distance-to-ground","text":"This analysis works in a similar way as the previous one. This time every voxel calculates the distance between itself and the ground floor. Distance to Ground","title":"Distance to ground"},{"location":"Configuring/a2_configuring_process/#noise","text":"Noise is estimated by looking at the busiest roads surrounding the building site. Noise pollution gets reduced once you get further away from the sound source. So this analysis is also calculated by means of the distance between a certain point and a voxel. Noise","title":"Noise"},{"location":"Configuring/a2_configuring_process/#sun-access","text":"For this analysis we had to take the annual path of the sun. From the points of this path the sun shoots rays of light that hit the voxels. The more hits, the higher the sun accessibility. Sun accessibility","title":"Sun access"},{"location":"Configuring/a2_configuring_process/#shadow-casting","text":"Shadow casting extends the previous analysis, by inverting the hits with the sun. The inverted hits are the shadows that cast a shadow over surrounded buildings. Shadow casting","title":"Shadow casting"},{"location":"Configuring/a2_configuring_process/#sky-view-factor","text":"In the sky view analysis we calculated the amount of a sky a voxel can see without being blocked by surrounded structures. Sky view factor","title":"Sky view factor"},{"location":"Configuring/a2_configuring_process/#view-on-greenery","text":"This analysis was acquired by looking into the database of tree points made by the city council of Rotterdam. These points were clustered and they shot rays at the voxels. The more hits, means the higher the value for view on greenery. View on greenery","title":"View on greenery"},{"location":"Configuring/a2_configuring_product/","text":"Configuring: product Distance to main entrance PSEUDO CODE NAKIJKEN Flowchart Distance to Main Entrance Pseudo code 0. Distance to main entrance field Distance_to_main_entrance_field.py Input : voxelized_envelope . csv ( low and high res ), points of main street and public transport 1. Import Meshes 2. Import Lattice 3. Compute from each voxel the average distance to the main street and public transport Choose the voxel with the minimum distance as the main entrance Retrieve the neighbour voxels of the main entrance Set the value of the horizontal neighbours to 1 and the vertical neighbours to 2 For each neighbour : Find the neighbours and add 1 ( horizontal ) or 2 ( vertical ) to it \u2019 s value , when it does not have a value yet Convert the values into values between 0 and 1 4. Construct the field Output : Distance to main entrance field ( low and high res ) Distance to the ground PSEUDO CODE AANPASSEN Distance to Ground Pseudo code 0. Distance to ground field Distance_to_ground_field.py Input : voxelized_envelope . csv ( low and high res ), svf points 1. Import Meshes 2. Import Lattice 3. Initialize vertical adjacency matrix Calculate distances 4. Construct the field Output : Distance to ground field ( low and high res ) Noise FLOWCHART UPDATEN Noise Pseudo code 0. Noise field Noise_field.py Input : voxelized_envelope . csv ( low and high res ), noise source points , context mesh 1. Import Meshes 2. Import Lattice 3. For each noise source point : Assign a value corresponding with the amount of noise from that point For each voxel : Compute the distance to the noise source points Multiply the distance by the value of the noise source point Convert the values into values between 0 and 1 ( 0 = most noise , 1 = no noise ) 4. Construct the field Output : noise field ( low and high res ) Sun Accessibility Sun Accessibility Sun Access Pseudo code 0. Sun access field Sun_access_field.py Input : voxelized_envelope . csv ( low and high res ), context mesh 1. Import Meshes 2. Import Lattice 3. Import Sun Vectors import Sunpath ( ladybug ) 4. Compute Intersection Create list of all vectors pointing towards the sun locations over the year For all voxels centers : o Compute rays towards all the sun points o If ray hits the context , skip that ray o Else store the ray Calculate the percentage of time each voxel sees the sun Convert the values into values between 0 and 1 ( 0 = no sun , 1 = much sun ) 5. Construct the field Output : sun access field ( low and high res ) Shadow Casting PSEUDO, FLOWCHART EN HIGHRES UPDATEN Shadow Casting Pseudo code 0. Shadow field Shadow_field.py Input : voxelized_envelope . csv ( low and high res ), context mesh 1. Import Meshes 2. Import Lattice 3. Import Sun Vectors import Sunpath ( ladybug ) 4. Compute Intersection Create list of all vectors pointing towards the sun locations over the year For all voxels centers : o Compute rays towards all the sun points o If ray hits the context , skip that ray o Else store the ray Calculate the percentage of time each voxel sees the sun Convert the values into values between 0 and 1 ( 0 = no sun , 1 = much sun ) 5. Construct the field Output : shadow field ( low and high res ) Sky View Factor PSEUDO AFMAKEN View on Greenery Pseudo code 0. Sky view factor field Sky_view_factor_field.py Input : voxelized_envelope . csv ( low and high res ), context mesh 1. Import Meshes 2. Import Lattice SUNPATH 3. Compute Intersection Create list of all vectors pointing towards the sun locations over the year For all voxels centers : o Compute rays towards all the sun points o If ray hits the context , skip that ray o Else store the ray Calculate the percentage of time each voxel sees the sun Convert the values into values between 0 and 1 ( 0 = no sun , 1 = much sun ) 4. Construct the field Output : sky view factor field ( low and high res ) View on Greenery TEST.... View on Greenery Pseudo code 0. View on Green field View_on_green_field.py Input : voxelized_envelope . csv ( low and high res ), green points , context mesh 1. Import Meshes 2. Import Lattice 3. Compute rays from green points to the center of the voxels For each ray the distance and intersection is calculated The outcome is reshaped Convert the values into values between 0 and 1 Construct the view on greenery field 4. Construct the field Output : view on greenery field ( low and high res )","title":"Product"},{"location":"Configuring/a2_configuring_product/#configuring-product","text":"","title":"Configuring: product"},{"location":"Configuring/a2_configuring_product/#distance-to-main-entrance","text":"PSEUDO CODE NAKIJKEN Flowchart Distance to Main Entrance Pseudo code 0. Distance to main entrance field Distance_to_main_entrance_field.py Input : voxelized_envelope . csv ( low and high res ), points of main street and public transport 1. Import Meshes 2. Import Lattice 3. Compute from each voxel the average distance to the main street and public transport Choose the voxel with the minimum distance as the main entrance Retrieve the neighbour voxels of the main entrance Set the value of the horizontal neighbours to 1 and the vertical neighbours to 2 For each neighbour : Find the neighbours and add 1 ( horizontal ) or 2 ( vertical ) to it \u2019 s value , when it does not have a value yet Convert the values into values between 0 and 1 4. Construct the field Output : Distance to main entrance field ( low and high res )","title":"Distance to main entrance"},{"location":"Configuring/a2_configuring_product/#distance-to-the-ground","text":"PSEUDO CODE AANPASSEN Distance to Ground Pseudo code 0. Distance to ground field Distance_to_ground_field.py Input : voxelized_envelope . csv ( low and high res ), svf points 1. Import Meshes 2. Import Lattice 3. Initialize vertical adjacency matrix Calculate distances 4. Construct the field Output : Distance to ground field ( low and high res )","title":"Distance to the ground"},{"location":"Configuring/a2_configuring_product/#noise","text":"FLOWCHART UPDATEN Noise Pseudo code 0. Noise field Noise_field.py Input : voxelized_envelope . csv ( low and high res ), noise source points , context mesh 1. Import Meshes 2. Import Lattice 3. For each noise source point : Assign a value corresponding with the amount of noise from that point For each voxel : Compute the distance to the noise source points Multiply the distance by the value of the noise source point Convert the values into values between 0 and 1 ( 0 = most noise , 1 = no noise ) 4. Construct the field Output : noise field ( low and high res )","title":"Noise"},{"location":"Configuring/a2_configuring_product/#sun-accessibility","text":"Sun Accessibility Sun Access Pseudo code 0. Sun access field Sun_access_field.py Input : voxelized_envelope . csv ( low and high res ), context mesh 1. Import Meshes 2. Import Lattice 3. Import Sun Vectors import Sunpath ( ladybug ) 4. Compute Intersection Create list of all vectors pointing towards the sun locations over the year For all voxels centers : o Compute rays towards all the sun points o If ray hits the context , skip that ray o Else store the ray Calculate the percentage of time each voxel sees the sun Convert the values into values between 0 and 1 ( 0 = no sun , 1 = much sun ) 5. Construct the field Output : sun access field ( low and high res )","title":"Sun Accessibility"},{"location":"Configuring/a2_configuring_product/#shadow-casting","text":"PSEUDO, FLOWCHART EN HIGHRES UPDATEN Shadow Casting Pseudo code 0. Shadow field Shadow_field.py Input : voxelized_envelope . csv ( low and high res ), context mesh 1. Import Meshes 2. Import Lattice 3. Import Sun Vectors import Sunpath ( ladybug ) 4. Compute Intersection Create list of all vectors pointing towards the sun locations over the year For all voxels centers : o Compute rays towards all the sun points o If ray hits the context , skip that ray o Else store the ray Calculate the percentage of time each voxel sees the sun Convert the values into values between 0 and 1 ( 0 = no sun , 1 = much sun ) 5. Construct the field Output : shadow field ( low and high res )","title":"Shadow Casting"},{"location":"Configuring/a2_configuring_product/#sky-view-factor","text":"PSEUDO AFMAKEN View on Greenery Pseudo code 0. Sky view factor field Sky_view_factor_field.py Input : voxelized_envelope . csv ( low and high res ), context mesh 1. Import Meshes 2. Import Lattice SUNPATH 3. Compute Intersection Create list of all vectors pointing towards the sun locations over the year For all voxels centers : o Compute rays towards all the sun points o If ray hits the context , skip that ray o Else store the ray Calculate the percentage of time each voxel sees the sun Convert the values into values between 0 and 1 ( 0 = no sun , 1 = much sun ) 4. Construct the field Output : sky view factor field ( low and high res )","title":"Sky View Factor"},{"location":"Configuring/a2_configuring_product/#view-on-greenery","text":"TEST.... View on Greenery Pseudo code 0. View on Green field View_on_green_field.py Input : voxelized_envelope . csv ( low and high res ), green points , context mesh 1. Import Meshes 2. Import Lattice 3. Compute rays from green points to the center of the voxels For each ray the distance and intersection is calculated The outcome is reshaped Convert the values into values between 0 and 1 Construct the view on greenery field 4. Construct the field Output : view on greenery field ( low and high res )","title":"View on Greenery"},{"location":"Final_Deliveries/bibliography/","text":"Bibliography Here you should cite all references and materials that you have used in your project. This is in addition to citation in the documentation itself.","title":"Bibliography"},{"location":"Final_Deliveries/bibliography/#bibliography","text":"Here you should cite all references and materials that you have used in your project. This is in addition to citation in the documentation itself.","title":"Bibliography"},{"location":"Final_Deliveries/figures/","text":"Figures Here you should include all of your figures and links to the pages that they have been used in. You can embed your only videos like this:","title":"Figures"},{"location":"Final_Deliveries/figures/#figures","text":"Here you should include all of your figures and links to the pages that they have been used in. You can embed your only videos like this:","title":"Figures"},{"location":"Final_Deliveries/poster/","text":"Poster Poster","title":"Poster"},{"location":"Final_Deliveries/poster/#poster","text":"Poster","title":"Poster"},{"location":"Final_Deliveries/presentations/","text":"Presentations Midterm presentation of the course Final presentation of the course","title":"Presentations"},{"location":"Final_Deliveries/presentations/#presentations","text":"Midterm presentation of the course Final presentation of the course","title":"Presentations"},{"location":"Final_Deliveries/reflection/","text":"Reflection Reflection on design goals While looking at the analysis for noise pollution, sun accessibility and view on greenery we can conclude that the residential voxels are mostly clustered at the side of the building site where the values for these analyses are the highest. The final building also has a very high porosity, which lets through a lot of sunlight for every voxel. This makes sure that every room in the building receives the desired amount of sun light. A possible improvement on this goal could be to increase the view on greenery on the building site itself. The external greenery is quite on the lower side when we look at the analysis. Reflection visualized, showing the division between public (purple) and private (green) Reflecting back on the generated floor plan, we can see that the separation between public and private places has been established. All the residential voxels are at the top half of the building and also at the upper levels of the building. The public spaces are at the bottom half of the building and mostly on the ground floor. In our opinion this design goals has been met. The final floor plan generator we have conceptualized can be considered as our most modular aspect of the building. Not only does every interior tile fit inside the voxels, they can also easily be swapped out and reorganized. This means that the function of a room can be changed with ease, without major adjustments to the shape of the building. We haven\u2019t implemented a similar tactic for the fa\u00e7ade, which is something which can be implemented for a project in the coming years. Planning Good job on the metro network diagram. \u25cf Nice architectural framework specified as goals for the quality of spaces \u25cf Stereotypes of the users and inhabitants used in developing narratives and constructing the metro network. And then forming the adjacency matrix Configuring Configuring: the studies on the voxel size look promising but the staircases have to also include the standing platforms. Page 29, perhaps you can put the shafts in the middle as you first create the shafts and then the corridors. Showing hidden corridors in the plan tiles with a hatch, similar to page 38, and explaining the meta-level principles of the modular floor planning process. A reflection on the marked position of the windows (visibility) or doorways (accessibility) on the edges and their potential effects on the configuration rules will be appreciated (for the website especially). \u25cf 2 stencils for computing the distances, the price of the vertical movement is considered higher (+) \u25cf How did you construct the diagrams on 17-20 slide,amazing diagrams, love the gamified style Voxel The final voxel is 3.6*3.6*3.24 (w*d*h) meters. With the minivoxel being 0.9*0.9*0.54 (w*d*h) meters to represent a flight of three stairs. (Fig. 3) The standing platforms between the stairs are 0.90 meters, ideally this would be 1.20 meters so that two people can pass at the same time. The voxel size might need some improvement as the standing platform is 0.90 meter when it ideally would be 1.20 meter or even bigger in depth. This is based on the width that a person needs for a walkway; 0.60 meter. To later improve this there would need to be an extra minivoxel with instead of 3 steps just one and the rest of the depth as standing platform. Visibility and accesibility reflection A reflection on the marked position of the windows (visibility) or doorways (accessibility) on the edges and their potential effects on the configuration rules will be appreciated (for the website especially). Massing Massing: the pixelated diagrams are on a whole new level of quality! Bravo! The special functions deserve to be explained one by one and more elaborately (on the website). With ABM, the research methodology is based on the general idea of testing the usefulness or validity of the local behavioral patterns for achieving the desired global results. Therefore, it would be a good idea to mention what each function is supposed/desired to achieve globally; and then reflect on whether the function in question has achieved the desired results or not (and an analysis of its behavior or idea for future improvement). Why do you get a Swiss Cheese on pages ca. 30? \u25cf S22 seed allocation based on entrance greenery and entrance distance field, agents start from ground, \u25cf Dynamic growth of agents is implemented.... Updating the availability lattice based on the existing voxel and growth only on top of other voxels... this explanation s23, could be done with pseudo code \u25cf Building depth is also implemented, s24, where is the pseudo code? \u25cf Example of building depth is missing, visualization is missing \u25cf Mass variants is showed, s25, great reflective process, this needs to be explained in the website \u25cf 26 amazing final growth \u25cf 27 visualized the evaluation function, did not explain it properly... yellow function could be chosen, since it moves more \u25cf Corridor on the ground floor connecting all of the spaces \u25cf 33 flowcharts of notebooks, functions and data set amazing Functions It would be a good idea to mention what each function is supposed/desired to achieve globally; and then reflect on whether the function in question has achieved the desired results or not (and an analysis of its behavior or idea for future improvement). Forming Forming: The forming phase is well structured but the connection with the early studies on the sizing of the voxels can be made more explicit. The idea is that the voxel sizes should be informed by the forming process. On page 38, why do you mention a \u2018random\u2019 configuration? The idea is that your rules define a grammatical system and then you play by the book containing these grammatical rules. The results may not be necessarily meaningful but they can still be \u2018grammatically\u2019 valid. Page 43 shows that it could be a good looking building. Please do not hesitate from showing the potential look of the building, even if necessary by applying your facade modules by hand, but of course systematically, according to your own rulebook. \u25cf 35 great flowchart describing the process of automatic plan generation, even if the plans are not coming out completely, this is a great framework to start from, 35: can you explain again the connection of the plan tiles? How you take that into consideration \u25cf 37 great to show cse the examples \u25cf 38, formulated as a game, with a scenario. This is perfect, even if the implementation is not complete","title":"Reflection"},{"location":"Final_Deliveries/reflection/#reflection","text":"","title":"Reflection"},{"location":"Final_Deliveries/reflection/#reflection-on-design-goals","text":"While looking at the analysis for noise pollution, sun accessibility and view on greenery we can conclude that the residential voxels are mostly clustered at the side of the building site where the values for these analyses are the highest. The final building also has a very high porosity, which lets through a lot of sunlight for every voxel. This makes sure that every room in the building receives the desired amount of sun light. A possible improvement on this goal could be to increase the view on greenery on the building site itself. The external greenery is quite on the lower side when we look at the analysis. Reflection visualized, showing the division between public (purple) and private (green) Reflecting back on the generated floor plan, we can see that the separation between public and private places has been established. All the residential voxels are at the top half of the building and also at the upper levels of the building. The public spaces are at the bottom half of the building and mostly on the ground floor. In our opinion this design goals has been met. The final floor plan generator we have conceptualized can be considered as our most modular aspect of the building. Not only does every interior tile fit inside the voxels, they can also easily be swapped out and reorganized. This means that the function of a room can be changed with ease, without major adjustments to the shape of the building. We haven\u2019t implemented a similar tactic for the fa\u00e7ade, which is something which can be implemented for a project in the coming years.","title":"Reflection on design goals"},{"location":"Final_Deliveries/reflection/#planning","text":"Good job on the metro network diagram. \u25cf Nice architectural framework specified as goals for the quality of spaces \u25cf Stereotypes of the users and inhabitants used in developing narratives and constructing the metro network. And then forming the adjacency matrix","title":"Planning"},{"location":"Final_Deliveries/reflection/#configuring","text":"Configuring: the studies on the voxel size look promising but the staircases have to also include the standing platforms. Page 29, perhaps you can put the shafts in the middle as you first create the shafts and then the corridors. Showing hidden corridors in the plan tiles with a hatch, similar to page 38, and explaining the meta-level principles of the modular floor planning process. A reflection on the marked position of the windows (visibility) or doorways (accessibility) on the edges and their potential effects on the configuration rules will be appreciated (for the website especially). \u25cf 2 stencils for computing the distances, the price of the vertical movement is considered higher (+) \u25cf How did you construct the diagrams on 17-20 slide,amazing diagrams, love the gamified style","title":"Configuring"},{"location":"Final_Deliveries/reflection/#voxel","text":"The final voxel is 3.6*3.6*3.24 (w*d*h) meters. With the minivoxel being 0.9*0.9*0.54 (w*d*h) meters to represent a flight of three stairs. (Fig. 3) The standing platforms between the stairs are 0.90 meters, ideally this would be 1.20 meters so that two people can pass at the same time. The voxel size might need some improvement as the standing platform is 0.90 meter when it ideally would be 1.20 meter or even bigger in depth. This is based on the width that a person needs for a walkway; 0.60 meter. To later improve this there would need to be an extra minivoxel with instead of 3 steps just one and the rest of the depth as standing platform.","title":"Voxel"},{"location":"Final_Deliveries/reflection/#visibility-and-accesibility-reflection","text":"A reflection on the marked position of the windows (visibility) or doorways (accessibility) on the edges and their potential effects on the configuration rules will be appreciated (for the website especially).","title":"Visibility and accesibility reflection"},{"location":"Final_Deliveries/reflection/#massing","text":"Massing: the pixelated diagrams are on a whole new level of quality! Bravo! The special functions deserve to be explained one by one and more elaborately (on the website). With ABM, the research methodology is based on the general idea of testing the usefulness or validity of the local behavioral patterns for achieving the desired global results. Therefore, it would be a good idea to mention what each function is supposed/desired to achieve globally; and then reflect on whether the function in question has achieved the desired results or not (and an analysis of its behavior or idea for future improvement). Why do you get a Swiss Cheese on pages ca. 30? \u25cf S22 seed allocation based on entrance greenery and entrance distance field, agents start from ground, \u25cf Dynamic growth of agents is implemented.... Updating the availability lattice based on the existing voxel and growth only on top of other voxels... this explanation s23, could be done with pseudo code \u25cf Building depth is also implemented, s24, where is the pseudo code? \u25cf Example of building depth is missing, visualization is missing \u25cf Mass variants is showed, s25, great reflective process, this needs to be explained in the website \u25cf 26 amazing final growth \u25cf 27 visualized the evaluation function, did not explain it properly... yellow function could be chosen, since it moves more \u25cf Corridor on the ground floor connecting all of the spaces \u25cf 33 flowcharts of notebooks, functions and data set amazing","title":"Massing"},{"location":"Final_Deliveries/reflection/#functions","text":"It would be a good idea to mention what each function is supposed/desired to achieve globally; and then reflect on whether the function in question has achieved the desired results or not (and an analysis of its behavior or idea for future improvement).","title":"Functions"},{"location":"Final_Deliveries/reflection/#forming","text":"Forming: The forming phase is well structured but the connection with the early studies on the sizing of the voxels can be made more explicit. The idea is that the voxel sizes should be informed by the forming process. On page 38, why do you mention a \u2018random\u2019 configuration? The idea is that your rules define a grammatical system and then you play by the book containing these grammatical rules. The results may not be necessarily meaningful but they can still be \u2018grammatically\u2019 valid. Page 43 shows that it could be a good looking building. Please do not hesitate from showing the potential look of the building, even if necessary by applying your facade modules by hand, but of course systematically, according to your own rulebook. \u25cf 35 great flowchart describing the process of automatic plan generation, even if the plans are not coming out completely, this is a great framework to start from, 35: can you explain again the connection of the plan tiles? How you take that into consideration \u25cf 37 great to show cse the examples \u25cf 38, formulated as a game, with a scenario. This is perfect, even if the implementation is not complete","title":"Forming"},{"location":"Final_Deliveries/scripts/","text":"Scripts Kopjes invoegen per cell Here you should include all of your scripts whether they are text, python notebook or procedural scripts. You should also include link to the link to relevant location in the main pages, description, explanatory materials such as pseudo code or flowcharts, and visualizations if it is applicable. If necessary this page can be broken down to multiple pages. Here is an example of how to include your scripts:","title":"Scripts"},{"location":"Final_Deliveries/scripts/#scripts","text":"","title":"Scripts"},{"location":"Final_Deliveries/scripts/#kopjes-invoegen-per-cell","text":"Here you should include all of your scripts whether they are text, python notebook or procedural scripts. You should also include link to the link to relevant location in the main pages, description, explanatory materials such as pseudo code or flowcharts, and visualizations if it is applicable. If necessary this page can be broken down to multiple pages. Here is an example of how to include your scripts:","title":"Kopjes invoegen per cell"},{"location":"Forming/a4_forming_process/","text":"Forming: process ARCH tiles korte uitleg, check spelling en layouts Arhcitectural tiles Below are the tiles used for the facade of the building. Facade Below are the tiles used for the corners of the building. Corners Below are the tiles used for the floor of the building. Floor Below are the tiles used for the roof of the building, consisting of three variants; solar pannels, ............. Roof Below are the tiles used for the interior of the building. Interior Below are the tiles used for the balconies of the building. Balcony Shown here is an example of a combination of tiles resulting in a room with a balcony. Example Flowchart architectural floor plan generator Decision Tree Floorplan Generator Floor plans EXPLAIN META LEVEL PRINCIPLE OF FLOOR PLANNING? Below are all the floor plans shown in two variations; regular floor plan and those with hidden corridors. The hidden corridors in the plan tiles are displayed with a hatch. Explaining the meta-level principles of the modular floor planning process. Floor plan living, laundry, bedroom and private toilet Floor plan living, laundry, bedroom and private toilet Floor plan with hidden corridors of living, laundry, bedroom and private toilet Floor plan with hidden corridors of living, laundry, bedroom and private toilet Floor plan library, shops, kitchen and gym Floor plan library, shops, kitchen and gym Floor plan with hidden corridors of library, shops, kitchen and gym Floor plan with hidden corridors of library, shops, kitchen and gym Floor plan restaurant, public toilet and workspaces Floor plan restaurant, public toilet and workspaces Floor plan with hidden corridors of restaurant, public toilet and workspaces Floor plan with hidden corridors of restaurant, public toilet and workspaces Catalogue Displayed below is the catalogue, containing all the furniture per type of space. Every space has hidden paths making for a room that is walkable and usable. These paths are displayed in the center of the catalogue. Catalogue roadmap Below is a roadmap, designed for making a floor plan for any given space. It makes the plan based on the area given, this then gets converted into an amount of mini- and microvoxels. Then the furniture gets selected that is assigned to the type of space. After that the borders of the furniture are assigned. Neighbours are assigned. Assemble the floor plan, make sure there are no double hidden corridors to not waste space. Make the plan orthogonal. And finally evaluate the plan, does it work? Catalogue game in steps (Living Room) Catalogue game in steps (Kitchen) Catalogue game in steps (Caf\u00e9)","title":"Process"},{"location":"Forming/a4_forming_process/#forming-process","text":"","title":"Forming: process"},{"location":"Forming/a4_forming_process/#arch-tiles-korte-uitleg-check-spelling-en-layouts","text":"","title":"ARCH tiles korte uitleg, check spelling en layouts"},{"location":"Forming/a4_forming_process/#arhcitectural-tiles","text":"Below are the tiles used for the facade of the building. Facade Below are the tiles used for the corners of the building. Corners Below are the tiles used for the floor of the building. Floor Below are the tiles used for the roof of the building, consisting of three variants; solar pannels, ............. Roof Below are the tiles used for the interior of the building. Interior Below are the tiles used for the balconies of the building. Balcony Shown here is an example of a combination of tiles resulting in a room with a balcony. Example","title":"Arhcitectural tiles"},{"location":"Forming/a4_forming_process/#flowchart-architectural-floor-plan-generator","text":"Decision Tree Floorplan Generator","title":"Flowchart architectural floor plan generator"},{"location":"Forming/a4_forming_process/#floor-plans-explain-meta-level-principle-of-floor-planning","text":"Below are all the floor plans shown in two variations; regular floor plan and those with hidden corridors. The hidden corridors in the plan tiles are displayed with a hatch. Explaining the meta-level principles of the modular floor planning process. Floor plan living, laundry, bedroom and private toilet Floor plan living, laundry, bedroom and private toilet Floor plan with hidden corridors of living, laundry, bedroom and private toilet Floor plan with hidden corridors of living, laundry, bedroom and private toilet Floor plan library, shops, kitchen and gym Floor plan library, shops, kitchen and gym Floor plan with hidden corridors of library, shops, kitchen and gym Floor plan with hidden corridors of library, shops, kitchen and gym Floor plan restaurant, public toilet and workspaces Floor plan restaurant, public toilet and workspaces Floor plan with hidden corridors of restaurant, public toilet and workspaces Floor plan with hidden corridors of restaurant, public toilet and workspaces","title":"Floor plans EXPLAIN META LEVEL PRINCIPLE OF FLOOR PLANNING?"},{"location":"Forming/a4_forming_process/#catalogue","text":"Displayed below is the catalogue, containing all the furniture per type of space. Every space has hidden paths making for a room that is walkable and usable. These paths are displayed in the center of the catalogue.","title":"Catalogue"},{"location":"Forming/a4_forming_process/#catalogue-roadmap","text":"Below is a roadmap, designed for making a floor plan for any given space. It makes the plan based on the area given, this then gets converted into an amount of mini- and microvoxels. Then the furniture gets selected that is assigned to the type of space. After that the borders of the furniture are assigned. Neighbours are assigned. Assemble the floor plan, make sure there are no double hidden corridors to not waste space. Make the plan orthogonal. And finally evaluate the plan, does it work? Catalogue game in steps (Living Room) Catalogue game in steps (Kitchen) Catalogue game in steps (Caf\u00e9)","title":"Catalogue roadmap"},{"location":"Forming/a4_forming_product/","text":"Forming: product RENDER Here the final renders of the project can be seen. Render birds eye view Render Render eye height park Render park Render eye height road Render road Render north side Render Render east side Render Render south side Render Render west side Render Render west side Render","title":"Product"},{"location":"Forming/a4_forming_product/#forming-product","text":"","title":"Forming: product"},{"location":"Forming/a4_forming_product/#render","text":"Here the final renders of the project can be seen.","title":"RENDER"},{"location":"Forming/a4_forming_product/#render-birds-eye-view","text":"Render","title":"Render birds eye view"},{"location":"Forming/a4_forming_product/#render-eye-height-park","text":"Render park","title":"Render eye height park"},{"location":"Forming/a4_forming_product/#render-eye-height-road","text":"Render road","title":"Render eye height road"},{"location":"Forming/a4_forming_product/#render-north-side","text":"Render","title":"Render north side"},{"location":"Forming/a4_forming_product/#render-east-side","text":"Render","title":"Render east side"},{"location":"Forming/a4_forming_product/#render-south-side","text":"Render","title":"Render south side"},{"location":"Forming/a4_forming_product/#render-west-side","text":"Render","title":"Render west side"},{"location":"Forming/a4_forming_product/#render-west-side_1","text":"Render","title":"Render west side"},{"location":"Massing/a3_massing_process/","text":"Massing: process Evaluate voxel Before the process of growing the voxels can start, we need a way to evaluate all the voxels in order to know where every agent wants to grow. That is the purpose of this function. The fields, created in the configuring part, will be combined with the information from the program of requirements. For the to be evaluated voxels the original value from a particular field will be raised by the preference to get the new value. The value of each voxel will be different for every agent and different for each iteration. Evaluate voxel Pseudo code Evaluate_voxels.py 1 2 3 4 5 6 7 8 9 10 Input : location of the to be evaluated voxels , fields , preferences Create a list full of ones with the same length as the amount of voxels to be evaluated For each agent : Find the raw value of these voxels in the fields Raise these values with the weight of each preference Multiply all the new values with each other to get the final value Return the final values Output : new values of evaluated voxels Seed allocation We started the massing part with the initializing the agents. For that we used the function to evaluate voxels. At first the agents are placed at the spot where they feel most comfortable. Furthermore, we added another feature to the initialization part. When the agents are at the place with the highest values, they are moved down to ground level. This is done to discourage too much floating agents later in the process. Initialization of the agents Pseudo code Initialization_agents.py 1 2 3 4 5 6 7 8 9 10 11 Input : voxelized_envelope . csv ( high res ), fields , program of requirement Initialize the empty occupation lattice ( full of - 1 ) For the agent ids and the agent preferences : Create a preference lattice for every agent Raise the value of every field by the weight given in the program Select the voxel with the highest value Move the voxel to ground level , to prevent floating parts Change the value in the occupation and availability lattice Output : Initialized agents Change value Change value This function is created to occupy voxels or leave voxels. In the beginning the agents will eat voxels. When the maximum amount of voxels is reached, the value of the neighbours is compared with the internal voxels. When the neighbour has a value which is 10% higher than the internal voxel, one will be let go and the other one will be occupied. This all happens within the same function. Pseudo code Change_value.py 1 2 3 4 5 6 7 8 9 10 11 Input : occupation lattice , availability lattice , location , agent location list , new id If the voxel needs to get occupied ( new id > - 1 in occupation lattice ): Add the location to the list of agent locations Change the value of the availability lattice to occupied ( = 0 ) Else ( voxel needs to be removed ): Remove the location from the agent locations list Change the value of the availability lattice to unoccupied ( = 1 ) Change the value of the occupation lattice to the new id Output : new occupation lattice , new availability lattice , location , agents location list Squareness Squareness is a behaviour we created to encourage the agents to grow in rectangular shapes to create usable spaces. When a neighbour exists for multiple voxels it will increase the squareness and therefore its value will be raised. Squareness Pseudo code Squareness.py 1 2 3 4 5 6 7 8 9 10 11 Input : 1 d location of the free neighbours , squareness weight use the numpy unique function to : return how many times each neighbour is in the list return what the first unique index is of each neighbour for every unique free neighbour : evaluate each agent with the \u201c evaluate_voxel \u201d function raise the squareness weight by the amount of times the neighbour exist - 1 multiply the old value with the calculated squareness value output : value of each free neighbour Prevent floating agents This behaviour is created to prevent agents from floating in the air in order to create a more realistic building. By only making the voxels available which have voxels beneath, the agents can only grow at places which are connected to the ground Prevent floating agents Pseudo code Prevent_floating.py 1 2 3 4 5 6 7 8 9 Input : occupation lattice Retrieve the location of the occupied voxels ( id > - 1 ) Move the occupied voxels one place up Subtract the new occupation lattice from the old occupation lattice Now only the voxels with voxels beneath are available ( id = 1 in avail_lattice ) Set the voxels on ground level which have now the value 0 ( unoccupied ) to 1 so the agent can grow to the sides as well . Output : new availability lattice Limitting building depth This behaviour limits the building depth in the horizontal directions. This is done to get as much light in the building as possible and thereby achieve one of the design principles, creating good living conditions. The skylight and sunlight hits the building at an angle and therefore it cannot reach too far in a space. Building depth Pseudo code Building_depth.py 1 2 3 4 5 6 7 8 Input : occupation lattice , availability lattice , max . building depth Create stencils to check the different directions Create conditions for each direction In the x - direction there can \u2019 t be more voxels next to each other than the max building depth In the y - direction there can \u2019 t be more voxels next to each other than the max building depth Output : new availability lattice Final mass Before choosing a final mass there were four options as we had two functions to choose out off. Below are the results of both functions off, float function off, both functions on and finally the final mass that has only the building depth function on and the no float function off. Functions and expectations Both off: We ran the simulation multiple times to see the effect of some specific functions, especially the function which prevents floating parts and the function on limiting the building depth. The first configuration is the result of simulation with both functions turned off. This configuration consists out of one big mass with for a big part a horizontal roof. This makes it difficult for the sun to penetrate the middle of the building. One of the design principles was to create a good living condition with as much light as possible. This configuration does not meet this criteria. Mass variant, both functions off No float function: In the second configuration the function which prevents floating agents is turned on. This function has the effect that all the agents want to go up and therefor it creates a massive wall of about 44 metres high. The building will cast too much shadow on the neighbours and is therefore not an option. To prevent getting a big wall as configuration, there needs to be experimented with extra fields which will push some of the agents to the other side of the plot. Mass variant, float function on Both on: The third time we ran the simulation with both functions on. The third configuration is similar to the second configuration. The difference is that there are some holes in the wall, because of the maximum building depth of 3 voxels. However, for the overall shape, the behaviour of preventing floating parts has more impact on the shape than the limitation of the building depth. As with the previous configuration is this mass too high, so it will cast too much shadow and is therefore not a fit for our project. Mass variant, both functions on Building depth: For the last configuration, only the limitation of the building depth is used. We choose a maximum building depth of 3 voxels, because then the building depth will become at most about 10 metres. When there are windows on both sides, most part of the building will be able to get sunlight. The result is a configuration which looks like the first configuration, but with a lot more height differences in the roof and walls. Therefore the sun can penetrate the building at more places. Next to that, the building does not cast too much shadow on the surrounding. To conclude, this configuration fits our design goals best and will therefore be our final mass. Final mass, float off, depth on Centers of clusters Centers of clusters Pseudo code Cluster_centers.py 1 2 3 4 5 6 Input : massing lattice Find the different clusters in the grown ABM Choose which voxel fits the best as centre of the agent cluster Output : cluster centers Shafts Shafts Pseudo code Shaft_forming.py 1 2 3 4 5 6 Input : cluster centers Create 4 clusters from the chosen cluster centres Choose which row of voxels fits the best as centre of the clusters Output : shafts Paths Paths Pseudo code Corridor_forming.py 1 2 3 4 5 6 7 8 Input : shafts , main entrance For every cluster center Find the shortest path to a shaft For every shaft Find the shortest path to the main entrance Output : corridors GIF growth example An example of the growth of the fields, shown below is the student house. Student house growth","title":"Process"},{"location":"Massing/a3_massing_process/#massing-process","text":"","title":"Massing: process"},{"location":"Massing/a3_massing_process/#evaluate-voxel","text":"Before the process of growing the voxels can start, we need a way to evaluate all the voxels in order to know where every agent wants to grow. That is the purpose of this function. The fields, created in the configuring part, will be combined with the information from the program of requirements. For the to be evaluated voxels the original value from a particular field will be raised by the preference to get the new value. The value of each voxel will be different for every agent and different for each iteration. Evaluate voxel Pseudo code Evaluate_voxels.py 1 2 3 4 5 6 7 8 9 10 Input : location of the to be evaluated voxels , fields , preferences Create a list full of ones with the same length as the amount of voxels to be evaluated For each agent : Find the raw value of these voxels in the fields Raise these values with the weight of each preference Multiply all the new values with each other to get the final value Return the final values Output : new values of evaluated voxels","title":"Evaluate voxel"},{"location":"Massing/a3_massing_process/#seed-allocation","text":"We started the massing part with the initializing the agents. For that we used the function to evaluate voxels. At first the agents are placed at the spot where they feel most comfortable. Furthermore, we added another feature to the initialization part. When the agents are at the place with the highest values, they are moved down to ground level. This is done to discourage too much floating agents later in the process. Initialization of the agents Pseudo code Initialization_agents.py 1 2 3 4 5 6 7 8 9 10 11 Input : voxelized_envelope . csv ( high res ), fields , program of requirement Initialize the empty occupation lattice ( full of - 1 ) For the agent ids and the agent preferences : Create a preference lattice for every agent Raise the value of every field by the weight given in the program Select the voxel with the highest value Move the voxel to ground level , to prevent floating parts Change the value in the occupation and availability lattice Output : Initialized agents","title":"Seed allocation"},{"location":"Massing/a3_massing_process/#change-value","text":"Change value This function is created to occupy voxels or leave voxels. In the beginning the agents will eat voxels. When the maximum amount of voxels is reached, the value of the neighbours is compared with the internal voxels. When the neighbour has a value which is 10% higher than the internal voxel, one will be let go and the other one will be occupied. This all happens within the same function. Pseudo code Change_value.py 1 2 3 4 5 6 7 8 9 10 11 Input : occupation lattice , availability lattice , location , agent location list , new id If the voxel needs to get occupied ( new id > - 1 in occupation lattice ): Add the location to the list of agent locations Change the value of the availability lattice to occupied ( = 0 ) Else ( voxel needs to be removed ): Remove the location from the agent locations list Change the value of the availability lattice to unoccupied ( = 1 ) Change the value of the occupation lattice to the new id Output : new occupation lattice , new availability lattice , location , agents location list","title":"Change value"},{"location":"Massing/a3_massing_process/#squareness","text":"Squareness is a behaviour we created to encourage the agents to grow in rectangular shapes to create usable spaces. When a neighbour exists for multiple voxels it will increase the squareness and therefore its value will be raised. Squareness Pseudo code Squareness.py 1 2 3 4 5 6 7 8 9 10 11 Input : 1 d location of the free neighbours , squareness weight use the numpy unique function to : return how many times each neighbour is in the list return what the first unique index is of each neighbour for every unique free neighbour : evaluate each agent with the \u201c evaluate_voxel \u201d function raise the squareness weight by the amount of times the neighbour exist - 1 multiply the old value with the calculated squareness value output : value of each free neighbour","title":"Squareness"},{"location":"Massing/a3_massing_process/#prevent-floating-agents","text":"This behaviour is created to prevent agents from floating in the air in order to create a more realistic building. By only making the voxels available which have voxels beneath, the agents can only grow at places which are connected to the ground Prevent floating agents Pseudo code Prevent_floating.py 1 2 3 4 5 6 7 8 9 Input : occupation lattice Retrieve the location of the occupied voxels ( id > - 1 ) Move the occupied voxels one place up Subtract the new occupation lattice from the old occupation lattice Now only the voxels with voxels beneath are available ( id = 1 in avail_lattice ) Set the voxels on ground level which have now the value 0 ( unoccupied ) to 1 so the agent can grow to the sides as well . Output : new availability lattice","title":"Prevent floating agents"},{"location":"Massing/a3_massing_process/#limitting-building-depth","text":"This behaviour limits the building depth in the horizontal directions. This is done to get as much light in the building as possible and thereby achieve one of the design principles, creating good living conditions. The skylight and sunlight hits the building at an angle and therefore it cannot reach too far in a space. Building depth Pseudo code Building_depth.py 1 2 3 4 5 6 7 8 Input : occupation lattice , availability lattice , max . building depth Create stencils to check the different directions Create conditions for each direction In the x - direction there can \u2019 t be more voxels next to each other than the max building depth In the y - direction there can \u2019 t be more voxels next to each other than the max building depth Output : new availability lattice","title":"Limitting building depth"},{"location":"Massing/a3_massing_process/#final-mass","text":"Before choosing a final mass there were four options as we had two functions to choose out off. Below are the results of both functions off, float function off, both functions on and finally the final mass that has only the building depth function on and the no float function off.","title":"Final mass"},{"location":"Massing/a3_massing_process/#functions-and-expectations","text":"Both off: We ran the simulation multiple times to see the effect of some specific functions, especially the function which prevents floating parts and the function on limiting the building depth. The first configuration is the result of simulation with both functions turned off. This configuration consists out of one big mass with for a big part a horizontal roof. This makes it difficult for the sun to penetrate the middle of the building. One of the design principles was to create a good living condition with as much light as possible. This configuration does not meet this criteria. Mass variant, both functions off No float function: In the second configuration the function which prevents floating agents is turned on. This function has the effect that all the agents want to go up and therefor it creates a massive wall of about 44 metres high. The building will cast too much shadow on the neighbours and is therefore not an option. To prevent getting a big wall as configuration, there needs to be experimented with extra fields which will push some of the agents to the other side of the plot. Mass variant, float function on Both on: The third time we ran the simulation with both functions on. The third configuration is similar to the second configuration. The difference is that there are some holes in the wall, because of the maximum building depth of 3 voxels. However, for the overall shape, the behaviour of preventing floating parts has more impact on the shape than the limitation of the building depth. As with the previous configuration is this mass too high, so it will cast too much shadow and is therefore not a fit for our project. Mass variant, both functions on Building depth: For the last configuration, only the limitation of the building depth is used. We choose a maximum building depth of 3 voxels, because then the building depth will become at most about 10 metres. When there are windows on both sides, most part of the building will be able to get sunlight. The result is a configuration which looks like the first configuration, but with a lot more height differences in the roof and walls. Therefore the sun can penetrate the building at more places. Next to that, the building does not cast too much shadow on the surrounding. To conclude, this configuration fits our design goals best and will therefore be our final mass. Final mass, float off, depth on","title":"Functions and expectations"},{"location":"Massing/a3_massing_process/#centers-of-clusters","text":"Centers of clusters Pseudo code Cluster_centers.py 1 2 3 4 5 6 Input : massing lattice Find the different clusters in the grown ABM Choose which voxel fits the best as centre of the agent cluster Output : cluster centers","title":"Centers of clusters"},{"location":"Massing/a3_massing_process/#shafts","text":"Shafts Pseudo code Shaft_forming.py 1 2 3 4 5 6 Input : cluster centers Create 4 clusters from the chosen cluster centres Choose which row of voxels fits the best as centre of the clusters Output : shafts","title":"Shafts"},{"location":"Massing/a3_massing_process/#paths","text":"Paths Pseudo code Corridor_forming.py 1 2 3 4 5 6 7 8 Input : shafts , main entrance For every cluster center Find the shortest path to a shaft For every shaft Find the shortest path to the main entrance Output : corridors","title":"Paths"},{"location":"Massing/a3_massing_process/#gif-growth-example","text":"An example of the growth of the fields, shown below is the student house. Student house growth","title":"GIF growth example"},{"location":"Massing/a3_massing_product/","text":"Massing: product GIF massing Below is the gif of the final massing. Gif of the massing Final mass Shown here is our final mass, using only the function of the building depth. In the mass the public and private parts of the building are seperated, the public spaces being grouped around the ground floor and towards the south and the private spaces such as housing is oriented towards the north of the building. Final mass Legend 1 Legend 2 Legend 3 GIF floors Floor plan gif Floor plan context Top view of the building in context with the city Flow diagram notebooks","title":"Product"},{"location":"Massing/a3_massing_product/#massing-product","text":"","title":"Massing: product"},{"location":"Massing/a3_massing_product/#gif-massing","text":"Below is the gif of the final massing. Gif of the massing","title":"GIF massing"},{"location":"Massing/a3_massing_product/#final-mass","text":"Shown here is our final mass, using only the function of the building depth. In the mass the public and private parts of the building are seperated, the public spaces being grouped around the ground floor and towards the south and the private spaces such as housing is oriented towards the north of the building. Final mass Legend 1 Legend 2 Legend 3","title":"Final mass"},{"location":"Massing/a3_massing_product/#gif-floors","text":"Floor plan gif","title":"GIF floors"},{"location":"Massing/a3_massing_product/#floor-plan-context","text":"Top view of the building in context with the city","title":"Floor plan context"},{"location":"Massing/a3_massing_product/#flow-diagram-notebooks","text":"","title":"Flow diagram notebooks"},{"location":"Planning/a1_planning_process/","text":"Planning: process Design goals Using the existing surrounding structures and creating a new function/environment. (train) Next to the site there is an unused train track. The train track is currently used by restaurants and caf\u00e9s. The train track provides a unique and creative location and is attractive to business owners and new developers. Especially since it's close to the city centre, the location provides a lot of potential. Integrating surrounding wall paintings on the site The area around the site has a lot of different wall paintings. This is something characteristic of Rotterdam, and especially Rotterdam-north. An improvement on the side would be integrating these artistic pieces on the building site and the surrounding area. Keeping current existing businesses onto the site and in the building Currently the building is used by various: restaurants, businesses and foundations. The idea is to keep these businesses on the newly developed site. and integrate them into the new program Expanding and connecting surrounding green structures to create qualitative greenery The area is currently divided into different sections of greenery. The disconnection between the green structures creates a low quality of green. by connecting and expanding the greenery, a more qualitative feel is created. Creating an accessible connection between the building and the surrounding area. By making entrances facing general accessibility points or entrance areas the site becomes more open towards the public Design principles Creating a good living condition which includes: enough daylight in every space reduce sound pollution view on green spaces (certain percentage) Living conditions Public spaces are separated from the private and communal spaces, (in which the public functions are easily accessible form public routes) Seperate public and private spaces Modules or components can be combined in a flexible way across a system standardized grid size Modularity Program of Requirements In the table below the requirements for every type of space is defined. The amount of housing is set from the start. The table shows the type of space, size in m\u00b2, size per unit (for housing) and the amount of voxels. Routing We created different routings for the different target groups of the building; students, starters, elderly and visitors. The first 3 groups have a division in arriving to their homes (external routing) and the routes they take inside the building (internal routing). Users of the building with their characteristics The routing diagrams also include the approximate times of occurrence per week. This will help weigh each connection between the spaces. Students External Internal Starters External Internal Elderly External Internal Visitors","title":"Process"},{"location":"Planning/a1_planning_process/#planning-process","text":"","title":"Planning: process"},{"location":"Planning/a1_planning_process/#design-goals","text":"Using the existing surrounding structures and creating a new function/environment. (train) Next to the site there is an unused train track. The train track is currently used by restaurants and caf\u00e9s. The train track provides a unique and creative location and is attractive to business owners and new developers. Especially since it's close to the city centre, the location provides a lot of potential. Integrating surrounding wall paintings on the site The area around the site has a lot of different wall paintings. This is something characteristic of Rotterdam, and especially Rotterdam-north. An improvement on the side would be integrating these artistic pieces on the building site and the surrounding area. Keeping current existing businesses onto the site and in the building Currently the building is used by various: restaurants, businesses and foundations. The idea is to keep these businesses on the newly developed site. and integrate them into the new program Expanding and connecting surrounding green structures to create qualitative greenery The area is currently divided into different sections of greenery. The disconnection between the green structures creates a low quality of green. by connecting and expanding the greenery, a more qualitative feel is created. Creating an accessible connection between the building and the surrounding area. By making entrances facing general accessibility points or entrance areas the site becomes more open towards the public","title":"Design goals"},{"location":"Planning/a1_planning_process/#design-principles","text":"Creating a good living condition which includes: enough daylight in every space reduce sound pollution view on green spaces (certain percentage) Living conditions Public spaces are separated from the private and communal spaces, (in which the public functions are easily accessible form public routes) Seperate public and private spaces Modules or components can be combined in a flexible way across a system standardized grid size Modularity","title":"Design principles"},{"location":"Planning/a1_planning_process/#program-of-requirements","text":"In the table below the requirements for every type of space is defined. The amount of housing is set from the start. The table shows the type of space, size in m\u00b2, size per unit (for housing) and the amount of voxels.","title":"Program of Requirements"},{"location":"Planning/a1_planning_process/#routing","text":"We created different routings for the different target groups of the building; students, starters, elderly and visitors. The first 3 groups have a division in arriving to their homes (external routing) and the routes they take inside the building (internal routing). Users of the building with their characteristics The routing diagrams also include the approximate times of occurrence per week. This will help weigh each connection between the spaces. Students External Internal Starters External Internal Elderly External Internal Visitors","title":"Routing"},{"location":"Planning/a1_planning_product/","text":"Planning: product Metro diagram The first objective of the design process was to create a network graph visualizing the main trips inside the building based on our design goals and the routing from the previous page. Adjacency matrix This matrix shows the relations between spaces, being either 0 or 1, thus defining if there is a connection between spaces or not.These have been based on the previous diagrams such as then metro diagram and the routing. Relations between spaces Relations between spaces, ranging from 0-1. This defines how strong the pull between certain spaces is. 1 being the closest and 0 the lowest, based on the metro diagram the spaces have been scored. If space 1 was one space away from space 2 then the relation would be 0.50, if space 2 had been two spaces away then the score would be 0.25. If the distance is further than two then there is no connection and 0.00 will be the connection between spaces.","title":"Product"},{"location":"Planning/a1_planning_product/#planning-product","text":"","title":"Planning: product"},{"location":"Planning/a1_planning_product/#metro-diagram","text":"The first objective of the design process was to create a network graph visualizing the main trips inside the building based on our design goals and the routing from the previous page.","title":"Metro diagram"},{"location":"Planning/a1_planning_product/#adjacency-matrix","text":"This matrix shows the relations between spaces, being either 0 or 1, thus defining if there is a connection between spaces or not.These have been based on the previous diagrams such as then metro diagram and the routing.","title":"Adjacency matrix"},{"location":"Planning/a1_planning_product/#relations-between-spaces","text":"Relations between spaces, ranging from 0-1. This defines how strong the pull between certain spaces is. 1 being the closest and 0 the lowest, based on the metro diagram the spaces have been scored. If space 1 was one space away from space 2 then the relation would be 0.50, if space 2 had been two spaces away then the score would be 0.25. If the distance is further than two then there is no connection and 0.00 will be the connection between spaces.","title":"Relations between spaces"},{"location":"Scripts/distance_entrance/","text":"Distance entrance Import packages 1 2 3 4 5 6 7 8 import os import topogenesis as tg import pyvista as pv import trimesh as tm import numpy as np import networkx as nx from scipy.interpolate import RegularGridInterpolator import resources.functions as f Import meshes 1 2 3 4 5 6 envelope_path = os . path . relpath ( '../data/new_envelope.obj' ) context_path = os . path . relpath ( '../data/immediate_context.obj' ) # load the mesh from file envelope_mesh = tm . load ( envelope_path ) context_mesh = tm . load ( context_path ) Import envelope lattice 1 2 3 4 5 6 7 8 9 10 11 # loading the lowres lattice from csv field_path = os . path . relpath ( \"../data/envelope_lowres.csv\" ) envelope_lattice = tg . lattice_from_csv ( field_path ) init_avail_lattice = tg . to_lattice ( np . copy ( envelope_lattice ), envelope_lattice ) # create a full lattice full with ones full_lattice = envelope_lattice * 0 + 1 # loading the highres lattice from csv field_path = os . path . relpath ( \"../data/envelope_highres.csv\" ) highres_lattice = tg . lattice_from_csv ( field_path ) Import street points + public transport points 1 2 street_transport_path = os . path . relpath ( '../data/mainstreet_publictransport.xyz.txt' ) street_transport = np . genfromtxt ( street_transport_path , delimiter = ',' ) Euclidean distance lattice Distance matrix 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 # extracting the centroid of all voxels env_cens = envelope_lattice . centroids_threshold ( - 1 ) # initializing the distance matrix dist_m = [] # for each voxel ... for voxel_cen in env_cens : # initializing the distance vector (per each voxel) dist_v = [] # for each street point ... for street_transport_point in street_transport : # find the difference vector diff = voxel_cen - street_transport_point # raise the components to the power of two diff_p2 = diff ** 2 # sum the components diff_p2s = diff_p2 . sum () # compute the square root dist = diff_p2s ** 0.5 # add the distance to the distance vector dist_v . append ( dist ) # add the distance vector to the distance matrix dist_m . append ( dist_v ) # change the distance matrix type, from list to array dist_m = np . array ( dist_m ) Selecting entrance voxel Finding min distance to street and public 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # average of the distances to each point per voxel av_dist = [] for str_trans_points in dist_m : # calculate av_dist by taking the sum of the distances and divide by the amount of street points av_dist_vox = str_trans_points . sum () / len ( street_transport ) av_dist . append ( av_dist_vox ) # Find the voxel with the minimum average distance min_dist = np . min ( av_dist ) # Find the index of this voxel min_index = np . argmin ( av_dist ) # get the 3d location min_index_3d = np . unravel_index ( min_index , envelope_lattice . shape ) Import the stencils Stencil horizontal 1 2 3 4 5 6 7 8 # creating neighborhood definition 1 (horizontal) stencil_1 = tg . create_stencil ( \"von_neumann\" , 0 , 1 ) # setting the indices stencil_1 . set_index ([ 0 , 0 , 0 ], 0 ) stencil_1 . set_index ([ 0 , - 1 , 0 ], 1 ) stencil_1 . set_index ([ 0 , 1 , 0 ], 1 ) stencil_1 . set_index ([ - 1 , 0 , 0 ], 1 ) stencil_1 . set_index ([ 1 , 0 , 0 ], 1 ) Stencil vertical 1 2 3 4 5 6 # creating neighborhood definition 2 (vertical) stencil_2 = tg . create_stencil ( \"von_neumann\" , 0 , 1 ) # setting the indices stencil_2 . set_index ([ 0 , 0 , 0 ], 0 ) stencil_2 . set_index ([ 0 , 0 , - 1 ], 1 ) stencil_2 . set_index ([ 0 , 0 , 1 ], 1 ) Make envelope padded 1 2 3 4 5 6 7 8 9 # make envelope padded to prevent seeing one side as a neighbour of the other side env_padded_array = np . pad ( envelope_lattice , 1 ) padded_minbound = envelope_lattice . minbound - envelope_lattice . unit env_padded_lattice = tg . to_lattice ( env_padded_array , minbound = padded_minbound , unit = envelope_lattice . unit ) # convert the location of the main entrance to the right envelope str_con_lattice = env_padded_lattice * False ent_sel_3d_ind_padded = tuple ( np . array ( np . unravel_index ( min_index , envelope_lattice . shape )) + 1 ) str_con_lattice [ ent_sel_3d_ind_padded ] = True Distance lattice Retrieve neighbours 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 # retrieve the neighbour list of each cell neighs_1 = str_con_lattice . find_neighbours ( stencil_1 ) neighs_2 = str_con_lattice . find_neighbours ( stencil_2 ) # set the maximum distance to sum of the size of the lattice in all dimensions. max_dist = np . sum ( str_con_lattice . shape ) # initialize the street network distance lattice with all the street cells as 0, and all other cells as maximum distance possible mn_dist_lattice = 1 - str_con_lattice mn_dist_lattice [ mn_dist_lattice == 1 ] = max_dist # flatten the distance lattice for easy access mn_dist_lattice_flat = mn_dist_lattice . flatten () # flatten the envelope lattice env_pad_lat_flat = env_padded_lattice . flatten () Giving every voxel values 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 # main loop for breath-first traversal for i in range ( 1 , max_dist ): # find the neighbours of the previous step next_step_1 = neighs_1 [ mn_dist_lattice_flat == i - 1 ] # find the unique neighbours next_unq_step_1 = np . unique ( next_step_1 . flatten ()) # check if the neighbours of the next step are inside the envelope validity_condition_1 = env_pad_lat_flat [ next_unq_step_1 ] # select the valid neighbours next_valid_step_1 = next_unq_step_1 [ validity_condition_1 ] # find the neighbours of the previous step next_step_2 = neighs_2 [ mn_dist_lattice_flat == i - 1 ] # find the unique neighbours next_unq_step_2 = np . unique ( next_step_2 . flatten ()) # check if the neighbours of the next step are inside the envelope validity_condition_2 = env_pad_lat_flat [ next_unq_step_2 ] # select the valid neighbours next_valid_step_2 = next_unq_step_2 [ validity_condition_2 ] # make a copy of the lattice to prevent overwriting in the memory mn_nex_dist_lattice_flat = np . copy ( mn_dist_lattice_flat ) # set the next step cells to the current distance mn_nex_dist_lattice_flat [ next_valid_step_2 ] = i + 1 # set the next step cells to the current distance mn_nex_dist_lattice_flat [ next_valid_step_1 ] = i # find the minimum of the current distance and previous distances to avoid overwriting previous steps mn_dist_lattice_flat = np . minimum ( mn_dist_lattice_flat , mn_nex_dist_lattice_flat ) # check how many of the cells have not been traversed yet filled_check = mn_dist_lattice_flat * env_pad_lat_flat == max_dist # if all the cells have been traversed, break the loop if filled_check . sum () == 0 : print ( i ) break # reshape and construct a lattice from the street network distance list mn_dist_lattice = mn_dist_lattice_flat . reshape ( mn_dist_lattice . shape ) mn_dist_lattice = mn_dist_lattice . astype ( float ) mn_dist_lattice *= env_padded_lattice # reverse the lattice values (1 = close, 0 = far) mn_dist_lattice = env_padded_lattice - ( mn_dist_lattice - mn_dist_lattice . min ()) / mn_dist_lattice . max () Visualize distance lattice 1 f . visualize ( mn_dist_lattice , \"Entrance distance\" , \"../data/distance_field.png\" ) Write distance lattice to csv 1 2 3 # write distance lattice to csv csv_path = os . path . relpath ( \"../data/field_distance_entrance.csv\" ) mn_dist_lattice . to_csv ( csv_path ) Interpolate lowres lattice to highres 1 2 3 # loading highres lattice highres_lattice_path = os . path . relpath ( '../data/envelope_highres.csv' ) highres_lattice = tg . lattice_from_csv ( highres_lattice_path ) Define interpolation function 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 def interpolate ( lowres_field ): # loading highres lattice highres_lattice_path = os . path . relpath ( '../data/envelope_highres.csv' ) highres_lat = tg . lattice_from_csv ( highres_lattice_path ) highres_lattice = highres_lat * 0 + 1 # line spaces x_space = np . linspace ( lowres_field . minbound [ 0 ], lowres_field . maxbound [ 0 ], lowres_field . shape [ 0 ]) y_space = np . linspace ( lowres_field . minbound [ 1 ], lowres_field . maxbound [ 1 ], lowres_field . shape [ 1 ]) z_space = np . linspace ( lowres_field . minbound [ 2 ], lowres_field . maxbound [ 2 ], lowres_field . shape [ 2 ]) # interpolation function interpolating_function = RegularGridInterpolator (( x_space , y_space , z_space ), lowres_field , bounds_error = False , fill_value = None ) # high_res lattice full_lattice = highres_lattice + 1 # sample point sample_points = full_lattice . centroids # interpolation interpolated_values = interpolating_function ( sample_points ) # lattice construction interpolated_lattice = tg . to_lattice ( interpolated_values . reshape ( highres_lattice . shape ), highres_lattice ) # nulling the unavailable cells interpolated_lattice *= highres_lattice return interpolated_lattice Interpolate closeness lattice 1 2 3 # Interpolate from lowres to highres highres_entrance = interpolate ( mn_dist_lattice ) highres_entrance_lattice = highres_entrance * highres_lattice Save interpolated field to csv 1 2 3 # save the interpolated distance field to csv csv_path = os . path . relpath ( \"../data/ent_acc.csv\" ) highres_entrance_lattice . to_csv ( csv_path ) Visualize highres field 1 f . visualize ( highres_entrance , \"Entrance distance\" , \"../data/ent_acc_highres.png\" ) Generate configuration Set conditions for the voxels 1 2 3 # this is an example configuration of looking only at the distance to the entrance highres_entrance_minmax = ( highres_entrance_lattice > 0.5 ) * ( highres_entrance_lattice != 0 ) highres_entrance_minmax . sum () Visualize the conditioned voxels 1 2 3 base_lattice = highres_entrance_minmax * highres_entrance_lattice f . visualize ( base_lattice , \"Entrance distance\" , \"distance_field_conf.png\" ) Save configuration to csv 1 2 3 # save the configuration to csv csv_path = os . path . relpath ( \"../data/configuration_distance_entrance.csv\" ) highres_entrance_minmax . to_csv ( csv_path ) Credits 1 2 3 4 5 __author__ = \"Shervin Azadi\" __license__ = \"MIT\" __version__ = \"1.0\" __url__ = \"https://github.com/shervinazadi/earthy_workshops\" __summary__ = \"Earthy Design Studio\"","title":"Distance"},{"location":"Scripts/distance_entrance/#distance-entrance","text":"Import packages 1 2 3 4 5 6 7 8 import os import topogenesis as tg import pyvista as pv import trimesh as tm import numpy as np import networkx as nx from scipy.interpolate import RegularGridInterpolator import resources.functions as f Import meshes 1 2 3 4 5 6 envelope_path = os . path . relpath ( '../data/new_envelope.obj' ) context_path = os . path . relpath ( '../data/immediate_context.obj' ) # load the mesh from file envelope_mesh = tm . load ( envelope_path ) context_mesh = tm . load ( context_path ) Import envelope lattice 1 2 3 4 5 6 7 8 9 10 11 # loading the lowres lattice from csv field_path = os . path . relpath ( \"../data/envelope_lowres.csv\" ) envelope_lattice = tg . lattice_from_csv ( field_path ) init_avail_lattice = tg . to_lattice ( np . copy ( envelope_lattice ), envelope_lattice ) # create a full lattice full with ones full_lattice = envelope_lattice * 0 + 1 # loading the highres lattice from csv field_path = os . path . relpath ( \"../data/envelope_highres.csv\" ) highres_lattice = tg . lattice_from_csv ( field_path ) Import street points + public transport points 1 2 street_transport_path = os . path . relpath ( '../data/mainstreet_publictransport.xyz.txt' ) street_transport = np . genfromtxt ( street_transport_path , delimiter = ',' )","title":"Distance entrance"},{"location":"Scripts/distance_entrance/#euclidean-distance-lattice","text":"Distance matrix 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 # extracting the centroid of all voxels env_cens = envelope_lattice . centroids_threshold ( - 1 ) # initializing the distance matrix dist_m = [] # for each voxel ... for voxel_cen in env_cens : # initializing the distance vector (per each voxel) dist_v = [] # for each street point ... for street_transport_point in street_transport : # find the difference vector diff = voxel_cen - street_transport_point # raise the components to the power of two diff_p2 = diff ** 2 # sum the components diff_p2s = diff_p2 . sum () # compute the square root dist = diff_p2s ** 0.5 # add the distance to the distance vector dist_v . append ( dist ) # add the distance vector to the distance matrix dist_m . append ( dist_v ) # change the distance matrix type, from list to array dist_m = np . array ( dist_m )","title":"Euclidean distance lattice"},{"location":"Scripts/distance_entrance/#selecting-entrance-voxel","text":"Finding min distance to street and public 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # average of the distances to each point per voxel av_dist = [] for str_trans_points in dist_m : # calculate av_dist by taking the sum of the distances and divide by the amount of street points av_dist_vox = str_trans_points . sum () / len ( street_transport ) av_dist . append ( av_dist_vox ) # Find the voxel with the minimum average distance min_dist = np . min ( av_dist ) # Find the index of this voxel min_index = np . argmin ( av_dist ) # get the 3d location min_index_3d = np . unravel_index ( min_index , envelope_lattice . shape )","title":"Selecting entrance voxel"},{"location":"Scripts/distance_entrance/#import-the-stencils","text":"Stencil horizontal 1 2 3 4 5 6 7 8 # creating neighborhood definition 1 (horizontal) stencil_1 = tg . create_stencil ( \"von_neumann\" , 0 , 1 ) # setting the indices stencil_1 . set_index ([ 0 , 0 , 0 ], 0 ) stencil_1 . set_index ([ 0 , - 1 , 0 ], 1 ) stencil_1 . set_index ([ 0 , 1 , 0 ], 1 ) stencil_1 . set_index ([ - 1 , 0 , 0 ], 1 ) stencil_1 . set_index ([ 1 , 0 , 0 ], 1 ) Stencil vertical 1 2 3 4 5 6 # creating neighborhood definition 2 (vertical) stencil_2 = tg . create_stencil ( \"von_neumann\" , 0 , 1 ) # setting the indices stencil_2 . set_index ([ 0 , 0 , 0 ], 0 ) stencil_2 . set_index ([ 0 , 0 , - 1 ], 1 ) stencil_2 . set_index ([ 0 , 0 , 1 ], 1 )","title":"Import the stencils"},{"location":"Scripts/distance_entrance/#make-envelope-padded","text":"1 2 3 4 5 6 7 8 9 # make envelope padded to prevent seeing one side as a neighbour of the other side env_padded_array = np . pad ( envelope_lattice , 1 ) padded_minbound = envelope_lattice . minbound - envelope_lattice . unit env_padded_lattice = tg . to_lattice ( env_padded_array , minbound = padded_minbound , unit = envelope_lattice . unit ) # convert the location of the main entrance to the right envelope str_con_lattice = env_padded_lattice * False ent_sel_3d_ind_padded = tuple ( np . array ( np . unravel_index ( min_index , envelope_lattice . shape )) + 1 ) str_con_lattice [ ent_sel_3d_ind_padded ] = True","title":"Make envelope padded"},{"location":"Scripts/distance_entrance/#distance-lattice","text":"Retrieve neighbours 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 # retrieve the neighbour list of each cell neighs_1 = str_con_lattice . find_neighbours ( stencil_1 ) neighs_2 = str_con_lattice . find_neighbours ( stencil_2 ) # set the maximum distance to sum of the size of the lattice in all dimensions. max_dist = np . sum ( str_con_lattice . shape ) # initialize the street network distance lattice with all the street cells as 0, and all other cells as maximum distance possible mn_dist_lattice = 1 - str_con_lattice mn_dist_lattice [ mn_dist_lattice == 1 ] = max_dist # flatten the distance lattice for easy access mn_dist_lattice_flat = mn_dist_lattice . flatten () # flatten the envelope lattice env_pad_lat_flat = env_padded_lattice . flatten () Giving every voxel values 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 # main loop for breath-first traversal for i in range ( 1 , max_dist ): # find the neighbours of the previous step next_step_1 = neighs_1 [ mn_dist_lattice_flat == i - 1 ] # find the unique neighbours next_unq_step_1 = np . unique ( next_step_1 . flatten ()) # check if the neighbours of the next step are inside the envelope validity_condition_1 = env_pad_lat_flat [ next_unq_step_1 ] # select the valid neighbours next_valid_step_1 = next_unq_step_1 [ validity_condition_1 ] # find the neighbours of the previous step next_step_2 = neighs_2 [ mn_dist_lattice_flat == i - 1 ] # find the unique neighbours next_unq_step_2 = np . unique ( next_step_2 . flatten ()) # check if the neighbours of the next step are inside the envelope validity_condition_2 = env_pad_lat_flat [ next_unq_step_2 ] # select the valid neighbours next_valid_step_2 = next_unq_step_2 [ validity_condition_2 ] # make a copy of the lattice to prevent overwriting in the memory mn_nex_dist_lattice_flat = np . copy ( mn_dist_lattice_flat ) # set the next step cells to the current distance mn_nex_dist_lattice_flat [ next_valid_step_2 ] = i + 1 # set the next step cells to the current distance mn_nex_dist_lattice_flat [ next_valid_step_1 ] = i # find the minimum of the current distance and previous distances to avoid overwriting previous steps mn_dist_lattice_flat = np . minimum ( mn_dist_lattice_flat , mn_nex_dist_lattice_flat ) # check how many of the cells have not been traversed yet filled_check = mn_dist_lattice_flat * env_pad_lat_flat == max_dist # if all the cells have been traversed, break the loop if filled_check . sum () == 0 : print ( i ) break # reshape and construct a lattice from the street network distance list mn_dist_lattice = mn_dist_lattice_flat . reshape ( mn_dist_lattice . shape ) mn_dist_lattice = mn_dist_lattice . astype ( float ) mn_dist_lattice *= env_padded_lattice # reverse the lattice values (1 = close, 0 = far) mn_dist_lattice = env_padded_lattice - ( mn_dist_lattice - mn_dist_lattice . min ()) / mn_dist_lattice . max ()","title":"Distance lattice"},{"location":"Scripts/distance_entrance/#visualize-distance-lattice","text":"1 f . visualize ( mn_dist_lattice , \"Entrance distance\" , \"../data/distance_field.png\" ) Write distance lattice to csv 1 2 3 # write distance lattice to csv csv_path = os . path . relpath ( \"../data/field_distance_entrance.csv\" ) mn_dist_lattice . to_csv ( csv_path )","title":"Visualize distance lattice"},{"location":"Scripts/distance_entrance/#interpolate-lowres-lattice-to-highres","text":"1 2 3 # loading highres lattice highres_lattice_path = os . path . relpath ( '../data/envelope_highres.csv' ) highres_lattice = tg . lattice_from_csv ( highres_lattice_path ) Define interpolation function 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 def interpolate ( lowres_field ): # loading highres lattice highres_lattice_path = os . path . relpath ( '../data/envelope_highres.csv' ) highres_lat = tg . lattice_from_csv ( highres_lattice_path ) highres_lattice = highres_lat * 0 + 1 # line spaces x_space = np . linspace ( lowres_field . minbound [ 0 ], lowres_field . maxbound [ 0 ], lowres_field . shape [ 0 ]) y_space = np . linspace ( lowres_field . minbound [ 1 ], lowres_field . maxbound [ 1 ], lowres_field . shape [ 1 ]) z_space = np . linspace ( lowres_field . minbound [ 2 ], lowres_field . maxbound [ 2 ], lowres_field . shape [ 2 ]) # interpolation function interpolating_function = RegularGridInterpolator (( x_space , y_space , z_space ), lowres_field , bounds_error = False , fill_value = None ) # high_res lattice full_lattice = highres_lattice + 1 # sample point sample_points = full_lattice . centroids # interpolation interpolated_values = interpolating_function ( sample_points ) # lattice construction interpolated_lattice = tg . to_lattice ( interpolated_values . reshape ( highres_lattice . shape ), highres_lattice ) # nulling the unavailable cells interpolated_lattice *= highres_lattice return interpolated_lattice Interpolate closeness lattice 1 2 3 # Interpolate from lowres to highres highres_entrance = interpolate ( mn_dist_lattice ) highres_entrance_lattice = highres_entrance * highres_lattice Save interpolated field to csv 1 2 3 # save the interpolated distance field to csv csv_path = os . path . relpath ( \"../data/ent_acc.csv\" ) highres_entrance_lattice . to_csv ( csv_path ) Visualize highres field 1 f . visualize ( highres_entrance , \"Entrance distance\" , \"../data/ent_acc_highres.png\" )","title":"Interpolate lowres lattice to highres"},{"location":"Scripts/distance_entrance/#generate-configuration","text":"Set conditions for the voxels 1 2 3 # this is an example configuration of looking only at the distance to the entrance highres_entrance_minmax = ( highres_entrance_lattice > 0.5 ) * ( highres_entrance_lattice != 0 ) highres_entrance_minmax . sum () Visualize the conditioned voxels 1 2 3 base_lattice = highres_entrance_minmax * highres_entrance_lattice f . visualize ( base_lattice , \"Entrance distance\" , \"distance_field_conf.png\" ) Save configuration to csv 1 2 3 # save the configuration to csv csv_path = os . path . relpath ( \"../data/configuration_distance_entrance.csv\" ) highres_entrance_minmax . to_csv ( csv_path )","title":"Generate configuration"},{"location":"Scripts/distance_entrance/#credits","text":"1 2 3 4 5 __author__ = \"Shervin Azadi\" __license__ = \"MIT\" __version__ = \"1.0\" __url__ = \"https://github.com/shervinazadi/earthy_workshops\" __summary__ = \"Earthy Design Studio\"","title":"Credits"},{"location":"Scripts/distance_floor/","text":"Distance floor Import packages 1 2 3 4 5 6 7 8 9 10 import os import topogenesis as tg import pyvista as pv import trimesh as tm import numpy as np import networkx as nx from scipy.interpolate import RegularGridInterpolator import copy import resources.functions as f Import lattice 1 2 3 lattice_path = os . path . relpath ( \"../data/voxelized_envelope_lowres.csv\" ) envelope_lattice = tg . lattice_from_csv ( lattice_path ) full_lattice = envelope_lattice * 0 + 1 Create distance lattice Creat vertical adjacency matrix 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 # get the amount of voxels in the z direction vox_count = len ( full_lattice [ 0 ][ 0 ]) # initialize an adjacency matrix adj_mtrx = np . zeros (( vox_count , vox_count )) # set the connecting values of the adjacency matrix to 1 for i in range ( vox_count ): if i == 0 : adj_mtrx [ i , i + 1 ] = 1 continue if i == vox_count - 1 : adj_mtrx [ i , i - 1 ] = 1 continue else : adj_mtrx [ i , i + 1 ] = 1 adj_mtrx [ i , i - 1 ] = 1 Turning into networkx datastructure and calculating distances 1 2 g = nx . from_numpy_array ( adj_mtrx ) dist_mtrx_vertical = nx . floyd_warshall_numpy ( g ) Selecting floor level and mapping distances between 0 and 1 1 2 3 4 5 floor_dist = dist_mtrx_vertical [ 0 - 4 ] # specified floor level max_valid = np . ma . masked_invalid ( floor_dist ) . max () # find max distance floor_dist_mapped = 1 - ( floor_dist / max_valid ) # map values between 0 and 1 with max distance Mapping the values to the full latice 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 floor_dist_mapped_full = [] height = len ( floor_dist_mapped ) # mapping the colomn of values to the full lattice for i in range ( len ( full_lattice ) * len ( full_lattice [ 0 ]) * len ( full_lattice [ 0 ][ 0 ])): floor_dist_mapped_full . append ( floor_dist_mapped [ i % height ]) # turning it into an np array floor_dist_mapped_full = np . array ( floor_dist_mapped_full ) # reshaping the array floor_dist_lattice_full = floor_dist_mapped_full . reshape ( full_lattice . shape ) # forming the lattice to the solar envelope floor_dist_lattice = floor_dist_lattice_full * full_lattice Visualize the floor level lattice 1 2 base_lattice = floor_dist_lattice * envelope_lattice f . visualize ( base_lattice , \"Ground floor closeness\" , \"../data/ground_dist_lowres.png\" ) Export to csv 1 2 3 4 5 floor_dist = floor_dist_lattice * envelope_lattice # save the lowres distance field to csv csv_path = os . path . relpath ( '../data/ground_field_lowres.csv' ) floor_dist . to_csv ( csv_path ) Interpolate lowres to highres Define interpolation function 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 def interpolate ( lowres_field ): # loading highres lattice highres_lattice_path = os . path . relpath ( '../data/envelope_highres.csv' ) highres_lattice = tg . lattice_from_csv ( highres_lattice_path ) # line spaces x_space = np . linspace ( lowres_field . minbound [ 0 ], lowres_field . maxbound [ 0 ], lowres_field . shape [ 0 ]) y_space = np . linspace ( lowres_field . minbound [ 1 ], lowres_field . maxbound [ 1 ], lowres_field . shape [ 1 ]) z_space = np . linspace ( lowres_field . minbound [ 2 ], lowres_field . maxbound [ 2 ], lowres_field . shape [ 2 ]) # interpolation function interpolating_function = RegularGridInterpolator (( x_space , y_space , z_space ), lowres_field , bounds_error = False , fill_value = None ) # high_res lattice full_lattice = highres_lattice + 1 # sample point sample_points = full_lattice . centroids # interpolation interpolated_values = interpolating_function ( sample_points ) # lattice construction interpolated_lattice = tg . to_lattice ( interpolated_values . reshape ( highres_lattice . shape ), highres_lattice ) # nulling the unavailable cells interpolated_lattice *= highres_lattice return interpolated_lattice Interpolate closeness lattice 1 2 3 4 5 6 7 8 # Import the highres envelope highres_lattice_path = os . path . relpath ( '../data/envelope_highres.csv' ) highres_lattice = tg . lattice_from_csv ( highres_lattice_path ) # Interpolate from lowres to highres highres_ground_lattice = interpolate ( floor_dist_lattice ) # multiply by original highres_lattice to filter out the voxels outside the envelope highres_ground = highres_ground_lattice * highres_lattice Save interpolated field to csv 1 2 3 # save the interpolated distance field to csv csv_path = os . path . relpath ( \"../data/ground.csv\" ) highres_ground . to_csv ( csv_path ) Visualize highres field 1 f . visualize ( highres_ground , \"Ground floor closeness\" , \"../data/ground_acc_highres.png\" ) Credits 1 2 3 4 5 6 7 __author__ = \"Shervin Azadi\" __license__ = \"MIT\" __version__ = \"1.0\" __url__ = \"https://github.com/shervinazadi/earthy_workshops\" __summary__ = \"Earthy Design Studio\" Made with floor closeness notebook from group CUB3D","title":"Floor distance"},{"location":"Scripts/distance_floor/#distance-floor","text":"Import packages 1 2 3 4 5 6 7 8 9 10 import os import topogenesis as tg import pyvista as pv import trimesh as tm import numpy as np import networkx as nx from scipy.interpolate import RegularGridInterpolator import copy import resources.functions as f Import lattice 1 2 3 lattice_path = os . path . relpath ( \"../data/voxelized_envelope_lowres.csv\" ) envelope_lattice = tg . lattice_from_csv ( lattice_path ) full_lattice = envelope_lattice * 0 + 1","title":"Distance floor"},{"location":"Scripts/distance_floor/#create-distance-lattice","text":"Creat vertical adjacency matrix 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 # get the amount of voxels in the z direction vox_count = len ( full_lattice [ 0 ][ 0 ]) # initialize an adjacency matrix adj_mtrx = np . zeros (( vox_count , vox_count )) # set the connecting values of the adjacency matrix to 1 for i in range ( vox_count ): if i == 0 : adj_mtrx [ i , i + 1 ] = 1 continue if i == vox_count - 1 : adj_mtrx [ i , i - 1 ] = 1 continue else : adj_mtrx [ i , i + 1 ] = 1 adj_mtrx [ i , i - 1 ] = 1 Turning into networkx datastructure and calculating distances 1 2 g = nx . from_numpy_array ( adj_mtrx ) dist_mtrx_vertical = nx . floyd_warshall_numpy ( g ) Selecting floor level and mapping distances between 0 and 1 1 2 3 4 5 floor_dist = dist_mtrx_vertical [ 0 - 4 ] # specified floor level max_valid = np . ma . masked_invalid ( floor_dist ) . max () # find max distance floor_dist_mapped = 1 - ( floor_dist / max_valid ) # map values between 0 and 1 with max distance Mapping the values to the full latice 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 floor_dist_mapped_full = [] height = len ( floor_dist_mapped ) # mapping the colomn of values to the full lattice for i in range ( len ( full_lattice ) * len ( full_lattice [ 0 ]) * len ( full_lattice [ 0 ][ 0 ])): floor_dist_mapped_full . append ( floor_dist_mapped [ i % height ]) # turning it into an np array floor_dist_mapped_full = np . array ( floor_dist_mapped_full ) # reshaping the array floor_dist_lattice_full = floor_dist_mapped_full . reshape ( full_lattice . shape ) # forming the lattice to the solar envelope floor_dist_lattice = floor_dist_lattice_full * full_lattice Visualize the floor level lattice 1 2 base_lattice = floor_dist_lattice * envelope_lattice f . visualize ( base_lattice , \"Ground floor closeness\" , \"../data/ground_dist_lowres.png\" ) Export to csv 1 2 3 4 5 floor_dist = floor_dist_lattice * envelope_lattice # save the lowres distance field to csv csv_path = os . path . relpath ( '../data/ground_field_lowres.csv' ) floor_dist . to_csv ( csv_path )","title":"Create distance lattice"},{"location":"Scripts/distance_floor/#interpolate-lowres-to-highres","text":"Define interpolation function 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 def interpolate ( lowres_field ): # loading highres lattice highres_lattice_path = os . path . relpath ( '../data/envelope_highres.csv' ) highres_lattice = tg . lattice_from_csv ( highres_lattice_path ) # line spaces x_space = np . linspace ( lowres_field . minbound [ 0 ], lowres_field . maxbound [ 0 ], lowres_field . shape [ 0 ]) y_space = np . linspace ( lowres_field . minbound [ 1 ], lowres_field . maxbound [ 1 ], lowres_field . shape [ 1 ]) z_space = np . linspace ( lowres_field . minbound [ 2 ], lowres_field . maxbound [ 2 ], lowres_field . shape [ 2 ]) # interpolation function interpolating_function = RegularGridInterpolator (( x_space , y_space , z_space ), lowres_field , bounds_error = False , fill_value = None ) # high_res lattice full_lattice = highres_lattice + 1 # sample point sample_points = full_lattice . centroids # interpolation interpolated_values = interpolating_function ( sample_points ) # lattice construction interpolated_lattice = tg . to_lattice ( interpolated_values . reshape ( highres_lattice . shape ), highres_lattice ) # nulling the unavailable cells interpolated_lattice *= highres_lattice return interpolated_lattice Interpolate closeness lattice 1 2 3 4 5 6 7 8 # Import the highres envelope highres_lattice_path = os . path . relpath ( '../data/envelope_highres.csv' ) highres_lattice = tg . lattice_from_csv ( highres_lattice_path ) # Interpolate from lowres to highres highres_ground_lattice = interpolate ( floor_dist_lattice ) # multiply by original highres_lattice to filter out the voxels outside the envelope highres_ground = highres_ground_lattice * highres_lattice Save interpolated field to csv 1 2 3 # save the interpolated distance field to csv csv_path = os . path . relpath ( \"../data/ground.csv\" ) highres_ground . to_csv ( csv_path ) Visualize highres field 1 f . visualize ( highres_ground , \"Ground floor closeness\" , \"../data/ground_acc_highres.png\" )","title":"Interpolate lowres to highres"},{"location":"Scripts/distance_floor/#credits","text":"1 2 3 4 5 6 7 __author__ = \"Shervin Azadi\" __license__ = \"MIT\" __version__ = \"1.0\" __url__ = \"https://github.com/shervinazadi/earthy_workshops\" __summary__ = \"Earthy Design Studio\" Made with floor closeness notebook from group CUB3D","title":"Credits"},{"location":"Scripts/dynamic_fields/","text":"Dynamic Fields Kopjes toevoegen Import Dynamic_fields.ipynb 1 2 3 4 5 6 7 import os import topogenesis as tg import pyvista as pv import trimesh as tm import pandas as pd import numpy as np import copy 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 def distance_field ( occ_lattice , env_lattice , a_id ): # creating neighborhood definition 1 stencil = tg . create_stencil ( \"von_neumann\" , 1 , 1 ) # setting the indices stencil . set_index ([ 0 , 0 , 0 ], 0 ) occ_array_padded = np . pad ( occ_lattice , 1 , mode = \"constant\" , constant_values =- 1 ) env_array_padded = np . pad ( env_lattice , 1 , mode = \"constant\" , constant_values = False ) padded_minbound = env_lattice . minbound - env_lattice . unit env_lattice_padded = tg . to_lattice ( env_array_padded , minbound = padded_minbound , unit = env_lattice . unit ) occ_lattice_padded = tg . to_lattice ( occ_array_padded , minbound = padded_minbound , unit = env_lattice . unit ) distance_lattice = env_lattice_padded * False a_voexls_3d_ind_padded = tuple ( np . argwhere ( occ_lattice_padded == a_id ) . T + 1 ) # print(a_voexls_3d_ind_padded) distance_lattice [ a_voexls_3d_ind_padded ] = True # retrieve the neighbour list of each cell neighs = distance_lattice . find_neighbours ( stencil ) # set the maximum distance to sum of the size of the lattice in all dimensions. max_dist = np . sum ( distance_lattice . shape ) # initialize the street network distance lattice with all the street cells as 0, and all other cells as maximum distance possible mn_dist_lattice = 1 - distance_lattice mn_dist_lattice [ mn_dist_lattice == 1 ] = max_dist # flatten the distance lattice for easy access mn_dist_lattice_flat = mn_dist_lattice . flatten () # flatten the envelope lattice env_pad_lat_flat = env_lattice_padded . flatten () # main loop for breath-first traversal for i in range ( 1 , max_dist ): # find the neighbours of the previous step next_step = neighs [ mn_dist_lattice_flat == i - 1 ] # find the unique neighbours next_unq_step = np . unique ( next_step . flatten ()) # check if the neighbours of the next step are inside the envelope validity_condition = env_pad_lat_flat [ next_unq_step ] # select the valid neighbours next_valid_step = next_unq_step [ validity_condition ] # make a copy of the lattice to prevent overwriting in the memory mn_nex_dist_lattice_flat = np . copy ( mn_dist_lattice_flat ) # set the next step cells to the current distance mn_nex_dist_lattice_flat [ next_valid_step ] = i # find the minimum of the current distance and previous distances to avoid overwriting previous steps mn_dist_lattice_flat = np . minimum ( mn_dist_lattice_flat , mn_nex_dist_lattice_flat ) # check how many of the cells have not been traversed yet filled_check = mn_dist_lattice_flat * env_pad_lat_flat == max_dist # if all the cells have been traversed, break the loop if filled_check . sum () == 0 : # print(i) break # reshape and construct a lattice from the street network distance list mn_dist_lattice = mn_dist_lattice_flat . reshape ( mn_dist_lattice . shape ) mn_dist_lattice = mn_dist_lattice . astype ( float ) mn_dist_lattice *= env_lattice_padded mn_dist_lattice = env_lattice_padded - ( mn_dist_lattice - mn_dist_lattice . min ()) / mn_dist_lattice . max () return mn_dist_lattice","title":"Dynamic"},{"location":"Scripts/dynamic_fields/#dynamic-fields","text":"","title":"Dynamic Fields"},{"location":"Scripts/dynamic_fields/#kopjes-toevoegen","text":"Import Dynamic_fields.ipynb 1 2 3 4 5 6 7 import os import topogenesis as tg import pyvista as pv import trimesh as tm import pandas as pd import numpy as np import copy 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 def distance_field ( occ_lattice , env_lattice , a_id ): # creating neighborhood definition 1 stencil = tg . create_stencil ( \"von_neumann\" , 1 , 1 ) # setting the indices stencil . set_index ([ 0 , 0 , 0 ], 0 ) occ_array_padded = np . pad ( occ_lattice , 1 , mode = \"constant\" , constant_values =- 1 ) env_array_padded = np . pad ( env_lattice , 1 , mode = \"constant\" , constant_values = False ) padded_minbound = env_lattice . minbound - env_lattice . unit env_lattice_padded = tg . to_lattice ( env_array_padded , minbound = padded_minbound , unit = env_lattice . unit ) occ_lattice_padded = tg . to_lattice ( occ_array_padded , minbound = padded_minbound , unit = env_lattice . unit ) distance_lattice = env_lattice_padded * False a_voexls_3d_ind_padded = tuple ( np . argwhere ( occ_lattice_padded == a_id ) . T + 1 ) # print(a_voexls_3d_ind_padded) distance_lattice [ a_voexls_3d_ind_padded ] = True # retrieve the neighbour list of each cell neighs = distance_lattice . find_neighbours ( stencil ) # set the maximum distance to sum of the size of the lattice in all dimensions. max_dist = np . sum ( distance_lattice . shape ) # initialize the street network distance lattice with all the street cells as 0, and all other cells as maximum distance possible mn_dist_lattice = 1 - distance_lattice mn_dist_lattice [ mn_dist_lattice == 1 ] = max_dist # flatten the distance lattice for easy access mn_dist_lattice_flat = mn_dist_lattice . flatten () # flatten the envelope lattice env_pad_lat_flat = env_lattice_padded . flatten () # main loop for breath-first traversal for i in range ( 1 , max_dist ): # find the neighbours of the previous step next_step = neighs [ mn_dist_lattice_flat == i - 1 ] # find the unique neighbours next_unq_step = np . unique ( next_step . flatten ()) # check if the neighbours of the next step are inside the envelope validity_condition = env_pad_lat_flat [ next_unq_step ] # select the valid neighbours next_valid_step = next_unq_step [ validity_condition ] # make a copy of the lattice to prevent overwriting in the memory mn_nex_dist_lattice_flat = np . copy ( mn_dist_lattice_flat ) # set the next step cells to the current distance mn_nex_dist_lattice_flat [ next_valid_step ] = i # find the minimum of the current distance and previous distances to avoid overwriting previous steps mn_dist_lattice_flat = np . minimum ( mn_dist_lattice_flat , mn_nex_dist_lattice_flat ) # check how many of the cells have not been traversed yet filled_check = mn_dist_lattice_flat * env_pad_lat_flat == max_dist # if all the cells have been traversed, break the loop if filled_check . sum () == 0 : # print(i) break # reshape and construct a lattice from the street network distance list mn_dist_lattice = mn_dist_lattice_flat . reshape ( mn_dist_lattice . shape ) mn_dist_lattice = mn_dist_lattice . astype ( float ) mn_dist_lattice *= env_lattice_padded mn_dist_lattice = env_lattice_padded - ( mn_dist_lattice - mn_dist_lattice . min ()) / mn_dist_lattice . max () return mn_dist_lattice","title":"Kopjes toevoegen"},{"location":"Scripts/functions/","text":"Functions Kopjes toevoegen Import ``` python linenums=\"1\" import os import topogenesis as tg import pyvista as pv import trimesh as tm import numpy as np import networkx as nx from scipy.interpolate import RegularGridInterpolator import matplotlib.pyplot as plt convert mesh to pv_mesh def tri_to_pv(tri_mesh): faces = np.pad(tri_mesh.faces, ((0, 0),(1,0)), 'constant', constant_values=3) pv_mesh = pv.PolyData(tri_mesh.vertices, faces) return pv_mesh def visualize(object_to_visualize, title, name_save): # load the context mesh context_path = os.path.relpath('../data/immediate_context.obj') context_mesh = tm.load(context_path) pv . set_plot_theme ( \"document\" ) # initiating the plotter p = pv . Plotter ( notebook = True ) # Create the spatial reference grid = pv . UniformGrid () # Set the grid dimensions : shape because we want to inject our values grid . dimensions = object_to_visualize . shape # The bottom left corner of the data set grid . origin = object_to_visualize . minbound # These are the cell sizes along each axis grid . spacing = object_to_visualize . unit # Add the data values to the cell data grid . point_arrays [ title ] = object_to_visualize . flatten ( order = \"F\" ) # Flatten the Lattice # adding the meshes p . add_mesh ( tri_to_pv ( context_mesh ), opacity = 0.1 , style = 'wireframe' ) # adding the volume opacity = np . array ( [ 0,0.6,0.6,0.6,0.6,0.6,0.6 ] ) p . add_volume ( grid , cmap = \"coolwarm\" , opacity = opacity , shade = False ) p . show ( screenshot = name_save ) def save_image(object_to_visualize, title, name_save): # load the context mesh context_path = os.path.relpath('../data/immediate_context.obj') context_mesh = tm.load(context_path) pv . set_plot_theme ( \"document\" ) # initiating the plotter p = pv . Plotter ( notebook = True ) # Create the spatial reference grid = pv . UniformGrid () # Set the grid dimensions : shape because we want to inject our values grid . dimensions = object_to_visualize . shape # The bottom left corner of the data set grid . origin = object_to_visualize . minbound # These are the cell sizes along each axis grid . spacing = object_to_visualize . unit # Add the data values to the cell data grid . point_arrays [ title ] = object_to_visualize . flatten ( order = \"F\" ) # Flatten the Lattice # adding the meshes p . add_mesh ( tri_to_pv ( context_mesh ), opacity = 0.1 , style = 'wireframe' ) # adding the volume opacity = np . array ( [ 0,0.6,0.6,0.6,0.6,0.6,0.6 ] ) p . add_volume ( grid , cmap = \"coolwarm\" , opacity = opacity , shade = False ) p . screenshot ( name_save ) def save_image_lattice(object_to_visualize, title, name_save, program): pv.set_plot_theme(\"document\") p = pv.Plotter(notebook=True) # Set the grid dimensions : shape + 1 because we want to inject our values on the CELL data grid = pv . UniformGrid () grid . dimensions = np . array ( object_to_visualize . shape ) + 1 # The bottom left corner of the data set grid . origin = object_to_visualize . minbound - object_to_visualize . unit * 0.5 # These are the cell sizes along each axis grid . spacing = object_to_visualize . unit # adding the boundingbox wireframe p . add_mesh ( grid . outline (), color = \"grey\" , label = \"Domain\" ) # adding axes p . add_axes () p . show_bounds ( grid = \"back\" , location = \"back\" , color = \"#777777\" ) # Add the data values to the cell data grid . cell_arrays [ title ] = object_to_visualize . flatten ( order = \"F\" ). astype ( int ) # Flatten the array ! # filtering the voxels agn_num = len ( program ) threshed = grid . threshold ( [ -0.1, agn_num - 0.9 ] ) # adding the voxels p . add_mesh ( threshed , show_edges = True , opacity = 1.0 , show_scalar_bar = False ) p . screenshot ( name_save ) ```","title":"Functions"},{"location":"Scripts/functions/#functions","text":"","title":"Functions"},{"location":"Scripts/functions/#kopjes-toevoegen","text":"Import ``` python linenums=\"1\" import os import topogenesis as tg import pyvista as pv import trimesh as tm import numpy as np import networkx as nx from scipy.interpolate import RegularGridInterpolator import matplotlib.pyplot as plt","title":"Kopjes toevoegen"},{"location":"Scripts/functions/#convert-mesh-to-pv_mesh","text":"def tri_to_pv(tri_mesh): faces = np.pad(tri_mesh.faces, ((0, 0),(1,0)), 'constant', constant_values=3) pv_mesh = pv.PolyData(tri_mesh.vertices, faces) return pv_mesh def visualize(object_to_visualize, title, name_save): # load the context mesh context_path = os.path.relpath('../data/immediate_context.obj') context_mesh = tm.load(context_path) pv . set_plot_theme ( \"document\" ) # initiating the plotter p = pv . Plotter ( notebook = True ) # Create the spatial reference grid = pv . UniformGrid () # Set the grid dimensions : shape because we want to inject our values grid . dimensions = object_to_visualize . shape # The bottom left corner of the data set grid . origin = object_to_visualize . minbound # These are the cell sizes along each axis grid . spacing = object_to_visualize . unit # Add the data values to the cell data grid . point_arrays [ title ] = object_to_visualize . flatten ( order = \"F\" ) # Flatten the Lattice # adding the meshes p . add_mesh ( tri_to_pv ( context_mesh ), opacity = 0.1 , style = 'wireframe' ) # adding the volume opacity = np . array ( [ 0,0.6,0.6,0.6,0.6,0.6,0.6 ] ) p . add_volume ( grid , cmap = \"coolwarm\" , opacity = opacity , shade = False ) p . show ( screenshot = name_save ) def save_image(object_to_visualize, title, name_save): # load the context mesh context_path = os.path.relpath('../data/immediate_context.obj') context_mesh = tm.load(context_path) pv . set_plot_theme ( \"document\" ) # initiating the plotter p = pv . Plotter ( notebook = True ) # Create the spatial reference grid = pv . UniformGrid () # Set the grid dimensions : shape because we want to inject our values grid . dimensions = object_to_visualize . shape # The bottom left corner of the data set grid . origin = object_to_visualize . minbound # These are the cell sizes along each axis grid . spacing = object_to_visualize . unit # Add the data values to the cell data grid . point_arrays [ title ] = object_to_visualize . flatten ( order = \"F\" ) # Flatten the Lattice # adding the meshes p . add_mesh ( tri_to_pv ( context_mesh ), opacity = 0.1 , style = 'wireframe' ) # adding the volume opacity = np . array ( [ 0,0.6,0.6,0.6,0.6,0.6,0.6 ] ) p . add_volume ( grid , cmap = \"coolwarm\" , opacity = opacity , shade = False ) p . screenshot ( name_save ) def save_image_lattice(object_to_visualize, title, name_save, program): pv.set_plot_theme(\"document\") p = pv.Plotter(notebook=True) # Set the grid dimensions : shape + 1 because we want to inject our values on the CELL data grid = pv . UniformGrid () grid . dimensions = np . array ( object_to_visualize . shape ) + 1 # The bottom left corner of the data set grid . origin = object_to_visualize . minbound - object_to_visualize . unit * 0.5 # These are the cell sizes along each axis grid . spacing = object_to_visualize . unit # adding the boundingbox wireframe p . add_mesh ( grid . outline (), color = \"grey\" , label = \"Domain\" ) # adding axes p . add_axes () p . show_bounds ( grid = \"back\" , location = \"back\" , color = \"#777777\" ) # Add the data values to the cell data grid . cell_arrays [ title ] = object_to_visualize . flatten ( order = \"F\" ). astype ( int ) # Flatten the array ! # filtering the voxels agn_num = len ( program ) threshed = grid . threshold ( [ -0.1, agn_num - 0.9 ] ) # adding the voxels p . add_mesh ( threshed , show_edges = True , opacity = 1.0 , show_scalar_bar = False ) p . screenshot ( name_save ) ```","title":"convert mesh to pv_mesh"},{"location":"Scripts/green_view/","text":"View on greenery Initalization Importing the packages 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 import os import topogenesis as tg import pyvista as pv import trimesh as tm import numpy as np import pickle from ladybug.sunpath import Sunpath from scipy.interpolate import RegularGridInterpolator from pathlib import Path import resources.functions as f # convert trimesh to pv_mesh def tri_to_pv ( tri_mesh ): faces = np . pad ( tri_mesh . faces , (( 0 , 0 ),( 1 , 0 )), 'constant' , constant_values = 3 ) pv_mesh = pv . PolyData ( tri_mesh . vertices , faces ) return pv_mesh Importing meshes 1 2 3 4 5 6 7 8 9 envelope_path = os . path . relpath ( \"../data/new_envelope.obj\" ) context_path = os . path . relpath ( \"../data/immediate_context.obj\" ) # load the mesh from file envelope_mesh = tm . load ( envelope_path ) context_mesh = tm . load ( context_path ) # Check if the mesh is watertight print ( envelope_mesh . is_watertight ) Importing envelope lattice 1 2 3 4 5 6 # loading the lattice from csv lattice_path = os . path . relpath ( \"../data/envelope_lowres.csv\" ) envelope_lattice = tg . lattice_from_csv ( lattice_path ) # creating the full lattice full_lattice = envelope_lattice * 0 + 1 Importing greenery mesh and points 1 2 3 4 5 6 green_path = os . path . relpath ( \"../data/green_agniesbuurt_rotatedpopgeo_nostumps.obj\" ) green_points_path = os . path . relpath ( \"../data/green_points.csv\" ) # load the mesh from file green_mesh = tm . load ( green_path ) green_points = tg . cloud_from_csv ( green_points_path ) Visualize greenery Visualize green meshes 1 2 3 4 5 6 7 8 9 10 11 12 13 14 pv . set_plot_theme ( \"document\" ) # initiating the plotter p = pv . Plotter ( notebook = True ) # adding the meshes p . add_mesh ( tri_to_pv ( envelope_mesh ), color = '#abd8ff' ) p . add_mesh ( tri_to_pv ( context_mesh ), opacity = 0.1 , style = 'wireframe' ) #trying the green p . add_mesh ( tri_to_pv ( green_mesh ), color = \"#8bbe8f\" , style = 'wireframe' ) # plotting #p.show(use_ipyvtk=True) Visualize green points 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # initiating the plotter p = pv . Plotter ( notebook = True ) pv . set_plot_theme ( \"document\" ) # fast visualization of the lattice full_lattice . fast_vis ( p ) # adding the context mesh p . add_mesh ( tri_to_pv ( context_mesh ), opacity = 0.1 , style = 'wireframe' ) # add the green points p . add_mesh ( green_points , color = \"#8bbe8f\" , show_edges = False , lighting = False ) #p.show(use_ipyvtk=True) Compute rays from green points to envelope Preparing the list of ray directions and origins 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 # Creating list of directions and rays converted_green_vecs = green_points . astype ( 'float16' ) green_dirs2 = np . array ( converted_green_vecs ) vox_cens = full_lattice . centroids ray_dir3 = [] ray_src3 = [] for v_cen in vox_cens : for gp in converted_green_vecs : ray_src3 . append ( v_cen ) ray_dir3 . append ( gp - v_cen ) # converting the list of directions and sources to numpy array ray_dir3 = np . array ( ray_dir3 ) ray_src3 = np . array ( ray_src3 ) # checking how many calculations to do print ( \"number of voxels to shoot rays from :\" , vox_cens . shape ) print ( \"number of rays per each voxel :\" , green_dirs2 . shape ) print ( \"number of rays to be shot :\" , ray_src3 . shape ) Import the pickle files with calculations 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 # the calculation is too big for a normal computer # the calculation has been done on a better computer and imported as pickle files bs = 1e5 d = '../data/sims' ray_id3 = [] int_loc3 = [] for i in range ( int ( len ( ray_src3 ) / bs ) + 1 ): # s = int(i * bs) # e = int((i + 1) * bs) # e = e if e < len(ray_src3) else len(ray_src3) - 1 with open ( f ' { d } /green_ { i } .pickle' , 'rb' ) as file : _ , r , l = pickle . load ( file ) ray_id3 . append ( r + int ( i * bs )) int_loc3 . append ( l ) ray_id3 = np . concatenate ( ray_id3 ) int_loc3 = np . concatenate ( int_loc3 ) Reshape the information 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 # initializing the hits list full of zeros hits3 = [ 0 ] * len ( ray_dir3 ) hit_loc3 = [[ 0 , 0 , 0 ]] * len ( ray_dir3 ) for i , id in enumerate ( ray_id3 ): hits3 [ id ] = 1 hit_loc3 [ id ] = int_loc3 [ i ] gp_count = len ( green_dirs2 ) vox_count = len ( vox_cens ) # initiating the list of ratio vox_grn_vis = [] # iterate over the voxels for v_id in range ( vox_count ): # counter for the intersection int_count = 0 # iterate over the sun rays for s_id in range ( gp_count ): # computing the ray id from voxel id and sun id r_id = s_id + v_id * gp_count if hits3 [ r_id ]: # retrieve the ray origin ray_orig = ray_src3 [ r_id ] # retrieve the intersection point ray_dest = hit_loc3 [ r_id ] # retrieve the ray vector ray_vec = ray_dir3 [ r_id ] # the distance from origin to intersection point int_length = np . sum (( ray_dest - ray_orig ) ** 2 ) ** 0.5 # the distance from the origin to the green point ray_length = np . sum ( ray_vec ** 2 ) ** 0.5 # if the ray length is greater than the intersection length, it means that the view toward the green point is blocked if ray_length > int_length : # summing the intersections int_count += 1 # computing the percentage of the rays that DID NOT have # an intersection (aka could see the skydome) grn_vis = 1.0 - int_count / gp_count # add the ratio to list vox_grn_vis . append ( grn_vis ) # converting the list of directions and sources to numpy array vox_grn_vis = np . array ( vox_grn_vis ) Store green view information in a lattice 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 # getting the condition of all voxels: are they inside the envelop or not env_all_vox = full_lattice . flatten () # all voxels green view all_vox_grn_vis = [] # v_id: voxel id in the list of only interior voxels v_id = 0 # for all the voxels, place the interiority condition of each voxel in \"vox_in\" for vox_in in env_all_vox : # if the voxel was outside... if vox_in == True : # read its value of green view and append it to the list of all voxel green view all_vox_grn_vis . append ( vox_grn_vis [ v_id ]) # add one to the voxel id so the next time we read the next voxel v_id += 1 # if the voxel was not inside... else : # add 0.0 all_vox_grn_vis . append ( 0.0 ) # convert to array grn_vis_array = np . array ( all_vox_grn_vis ) # Further info: for vectorized version of this code check: https://github.com/shervinazadi/spatial_computing_workshops/blob/master/notebooks/w2_solar_envelope.ipynb # reshape to lattice shape grn_vis_array = grn_vis_array . reshape ( full_lattice . shape ) # convert to lattice grn_vis_lattice = tg . to_lattice ( grn_vis_array , full_lattice ) Visualize the view on greenery field 1 f . visualize ( grn_vis_lattice , \"Green visibility\" , \"../data/green_view_lowres\" ) Save lowres field to csv 1 2 3 # save the SVF latice to csv csv_path = os . path . relpath ( '../data/green_view_lowres.csv' ) grn_vis_lattice . to_csv ( csv_path ) Interpolate lowres lattices to highres Import highres lattice 1 2 3 # loading highres lattice highres_lattice_path = os . path . relpath ( '../data/envelope_highres.csv' ) highres_lattice = tg . lattice_from_csv ( highres_lattice_path ) Define interpolation function 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 def interpolate ( lowres_field ): # loading highres lattice highres_lattice_path = os . path . relpath ( '../data/envelope_highres.csv' ) highres_lat = tg . lattice_from_csv ( highres_lattice_path ) highres_lattice = highres_lat * 0 + 1 # line spaces x_space = np . linspace ( lowres_field . minbound [ 0 ], lowres_field . maxbound [ 0 ], lowres_field . shape [ 0 ]) y_space = np . linspace ( lowres_field . minbound [ 1 ], lowres_field . maxbound [ 1 ], lowres_field . shape [ 1 ]) z_space = np . linspace ( lowres_field . minbound [ 2 ], lowres_field . maxbound [ 2 ], lowres_field . shape [ 2 ]) # interpolation function interpolating_function = RegularGridInterpolator (( x_space , y_space , z_space ), lowres_field , bounds_error = False , fill_value = None ) # high_res lattice full_lattice = highres_lattice + 1 # sample point sample_points = full_lattice . centroids # interpolation interpolated_values = interpolating_function ( sample_points ) # lattice construction interpolated_lattice = tg . to_lattice ( interpolated_values . reshape ( highres_lattice . shape ), highres_lattice ) # nulling the unavailable cells interpolated_lattice *= highres_lattice return interpolated_lattice Interpolate greenery lattice 1 2 highres_grn = interpolate ( grn_vis_lattice ) highres_grn_lattice = highres_grn * highres_lattice Visualize highres green view field 1 f . visualize ( highres_grn , \"Green visibility\" , \"../data/green_view_highres.png\" ) Save highres field into a csv 1 2 3 # save the SVF latice to csv csv_path = os . path . relpath ( '../data/green_view.csv' ) highres_grn_lattice . to_csv ( csv_path ) Credits 1 2 3 4 5 __author__ = \"Shervin Azadi and Pirouz Nourian\" __license__ = \"MIT\" __version__ = \"1.0\" __url__ = \"https://github.com/shervinazadi/spatial_computing_workshops\" __summary__ = \"Spatial Computing Design Studio Workshop on Solar Envelope\"","title":"Green"},{"location":"Scripts/green_view/#view-on-greenery","text":"","title":"View on greenery"},{"location":"Scripts/green_view/#initalization","text":"Importing the packages 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 import os import topogenesis as tg import pyvista as pv import trimesh as tm import numpy as np import pickle from ladybug.sunpath import Sunpath from scipy.interpolate import RegularGridInterpolator from pathlib import Path import resources.functions as f # convert trimesh to pv_mesh def tri_to_pv ( tri_mesh ): faces = np . pad ( tri_mesh . faces , (( 0 , 0 ),( 1 , 0 )), 'constant' , constant_values = 3 ) pv_mesh = pv . PolyData ( tri_mesh . vertices , faces ) return pv_mesh Importing meshes 1 2 3 4 5 6 7 8 9 envelope_path = os . path . relpath ( \"../data/new_envelope.obj\" ) context_path = os . path . relpath ( \"../data/immediate_context.obj\" ) # load the mesh from file envelope_mesh = tm . load ( envelope_path ) context_mesh = tm . load ( context_path ) # Check if the mesh is watertight print ( envelope_mesh . is_watertight ) Importing envelope lattice 1 2 3 4 5 6 # loading the lattice from csv lattice_path = os . path . relpath ( \"../data/envelope_lowres.csv\" ) envelope_lattice = tg . lattice_from_csv ( lattice_path ) # creating the full lattice full_lattice = envelope_lattice * 0 + 1 Importing greenery mesh and points 1 2 3 4 5 6 green_path = os . path . relpath ( \"../data/green_agniesbuurt_rotatedpopgeo_nostumps.obj\" ) green_points_path = os . path . relpath ( \"../data/green_points.csv\" ) # load the mesh from file green_mesh = tm . load ( green_path ) green_points = tg . cloud_from_csv ( green_points_path )","title":"Initalization"},{"location":"Scripts/green_view/#visualize-greenery","text":"Visualize green meshes 1 2 3 4 5 6 7 8 9 10 11 12 13 14 pv . set_plot_theme ( \"document\" ) # initiating the plotter p = pv . Plotter ( notebook = True ) # adding the meshes p . add_mesh ( tri_to_pv ( envelope_mesh ), color = '#abd8ff' ) p . add_mesh ( tri_to_pv ( context_mesh ), opacity = 0.1 , style = 'wireframe' ) #trying the green p . add_mesh ( tri_to_pv ( green_mesh ), color = \"#8bbe8f\" , style = 'wireframe' ) # plotting #p.show(use_ipyvtk=True) Visualize green points 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # initiating the plotter p = pv . Plotter ( notebook = True ) pv . set_plot_theme ( \"document\" ) # fast visualization of the lattice full_lattice . fast_vis ( p ) # adding the context mesh p . add_mesh ( tri_to_pv ( context_mesh ), opacity = 0.1 , style = 'wireframe' ) # add the green points p . add_mesh ( green_points , color = \"#8bbe8f\" , show_edges = False , lighting = False ) #p.show(use_ipyvtk=True)","title":"Visualize greenery"},{"location":"Scripts/green_view/#compute-rays-from-green-points-to-envelope","text":"Preparing the list of ray directions and origins 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 # Creating list of directions and rays converted_green_vecs = green_points . astype ( 'float16' ) green_dirs2 = np . array ( converted_green_vecs ) vox_cens = full_lattice . centroids ray_dir3 = [] ray_src3 = [] for v_cen in vox_cens : for gp in converted_green_vecs : ray_src3 . append ( v_cen ) ray_dir3 . append ( gp - v_cen ) # converting the list of directions and sources to numpy array ray_dir3 = np . array ( ray_dir3 ) ray_src3 = np . array ( ray_src3 ) # checking how many calculations to do print ( \"number of voxels to shoot rays from :\" , vox_cens . shape ) print ( \"number of rays per each voxel :\" , green_dirs2 . shape ) print ( \"number of rays to be shot :\" , ray_src3 . shape ) Import the pickle files with calculations 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 # the calculation is too big for a normal computer # the calculation has been done on a better computer and imported as pickle files bs = 1e5 d = '../data/sims' ray_id3 = [] int_loc3 = [] for i in range ( int ( len ( ray_src3 ) / bs ) + 1 ): # s = int(i * bs) # e = int((i + 1) * bs) # e = e if e < len(ray_src3) else len(ray_src3) - 1 with open ( f ' { d } /green_ { i } .pickle' , 'rb' ) as file : _ , r , l = pickle . load ( file ) ray_id3 . append ( r + int ( i * bs )) int_loc3 . append ( l ) ray_id3 = np . concatenate ( ray_id3 ) int_loc3 = np . concatenate ( int_loc3 ) Reshape the information 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 # initializing the hits list full of zeros hits3 = [ 0 ] * len ( ray_dir3 ) hit_loc3 = [[ 0 , 0 , 0 ]] * len ( ray_dir3 ) for i , id in enumerate ( ray_id3 ): hits3 [ id ] = 1 hit_loc3 [ id ] = int_loc3 [ i ] gp_count = len ( green_dirs2 ) vox_count = len ( vox_cens ) # initiating the list of ratio vox_grn_vis = [] # iterate over the voxels for v_id in range ( vox_count ): # counter for the intersection int_count = 0 # iterate over the sun rays for s_id in range ( gp_count ): # computing the ray id from voxel id and sun id r_id = s_id + v_id * gp_count if hits3 [ r_id ]: # retrieve the ray origin ray_orig = ray_src3 [ r_id ] # retrieve the intersection point ray_dest = hit_loc3 [ r_id ] # retrieve the ray vector ray_vec = ray_dir3 [ r_id ] # the distance from origin to intersection point int_length = np . sum (( ray_dest - ray_orig ) ** 2 ) ** 0.5 # the distance from the origin to the green point ray_length = np . sum ( ray_vec ** 2 ) ** 0.5 # if the ray length is greater than the intersection length, it means that the view toward the green point is blocked if ray_length > int_length : # summing the intersections int_count += 1 # computing the percentage of the rays that DID NOT have # an intersection (aka could see the skydome) grn_vis = 1.0 - int_count / gp_count # add the ratio to list vox_grn_vis . append ( grn_vis ) # converting the list of directions and sources to numpy array vox_grn_vis = np . array ( vox_grn_vis ) Store green view information in a lattice 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 # getting the condition of all voxels: are they inside the envelop or not env_all_vox = full_lattice . flatten () # all voxels green view all_vox_grn_vis = [] # v_id: voxel id in the list of only interior voxels v_id = 0 # for all the voxels, place the interiority condition of each voxel in \"vox_in\" for vox_in in env_all_vox : # if the voxel was outside... if vox_in == True : # read its value of green view and append it to the list of all voxel green view all_vox_grn_vis . append ( vox_grn_vis [ v_id ]) # add one to the voxel id so the next time we read the next voxel v_id += 1 # if the voxel was not inside... else : # add 0.0 all_vox_grn_vis . append ( 0.0 ) # convert to array grn_vis_array = np . array ( all_vox_grn_vis ) # Further info: for vectorized version of this code check: https://github.com/shervinazadi/spatial_computing_workshops/blob/master/notebooks/w2_solar_envelope.ipynb # reshape to lattice shape grn_vis_array = grn_vis_array . reshape ( full_lattice . shape ) # convert to lattice grn_vis_lattice = tg . to_lattice ( grn_vis_array , full_lattice ) Visualize the view on greenery field 1 f . visualize ( grn_vis_lattice , \"Green visibility\" , \"../data/green_view_lowres\" ) Save lowres field to csv 1 2 3 # save the SVF latice to csv csv_path = os . path . relpath ( '../data/green_view_lowres.csv' ) grn_vis_lattice . to_csv ( csv_path )","title":"Compute rays from green points to envelope"},{"location":"Scripts/green_view/#interpolate-lowres-lattices-to-highres","text":"Import highres lattice 1 2 3 # loading highres lattice highres_lattice_path = os . path . relpath ( '../data/envelope_highres.csv' ) highres_lattice = tg . lattice_from_csv ( highres_lattice_path ) Define interpolation function 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 def interpolate ( lowres_field ): # loading highres lattice highres_lattice_path = os . path . relpath ( '../data/envelope_highres.csv' ) highres_lat = tg . lattice_from_csv ( highres_lattice_path ) highres_lattice = highres_lat * 0 + 1 # line spaces x_space = np . linspace ( lowres_field . minbound [ 0 ], lowres_field . maxbound [ 0 ], lowres_field . shape [ 0 ]) y_space = np . linspace ( lowres_field . minbound [ 1 ], lowres_field . maxbound [ 1 ], lowres_field . shape [ 1 ]) z_space = np . linspace ( lowres_field . minbound [ 2 ], lowres_field . maxbound [ 2 ], lowres_field . shape [ 2 ]) # interpolation function interpolating_function = RegularGridInterpolator (( x_space , y_space , z_space ), lowres_field , bounds_error = False , fill_value = None ) # high_res lattice full_lattice = highres_lattice + 1 # sample point sample_points = full_lattice . centroids # interpolation interpolated_values = interpolating_function ( sample_points ) # lattice construction interpolated_lattice = tg . to_lattice ( interpolated_values . reshape ( highres_lattice . shape ), highres_lattice ) # nulling the unavailable cells interpolated_lattice *= highres_lattice return interpolated_lattice Interpolate greenery lattice 1 2 highres_grn = interpolate ( grn_vis_lattice ) highres_grn_lattice = highres_grn * highres_lattice Visualize highres green view field 1 f . visualize ( highres_grn , \"Green visibility\" , \"../data/green_view_highres.png\" ) Save highres field into a csv 1 2 3 # save the SVF latice to csv csv_path = os . path . relpath ( '../data/green_view.csv' ) highres_grn_lattice . to_csv ( csv_path )","title":"Interpolate lowres lattices to highres"},{"location":"Scripts/green_view/#credits","text":"1 2 3 4 5 __author__ = \"Shervin Azadi and Pirouz Nourian\" __license__ = \"MIT\" __version__ = \"1.0\" __url__ = \"https://github.com/shervinazadi/spatial_computing_workshops\" __summary__ = \"Spatial Computing Design Studio Workshop on Solar Envelope\"","title":"Credits"},{"location":"Scripts/grow_agents/","text":"Initialize and grown agents (ABM) Load required libraries 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 # !pip install pyvista==0.28.1 ipyvtklink import os import topogenesis as tg import pyvista as pv import trimesh as tm import pandas as pd import numpy as np import copy import random from sklearn.cluster import KMeans np . random . seed ( 0 ) import resources.dynamic_fields as df import resources.functions as func # convert mesh to pv_mesh def tri_to_pv ( tri_mesh ): faces = np . pad ( tri_mesh . faces , (( 0 , 0 ),( 1 , 0 )), 'constant' , constant_values = 3 ) pv_mesh = pv . PolyData ( tri_mesh . vertices , faces ) return pv_mesh Define the neighborhood (stencil) Stencil: horizontal 1 2 3 4 5 6 7 8 9 10 11 # creating neighborhood definition 1 stencil = tg . create_stencil ( \"von_neumann\" , 1 , 1 ) # setting the indices stencil . set_index ([ 0 , 0 , 0 ], 0 ) # creating neighborhood definition 1 stencil_hor = tg . create_stencil ( \"von_neumann\" , 1 , 1 ) # setting the indices stencil_hor . set_index ([ 0 , 0 , 0 ], 0 ) stencil_hor . set_index ([ 0 , 0 , 1 ], 0 ) stencil_hor . set_index ([ 0 , 0 , - 1 ], 0 ) Setup the environment Load the envelope lattice as the availability lattice 1 2 3 4 5 6 7 8 9 10 11 # loading the lattice from csv lattice_path = os . path . relpath ( '../data/envelope_highres.csv' ) avail_lattice = tg . lattice_from_csv ( lattice_path ) init_avail_lattice = tg . to_lattice ( np . copy ( avail_lattice ), avail_lattice ) # loading the lattice from csv field_path = os . path . relpath ( \"../data/envelope_lowres.csv\" ) envelope_lattice = tg . lattice_from_csv ( field_path ) #init_avail_lattice = tg.to_lattice(np.copy(envelope_lattice), envelope_lattice) full_lattice = envelope_lattice * 0 + 1 Load program 1 2 3 4 5 6 7 8 program_full = pd . read_csv ( \"../data/program_req.csv\" ) #program_full program_complete = program_full . drop ([ \"vox_amount\" ], 1 ) #program_complete program_prefs = program_complete . drop ([ \"space_name\" , \"space_id\" ], 1 ) #program_prefs Load value fields 1 2 3 4 5 6 7 8 # loading the lattice from csv, when it is there fields = {} for f in program_full . columns : lattice_path = os . path . relpath ( '../data/' + f + '.csv' ) try : fields [ f ] = tg . lattice_from_csv ( lattice_path ) except : fields [ f ] = copy . deepcopy ( avail_lattice * 0 + 1 ) Initialize agents 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 def initialize_agents ( avail_lattice , program_prefs , fields ): # initialize the occupation lattice occ_lattice = avail_lattice * 0 - 1 # create a list for agents locations agn_locs = [] # for each agent origin ... for a_id , a_prefs in program_prefs . iterrows (): # create a preference lattice pref_lattice = ( avail_lattice * 0.0 + 1.0 ) * avail_lattice # choosing three available voxels for f , w in a_prefs . iteritems (): pref_lattice *= fields [ f ] ** w select_id = np . argmax ( pref_lattice ) a_origin_1 = np . unravel_index ( select_id , avail_lattice . shape ) # set the initialised agent to ground level, than later there will be no floating parts a_origin_2 = ( a_origin_1 [ 0 ], a_origin_1 [ 1 ], 1 ) # to prevent voxels from occupying the same place for n in range ( 5 ): if avail_lattice [ a_origin_2 ] == 0 : a_origin_2 = ( a_origin_1 [ 0 ], a_origin_1 [ 1 ], 1 + n ) # add the origin to the list of agent locations agn_locs . append ([ a_origin_2 ]) # set the origin in availablity lattice as 0 (UNavailable) avail_lattice [ a_origin_2 ] = 0 # set the origin in occupation lattice as the agent id (a_id) occ_lattice [ a_origin_2 ] = a_id return occ_lattice , agn_locs Save agents to csv 1 2 csv_path = os . path . relpath ( \"../data/initialized_agents.csv\" ) occ_lattice . to_csv ( csv_path ) Visualize initialized agents 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 pv . set_plot_theme ( \"document\" ) p = pv . Plotter ( notebook = True ) # Set the grid dimensions: shape + 1 because we want to inject our values on the CELL data grid = pv . UniformGrid () grid . dimensions = np . array ( occ_lattice . shape ) + 1 # The bottom left corner of the data set grid . origin = occ_lattice . minbound - occ_lattice . unit * 0.5 # These are the cell sizes along each axis grid . spacing = occ_lattice . unit # adding the boundingbox wireframe p . add_mesh ( grid . outline (), color = \"grey\" , label = \"Domain\" ) # adding axes p . add_axes () p . show_bounds ( grid = \"back\" , location = \"back\" , color = \"#777777\" ) # Add the data values to the cell data grid . cell_arrays [ \"Agents\" ] = occ_lattice . flatten ( order = \"F\" ) . astype ( int ) # Flatten the array! # filtering the voxels agn_num = len ( program_complete ) threshed = grid . threshold ([ - 0.1 , agn_num - 0.9 ]) # adding the voxels p . add_mesh ( threshed , show_edges = True , opacity = 1.0 , show_scalar_bar = False ) #p.show(use_ipyvtk=True) #p.show(screenshot=\"../data/init_agents.png\") ABM simulation 1 2 3 # make a dictionary from the max amount of voxels per space program_dict = program_full . to_dict () vox_am_program = program_dict [ \"vox_amount\" ] Functions for in the ABM simulation 1 2 3 4 5 6 7 8 9 10 11 12 13 def evaluate_voxels ( a_prefs , fns ): # find the value of neighbours # init the agent value array a_eval = np . ones ( len ( fns )) # for each field... for f in a_prefs . keys (): # find the raw value of free neighbours... vals = fields [ f ][ fns [:, 0 ], fns [:, 1 ], fns [:, 2 ]] # raise the the raw value to the power of preference weight of the agent a_weighted_vals = vals ** a_prefs [ f ] # multiply them to the previous weighted values a_eval *= a_weighted_vals return a_eval Function change value of a voxel 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # A defition to change the value of voxel in the avail_lattice and occ_lattice to occupied or not occupied (True = occupie, False = remove) def change_value ( occ_lattice , avail_lattice , id_3d , new_id , old_id = 0 , new_index_1d = 0 ): # set the newly selected neighbour as UNavailable (0) or available (1) in the availability lattice if new_id > - 1 : # find the location of the newly selected neighbour selected_neigh_loc = np . array ( id_3d ) . flatten () agn_locs [ new_id ] . append ( selected_neigh_loc ) avail_lattice [ id_3d ] = 0 else : agn_locs [ old_id ] . pop ( new_index_1d ) avail_lattice [ id_3d ] = 1 # set the newly selected neighbour as OCCUPIED by current agent # (-1 means not-occupied so a_id) occ_lattice [ tuple ( id_3d )] = new_id return occ_lattice Function update availability lattice 1 2 3 4 5 6 7 def update_avail_lat ( occ_lattice ): occ_all = occ_lattice > - 1 rolled_al = np . roll ( occ_all , 1 , axis = 2 ) dif = rolled_al . astype ( int ) - occ_all . astype ( int ) dif [:, :, 1 ] = ( occ_lattice [:,:, 1 ] == - 1 ) * ( avail_lattice [:, :, 1 ]) new_avail_lattice = dif == 1 return new_avail_lattice Function limit buliding depth 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 def depth ( occ_lattice , avail_lattice , max_depth ): # Constructing the stencils to check in different directions # filled array for x direction of the stencils sx_ar = np . ones (( max_depth + 1 , 1 , 1 ), dtype = np . int8 ) # filled array for y direction of the stencils sy_ar = np . ones (( 1 , max_depth + 1 , 1 ), dtype = np . int8 ) # east and west stencils se = tg . stencil ( sx_ar , origin = [ max_depth , 0 , 0 ], function = tg . sfunc . sum , dtype = np . int8 ) sw = tg . stencil ( sx_ar , origin = [ 0 , 0 , 0 ], function = tg . sfunc . sum , dtype = np . int8 ) # north and south stencils sn = tg . stencil ( sy_ar , origin = [ 0 , max_depth , 0 ], function = tg . sfunc . sum , dtype = np . int8 ) ss = tg . stencil ( sy_ar , origin = [ 0 , 0 , 0 ], function = tg . sfunc . sum , dtype = np . int8 ) # the depth condition executed on the all occupations occ_all = occ_lattice > - 1 de_con = occ_all . apply_stencil ( se ) < max_depth dw_con = occ_all . apply_stencil ( sw ) < max_depth dn_con = occ_all . apply_stencil ( sn ) < max_depth ds_con = occ_all . apply_stencil ( ss ) < max_depth # apply the conditions to the availability lattice return avail_lattice * de_con * dw_con * dn_con * ds_con Run the simulation 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 # make a deep copy of occupation lattice cur_occ_lattice = tg . to_lattice ( np . copy ( occ_lattice ), occ_lattice ) lat_flat = avail_lattice . flatten () # initialzing the list of frames frames = [ cur_occ_lattice ] squareness_weight = 1.05 # setting the time variable to 0 t = 0 n_frames = 1000 # main feedback loop of the simulation (for each time step ...) while t < n_frames : print ( t ) for a_id , a_prefs in program_full . iterrows (): # update the availability lattice to prevent the voxels to grow in the air #update_avail_lattice = update_avail_lat(occ_lattice) new_avail_lattice = depth ( occ_lattice , avail_lattice , 3 ) #new_avail_lattice = avail_lattice # retrieve the list of the locations of the current agent a_locs = agn_locs [ a_id ] # initialize the list of free neighbours free_neighs = [] free_neighs_1d = [] # for each location of the agent for loc in a_locs : # retrieve the list of neighbours of the agent based on the stencil neighs = avail_lattice . find_neighbours_masked ( stencil , loc = loc ) # for each neighbour ... for n in neighs : # compute 3D index of neighbour neigh_3d_id = np . unravel_index ( n , avail_lattice . shape ) # if the neighbour is available... (also not taken by a corridor) if new_avail_lattice [ neigh_3d_id ]: # add the neighbour to the list of free neighbours free_neighs . append ( neigh_3d_id ) free_neighs_1d . append ( n ) fns = np . array ( free_neighs ) # check if found any free neighbour if len ( free_neighs ) > 0 : # retrieve a list of 1d locations of the neighbours + how often do these neighbours occur fns_1d , fn_ind , fn_count = np . unique ( np . array ( free_neighs_1d ), return_index = True , return_counts = True ) # find the value of each of these free neighbours a_eval = evaluate_voxels ( program_prefs . iloc [ a_id ], fns [ fn_ind ]) # rais the value with a squareness factor according to how often the neighbour occurs new_a_eval = a_eval * ( squareness_weight ** ( fn_count - 1 )) # check if the the vox_amount of the agent is satisfied if len ( a_locs ) >= vox_am_program [ a_id ]: # evaluate the internal voxels with the right a_id internal_eval = evaluate_voxels ( program_prefs . iloc [ a_id ], np . array ( a_locs )) # find the value of the min internal in the correct a_id min_internal = min ( internal_eval ) # find the maximum value of the neighbours max_neigh = new_a_eval . max () # if the maximum neigbhour has a 10% higher value than the min internal voxel, it will be replaced if max_neigh * 1.1 >= min_internal : # find index of max neighbour max_neigh_in = np . argmax ( new_a_eval ) # find the 1d index of max neighbour selected_neigh_1d_id = fns_1d [ max_neigh_in ] # make it 3d location selected_neigh_3d_id = np . unravel_index ( selected_neigh_1d_id , avail_lattice . shape ) # find index of min internal index_min_int = np . argmin ( internal_eval ) # make it 3d location min_int_3d_id = tuple ( a_locs [ index_min_int ]) # occupy max neighbour occ_lattice = change_value ( occ_lattice , avail_lattice , selected_neigh_3d_id , a_id ) # drop the min internal occ_lattice = change_value ( occ_lattice , avail_lattice , min_int_3d_id , - 1 , a_id , index_min_int ) else : # select the neighbour with highest evaluation selected_int = np . argmax ( new_a_eval ) # find the 1d index of max neighbour selected_neigh_1d_id = fns_1d [ selected_int ] # make it 3d location selected_neigh_3d_id = np . unravel_index ( selected_neigh_1d_id , avail_lattice . shape ) # change the value of the voxel occ_lattice = change_value ( occ_lattice , avail_lattice , selected_neigh_3d_id , a_id ) # run the update of the distance field of this agent fields [ str ( a_id )] = df . distance_field ( occ_lattice , avail_lattice , a_id ) # save the evaluation field of agent 0 # if a_id == 0: # frns = np.argwhere(init_avail_lattice > -1) # vox_vals = evaluate_voxels(program_prefs.iloc[0], frns) # val_lattice = tg.to_lattice(vox_vals.reshape(avail_lattice.shape), avail_lattice) # func.save_image(val_lattice, \"a_id = 0\", \"../data/evaluation/0_\"+str(np.sum(occ_lattice == 0))+\"_field.png\") # constructing the new lattice new_occ_lattice = tg . to_lattice ( np . copy ( occ_lattice ), occ_lattice ) # adding the new lattice to the list of frames frames . append ( new_occ_lattice ) # adding one to the time counter t += 1 Visualizing the simulation 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 pv . set_plot_theme ( \"document\" ) p = pv . Plotter ( notebook = True ) base_lattice = frames [ 0 ] # Set the grid dimensions: shape + 1 because we want to inject our values on the CELL data grid = pv . UniformGrid () grid . dimensions = np . array ( base_lattice . shape ) + 1 # The bottom left corner of the data set grid . origin = base_lattice . minbound - base_lattice . unit * 0.5 # These are the cell sizes along each axis grid . spacing = base_lattice . unit # adding the boundingbox wireframe p . add_mesh ( grid . outline (), color = \"grey\" , label = \"Domain\" ) # adding axes p . add_axes () p . show_bounds ( grid = \"back\" , location = \"back\" , color = \"#aaaaaa\" ) def create_mesh ( value ): f = int ( value ) lattice = frames [ f ] # Add the data values to the cell data grid . cell_arrays [ \"Agents\" ] = lattice . flatten ( order = \"F\" ) . astype ( int ) # Flatten the array! # filtering the voxels threshed = grid . threshold ([ - 0.1 , agn_num - 0.9 ]) # adding the voxels p . add_mesh ( threshed , name = 'sphere' , show_edges = True , opacity = 1.0 , show_scalar_bar = False ) return p . add_slider_widget ( create_mesh , [ 0 , n_frames ], title = 'Time' , value = 0 , event_type = \"always\" , style = \"classic\" ) p . show ( use_ipyvtk = True ) Saving lattice frames in csv 1 2 3 4 5 6 for i , lattice in enumerate ( frames ): csv_path = os . path . relpath ( '../data/abm_animation/abm_f_' + f ' { i : 03 } ' + '.csv' ) lattice . to_csv ( csv_path ) csv_path = os . path . relpath ( '../data/new_avail_lat.csv' ) avail_lattice . to_csv ( csv_path ) Find the cluster centers 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 cluster_centers = [] for func_id in range ( 0 , int ( np . max ( frames [ - 1 ])) + 1 ): function_locs = np . array ( np . where ( frames [ - 1 ] == func_id )) . T # for every multiple of 100 voxels a cluster center is created and at least 1 per agent nclusters = int ( len ( function_locs ) / 100 + 1 ) kmeans_model = KMeans ( n_clusters = nclusters , random_state = 0 ) . fit ( function_locs ) cluster_centers . append ( np . round ( kmeans_model . cluster_centers_ ) . astype ( np . int8 )) # making shure it's no longer a nested cluster center list cluster_center_list = [] for i in range ( len ( cluster_centers )): cluster_center_list . append ( cluster_centers [ i ][ 0 ]) #creating a lattice that shows all cluster centers cluster_center_lattice = avail_lattice * 0 - 1 for cluster_center in cluster_center_list : cluster_center_lattice [ cluster_center [ 0 ], cluster_center [ 1 ], cluster_center [ 2 ]] = 1 print ( cluster_center ) Visualize voxel centers 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 pv . set_plot_theme ( \"document\" ) p = pv . Plotter ( notebook = True ) base_lattice = cluster_center_lattice # Set the grid dimensions: shape + 1 because we want to inject our values on the CELL data grid = pv . UniformGrid () grid . dimensions = np . array ( base_lattice . shape ) + 1 # The bottom left corner of the data set grid . origin = base_lattice . minbound - base_lattice . unit * 0.5 # These are the cell sizes along each axis grid . spacing = base_lattice . unit # adding the boundingbox wireframe p . add_mesh ( grid . outline (), color = \"grey\" , label = \"Domain\" ) # adding axes p . add_axes () p . show_bounds ( grid = \"back\" , location = \"back\" , color = \"#aaaaaa\" ) # Add the data values to the cell data grid . cell_arrays [ \"Agents\" ] = base_lattice . flatten ( order = \"F\" ) . astype ( int ) # Flatten the array! # filtering the voxels threshed = grid . threshold ([ 0.9 , 1.1 ]) # adding the voxels p . add_mesh ( threshed , name = 'sphere' , show_edges = True , opacity = 1.0 , show_scalar_bar = False ) #p.show(use_ipyvtk=True) #p.show(screenshot=\"../data/cluster_centers.png\") Save voxel centers to csv 1 2 3 # save cluster centers to csv # csv_path = os.path.relpath(\"../data/cluster_center_lattice.csv\") # cluster_center_lattice.to_csv(csv_path) Create floor plans Slice the massing lattice 1 2 3 4 5 6 7 8 9 # loading the lattice from csv lattice_path = os . path . relpath ( '../data/abm_animation/abm_f_1000.csv' ) massing_lattice = tg . lattice_from_csv ( lattice_path ) # slice the massing lattice to create floorplans floor_lattice = tg . to_lattice ( np . copy ( massing_lattice ), massing_lattice ) # slice to get a floor plan, the rest will be -1 (empty) floor_lattice [:,:,: 11 ] = - 1 floor_lattice [:,:, 12 :] = - 1 Visualize floorplans 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 def tri_to_pv ( tri_mesh ): faces = np . pad ( tri_mesh . faces , (( 0 , 0 ),( 1 , 0 )), 'constant' , constant_values = 3 ) pv_mesh = pv . PolyData ( tri_mesh . vertices , faces ) return pv_mesh # load the context mesh context_path = os . path . relpath ( '../data/immediate_context.obj' ) context_mesh = tm . load ( context_path ) # make a dictionary from the space names connected to the id program_dict = program_complete . to_dict () space_list = program_dict [ \"space_name\" ] pv . set_plot_theme ( \"document\" ) p = pv . Plotter ( notebook = False ) base_lattice = massing_lattice # Set the grid dimensions: shape + 1 because we want to inject our values on the CELL data grid = pv . UniformGrid () grid . dimensions = np . array ( base_lattice . shape ) + 1 # The bottom left corner of the data set grid . origin = base_lattice . minbound - base_lattice . unit * 0.5 # These are the cell sizes along each axis grid . spacing = base_lattice . unit # adding axes p . add_axes () # adding the meshes p . add_mesh ( tri_to_pv ( context_mesh ), opacity = 0.1 , style = 'wireframe' ) # Add the data values to the cell data grid . cell_arrays [ \"Agents\" ] = base_lattice . flatten ( order = \"F\" ) . astype ( int ) # Flatten the array! # filtering the voxels threshed = grid . threshold ([ 0 , 21 ]) # add a legend sargs = dict ( interactive = True , label_font_size = 6 , shadow = True ) p . add_mesh ( threshed , name = 'sphere' , show_edges = True , opacity = 1.0 , show_scalar_bar = True , annotations = space_list , scalar_bar_args = sargs , cmap = \"tab20b\" ) p . camera_position = 'xy' p . camera . zoom ( 3.0 ) p . show ( use_ipyvtk = False ) #p.show(screenshot=\"../data/floor_plan_legend.png\") Credits 1 2 3 4 5 __author__ = \"Shervin Azadi \" __license__ = \"MIT\" __version__ = \"1.0\" __url__ = \"https://github.com/shervinazadi/spatial_computing_workshops\" __summary__ = \"Spatial Computing Design Studio Workshop on Agent Based Models for Generative Spaces\"","title":"Initialization"},{"location":"Scripts/grow_agents/#initialize-and-grown-agents-abm","text":"Load required libraries 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 # !pip install pyvista==0.28.1 ipyvtklink import os import topogenesis as tg import pyvista as pv import trimesh as tm import pandas as pd import numpy as np import copy import random from sklearn.cluster import KMeans np . random . seed ( 0 ) import resources.dynamic_fields as df import resources.functions as func # convert mesh to pv_mesh def tri_to_pv ( tri_mesh ): faces = np . pad ( tri_mesh . faces , (( 0 , 0 ),( 1 , 0 )), 'constant' , constant_values = 3 ) pv_mesh = pv . PolyData ( tri_mesh . vertices , faces ) return pv_mesh","title":"Initialize and grown agents (ABM)"},{"location":"Scripts/grow_agents/#define-the-neighborhood-stencil","text":"Stencil: horizontal 1 2 3 4 5 6 7 8 9 10 11 # creating neighborhood definition 1 stencil = tg . create_stencil ( \"von_neumann\" , 1 , 1 ) # setting the indices stencil . set_index ([ 0 , 0 , 0 ], 0 ) # creating neighborhood definition 1 stencil_hor = tg . create_stencil ( \"von_neumann\" , 1 , 1 ) # setting the indices stencil_hor . set_index ([ 0 , 0 , 0 ], 0 ) stencil_hor . set_index ([ 0 , 0 , 1 ], 0 ) stencil_hor . set_index ([ 0 , 0 , - 1 ], 0 )","title":"Define the neighborhood (stencil)"},{"location":"Scripts/grow_agents/#setup-the-environment","text":"Load the envelope lattice as the availability lattice 1 2 3 4 5 6 7 8 9 10 11 # loading the lattice from csv lattice_path = os . path . relpath ( '../data/envelope_highres.csv' ) avail_lattice = tg . lattice_from_csv ( lattice_path ) init_avail_lattice = tg . to_lattice ( np . copy ( avail_lattice ), avail_lattice ) # loading the lattice from csv field_path = os . path . relpath ( \"../data/envelope_lowres.csv\" ) envelope_lattice = tg . lattice_from_csv ( field_path ) #init_avail_lattice = tg.to_lattice(np.copy(envelope_lattice), envelope_lattice) full_lattice = envelope_lattice * 0 + 1 Load program 1 2 3 4 5 6 7 8 program_full = pd . read_csv ( \"../data/program_req.csv\" ) #program_full program_complete = program_full . drop ([ \"vox_amount\" ], 1 ) #program_complete program_prefs = program_complete . drop ([ \"space_name\" , \"space_id\" ], 1 ) #program_prefs Load value fields 1 2 3 4 5 6 7 8 # loading the lattice from csv, when it is there fields = {} for f in program_full . columns : lattice_path = os . path . relpath ( '../data/' + f + '.csv' ) try : fields [ f ] = tg . lattice_from_csv ( lattice_path ) except : fields [ f ] = copy . deepcopy ( avail_lattice * 0 + 1 ) Initialize agents 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 def initialize_agents ( avail_lattice , program_prefs , fields ): # initialize the occupation lattice occ_lattice = avail_lattice * 0 - 1 # create a list for agents locations agn_locs = [] # for each agent origin ... for a_id , a_prefs in program_prefs . iterrows (): # create a preference lattice pref_lattice = ( avail_lattice * 0.0 + 1.0 ) * avail_lattice # choosing three available voxels for f , w in a_prefs . iteritems (): pref_lattice *= fields [ f ] ** w select_id = np . argmax ( pref_lattice ) a_origin_1 = np . unravel_index ( select_id , avail_lattice . shape ) # set the initialised agent to ground level, than later there will be no floating parts a_origin_2 = ( a_origin_1 [ 0 ], a_origin_1 [ 1 ], 1 ) # to prevent voxels from occupying the same place for n in range ( 5 ): if avail_lattice [ a_origin_2 ] == 0 : a_origin_2 = ( a_origin_1 [ 0 ], a_origin_1 [ 1 ], 1 + n ) # add the origin to the list of agent locations agn_locs . append ([ a_origin_2 ]) # set the origin in availablity lattice as 0 (UNavailable) avail_lattice [ a_origin_2 ] = 0 # set the origin in occupation lattice as the agent id (a_id) occ_lattice [ a_origin_2 ] = a_id return occ_lattice , agn_locs Save agents to csv 1 2 csv_path = os . path . relpath ( \"../data/initialized_agents.csv\" ) occ_lattice . to_csv ( csv_path ) Visualize initialized agents 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 pv . set_plot_theme ( \"document\" ) p = pv . Plotter ( notebook = True ) # Set the grid dimensions: shape + 1 because we want to inject our values on the CELL data grid = pv . UniformGrid () grid . dimensions = np . array ( occ_lattice . shape ) + 1 # The bottom left corner of the data set grid . origin = occ_lattice . minbound - occ_lattice . unit * 0.5 # These are the cell sizes along each axis grid . spacing = occ_lattice . unit # adding the boundingbox wireframe p . add_mesh ( grid . outline (), color = \"grey\" , label = \"Domain\" ) # adding axes p . add_axes () p . show_bounds ( grid = \"back\" , location = \"back\" , color = \"#777777\" ) # Add the data values to the cell data grid . cell_arrays [ \"Agents\" ] = occ_lattice . flatten ( order = \"F\" ) . astype ( int ) # Flatten the array! # filtering the voxels agn_num = len ( program_complete ) threshed = grid . threshold ([ - 0.1 , agn_num - 0.9 ]) # adding the voxels p . add_mesh ( threshed , show_edges = True , opacity = 1.0 , show_scalar_bar = False ) #p.show(use_ipyvtk=True) #p.show(screenshot=\"../data/init_agents.png\")","title":"Setup the environment"},{"location":"Scripts/grow_agents/#abm-simulation","text":"1 2 3 # make a dictionary from the max amount of voxels per space program_dict = program_full . to_dict () vox_am_program = program_dict [ \"vox_amount\" ] Functions for in the ABM simulation 1 2 3 4 5 6 7 8 9 10 11 12 13 def evaluate_voxels ( a_prefs , fns ): # find the value of neighbours # init the agent value array a_eval = np . ones ( len ( fns )) # for each field... for f in a_prefs . keys (): # find the raw value of free neighbours... vals = fields [ f ][ fns [:, 0 ], fns [:, 1 ], fns [:, 2 ]] # raise the the raw value to the power of preference weight of the agent a_weighted_vals = vals ** a_prefs [ f ] # multiply them to the previous weighted values a_eval *= a_weighted_vals return a_eval Function change value of a voxel 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # A defition to change the value of voxel in the avail_lattice and occ_lattice to occupied or not occupied (True = occupie, False = remove) def change_value ( occ_lattice , avail_lattice , id_3d , new_id , old_id = 0 , new_index_1d = 0 ): # set the newly selected neighbour as UNavailable (0) or available (1) in the availability lattice if new_id > - 1 : # find the location of the newly selected neighbour selected_neigh_loc = np . array ( id_3d ) . flatten () agn_locs [ new_id ] . append ( selected_neigh_loc ) avail_lattice [ id_3d ] = 0 else : agn_locs [ old_id ] . pop ( new_index_1d ) avail_lattice [ id_3d ] = 1 # set the newly selected neighbour as OCCUPIED by current agent # (-1 means not-occupied so a_id) occ_lattice [ tuple ( id_3d )] = new_id return occ_lattice Function update availability lattice 1 2 3 4 5 6 7 def update_avail_lat ( occ_lattice ): occ_all = occ_lattice > - 1 rolled_al = np . roll ( occ_all , 1 , axis = 2 ) dif = rolled_al . astype ( int ) - occ_all . astype ( int ) dif [:, :, 1 ] = ( occ_lattice [:,:, 1 ] == - 1 ) * ( avail_lattice [:, :, 1 ]) new_avail_lattice = dif == 1 return new_avail_lattice Function limit buliding depth 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 def depth ( occ_lattice , avail_lattice , max_depth ): # Constructing the stencils to check in different directions # filled array for x direction of the stencils sx_ar = np . ones (( max_depth + 1 , 1 , 1 ), dtype = np . int8 ) # filled array for y direction of the stencils sy_ar = np . ones (( 1 , max_depth + 1 , 1 ), dtype = np . int8 ) # east and west stencils se = tg . stencil ( sx_ar , origin = [ max_depth , 0 , 0 ], function = tg . sfunc . sum , dtype = np . int8 ) sw = tg . stencil ( sx_ar , origin = [ 0 , 0 , 0 ], function = tg . sfunc . sum , dtype = np . int8 ) # north and south stencils sn = tg . stencil ( sy_ar , origin = [ 0 , max_depth , 0 ], function = tg . sfunc . sum , dtype = np . int8 ) ss = tg . stencil ( sy_ar , origin = [ 0 , 0 , 0 ], function = tg . sfunc . sum , dtype = np . int8 ) # the depth condition executed on the all occupations occ_all = occ_lattice > - 1 de_con = occ_all . apply_stencil ( se ) < max_depth dw_con = occ_all . apply_stencil ( sw ) < max_depth dn_con = occ_all . apply_stencil ( sn ) < max_depth ds_con = occ_all . apply_stencil ( ss ) < max_depth # apply the conditions to the availability lattice return avail_lattice * de_con * dw_con * dn_con * ds_con Run the simulation 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 # make a deep copy of occupation lattice cur_occ_lattice = tg . to_lattice ( np . copy ( occ_lattice ), occ_lattice ) lat_flat = avail_lattice . flatten () # initialzing the list of frames frames = [ cur_occ_lattice ] squareness_weight = 1.05 # setting the time variable to 0 t = 0 n_frames = 1000 # main feedback loop of the simulation (for each time step ...) while t < n_frames : print ( t ) for a_id , a_prefs in program_full . iterrows (): # update the availability lattice to prevent the voxels to grow in the air #update_avail_lattice = update_avail_lat(occ_lattice) new_avail_lattice = depth ( occ_lattice , avail_lattice , 3 ) #new_avail_lattice = avail_lattice # retrieve the list of the locations of the current agent a_locs = agn_locs [ a_id ] # initialize the list of free neighbours free_neighs = [] free_neighs_1d = [] # for each location of the agent for loc in a_locs : # retrieve the list of neighbours of the agent based on the stencil neighs = avail_lattice . find_neighbours_masked ( stencil , loc = loc ) # for each neighbour ... for n in neighs : # compute 3D index of neighbour neigh_3d_id = np . unravel_index ( n , avail_lattice . shape ) # if the neighbour is available... (also not taken by a corridor) if new_avail_lattice [ neigh_3d_id ]: # add the neighbour to the list of free neighbours free_neighs . append ( neigh_3d_id ) free_neighs_1d . append ( n ) fns = np . array ( free_neighs ) # check if found any free neighbour if len ( free_neighs ) > 0 : # retrieve a list of 1d locations of the neighbours + how often do these neighbours occur fns_1d , fn_ind , fn_count = np . unique ( np . array ( free_neighs_1d ), return_index = True , return_counts = True ) # find the value of each of these free neighbours a_eval = evaluate_voxels ( program_prefs . iloc [ a_id ], fns [ fn_ind ]) # rais the value with a squareness factor according to how often the neighbour occurs new_a_eval = a_eval * ( squareness_weight ** ( fn_count - 1 )) # check if the the vox_amount of the agent is satisfied if len ( a_locs ) >= vox_am_program [ a_id ]: # evaluate the internal voxels with the right a_id internal_eval = evaluate_voxels ( program_prefs . iloc [ a_id ], np . array ( a_locs )) # find the value of the min internal in the correct a_id min_internal = min ( internal_eval ) # find the maximum value of the neighbours max_neigh = new_a_eval . max () # if the maximum neigbhour has a 10% higher value than the min internal voxel, it will be replaced if max_neigh * 1.1 >= min_internal : # find index of max neighbour max_neigh_in = np . argmax ( new_a_eval ) # find the 1d index of max neighbour selected_neigh_1d_id = fns_1d [ max_neigh_in ] # make it 3d location selected_neigh_3d_id = np . unravel_index ( selected_neigh_1d_id , avail_lattice . shape ) # find index of min internal index_min_int = np . argmin ( internal_eval ) # make it 3d location min_int_3d_id = tuple ( a_locs [ index_min_int ]) # occupy max neighbour occ_lattice = change_value ( occ_lattice , avail_lattice , selected_neigh_3d_id , a_id ) # drop the min internal occ_lattice = change_value ( occ_lattice , avail_lattice , min_int_3d_id , - 1 , a_id , index_min_int ) else : # select the neighbour with highest evaluation selected_int = np . argmax ( new_a_eval ) # find the 1d index of max neighbour selected_neigh_1d_id = fns_1d [ selected_int ] # make it 3d location selected_neigh_3d_id = np . unravel_index ( selected_neigh_1d_id , avail_lattice . shape ) # change the value of the voxel occ_lattice = change_value ( occ_lattice , avail_lattice , selected_neigh_3d_id , a_id ) # run the update of the distance field of this agent fields [ str ( a_id )] = df . distance_field ( occ_lattice , avail_lattice , a_id ) # save the evaluation field of agent 0 # if a_id == 0: # frns = np.argwhere(init_avail_lattice > -1) # vox_vals = evaluate_voxels(program_prefs.iloc[0], frns) # val_lattice = tg.to_lattice(vox_vals.reshape(avail_lattice.shape), avail_lattice) # func.save_image(val_lattice, \"a_id = 0\", \"../data/evaluation/0_\"+str(np.sum(occ_lattice == 0))+\"_field.png\") # constructing the new lattice new_occ_lattice = tg . to_lattice ( np . copy ( occ_lattice ), occ_lattice ) # adding the new lattice to the list of frames frames . append ( new_occ_lattice ) # adding one to the time counter t += 1 Visualizing the simulation 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 pv . set_plot_theme ( \"document\" ) p = pv . Plotter ( notebook = True ) base_lattice = frames [ 0 ] # Set the grid dimensions: shape + 1 because we want to inject our values on the CELL data grid = pv . UniformGrid () grid . dimensions = np . array ( base_lattice . shape ) + 1 # The bottom left corner of the data set grid . origin = base_lattice . minbound - base_lattice . unit * 0.5 # These are the cell sizes along each axis grid . spacing = base_lattice . unit # adding the boundingbox wireframe p . add_mesh ( grid . outline (), color = \"grey\" , label = \"Domain\" ) # adding axes p . add_axes () p . show_bounds ( grid = \"back\" , location = \"back\" , color = \"#aaaaaa\" ) def create_mesh ( value ): f = int ( value ) lattice = frames [ f ] # Add the data values to the cell data grid . cell_arrays [ \"Agents\" ] = lattice . flatten ( order = \"F\" ) . astype ( int ) # Flatten the array! # filtering the voxels threshed = grid . threshold ([ - 0.1 , agn_num - 0.9 ]) # adding the voxels p . add_mesh ( threshed , name = 'sphere' , show_edges = True , opacity = 1.0 , show_scalar_bar = False ) return p . add_slider_widget ( create_mesh , [ 0 , n_frames ], title = 'Time' , value = 0 , event_type = \"always\" , style = \"classic\" ) p . show ( use_ipyvtk = True ) Saving lattice frames in csv 1 2 3 4 5 6 for i , lattice in enumerate ( frames ): csv_path = os . path . relpath ( '../data/abm_animation/abm_f_' + f ' { i : 03 } ' + '.csv' ) lattice . to_csv ( csv_path ) csv_path = os . path . relpath ( '../data/new_avail_lat.csv' ) avail_lattice . to_csv ( csv_path )","title":"ABM simulation"},{"location":"Scripts/grow_agents/#find-the-cluster-centers","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 cluster_centers = [] for func_id in range ( 0 , int ( np . max ( frames [ - 1 ])) + 1 ): function_locs = np . array ( np . where ( frames [ - 1 ] == func_id )) . T # for every multiple of 100 voxels a cluster center is created and at least 1 per agent nclusters = int ( len ( function_locs ) / 100 + 1 ) kmeans_model = KMeans ( n_clusters = nclusters , random_state = 0 ) . fit ( function_locs ) cluster_centers . append ( np . round ( kmeans_model . cluster_centers_ ) . astype ( np . int8 )) # making shure it's no longer a nested cluster center list cluster_center_list = [] for i in range ( len ( cluster_centers )): cluster_center_list . append ( cluster_centers [ i ][ 0 ]) #creating a lattice that shows all cluster centers cluster_center_lattice = avail_lattice * 0 - 1 for cluster_center in cluster_center_list : cluster_center_lattice [ cluster_center [ 0 ], cluster_center [ 1 ], cluster_center [ 2 ]] = 1 print ( cluster_center ) Visualize voxel centers 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 pv . set_plot_theme ( \"document\" ) p = pv . Plotter ( notebook = True ) base_lattice = cluster_center_lattice # Set the grid dimensions: shape + 1 because we want to inject our values on the CELL data grid = pv . UniformGrid () grid . dimensions = np . array ( base_lattice . shape ) + 1 # The bottom left corner of the data set grid . origin = base_lattice . minbound - base_lattice . unit * 0.5 # These are the cell sizes along each axis grid . spacing = base_lattice . unit # adding the boundingbox wireframe p . add_mesh ( grid . outline (), color = \"grey\" , label = \"Domain\" ) # adding axes p . add_axes () p . show_bounds ( grid = \"back\" , location = \"back\" , color = \"#aaaaaa\" ) # Add the data values to the cell data grid . cell_arrays [ \"Agents\" ] = base_lattice . flatten ( order = \"F\" ) . astype ( int ) # Flatten the array! # filtering the voxels threshed = grid . threshold ([ 0.9 , 1.1 ]) # adding the voxels p . add_mesh ( threshed , name = 'sphere' , show_edges = True , opacity = 1.0 , show_scalar_bar = False ) #p.show(use_ipyvtk=True) #p.show(screenshot=\"../data/cluster_centers.png\") Save voxel centers to csv 1 2 3 # save cluster centers to csv # csv_path = os.path.relpath(\"../data/cluster_center_lattice.csv\") # cluster_center_lattice.to_csv(csv_path)","title":"Find the cluster centers"},{"location":"Scripts/grow_agents/#create-floor-plans","text":"Slice the massing lattice 1 2 3 4 5 6 7 8 9 # loading the lattice from csv lattice_path = os . path . relpath ( '../data/abm_animation/abm_f_1000.csv' ) massing_lattice = tg . lattice_from_csv ( lattice_path ) # slice the massing lattice to create floorplans floor_lattice = tg . to_lattice ( np . copy ( massing_lattice ), massing_lattice ) # slice to get a floor plan, the rest will be -1 (empty) floor_lattice [:,:,: 11 ] = - 1 floor_lattice [:,:, 12 :] = - 1 Visualize floorplans 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 def tri_to_pv ( tri_mesh ): faces = np . pad ( tri_mesh . faces , (( 0 , 0 ),( 1 , 0 )), 'constant' , constant_values = 3 ) pv_mesh = pv . PolyData ( tri_mesh . vertices , faces ) return pv_mesh # load the context mesh context_path = os . path . relpath ( '../data/immediate_context.obj' ) context_mesh = tm . load ( context_path ) # make a dictionary from the space names connected to the id program_dict = program_complete . to_dict () space_list = program_dict [ \"space_name\" ] pv . set_plot_theme ( \"document\" ) p = pv . Plotter ( notebook = False ) base_lattice = massing_lattice # Set the grid dimensions: shape + 1 because we want to inject our values on the CELL data grid = pv . UniformGrid () grid . dimensions = np . array ( base_lattice . shape ) + 1 # The bottom left corner of the data set grid . origin = base_lattice . minbound - base_lattice . unit * 0.5 # These are the cell sizes along each axis grid . spacing = base_lattice . unit # adding axes p . add_axes () # adding the meshes p . add_mesh ( tri_to_pv ( context_mesh ), opacity = 0.1 , style = 'wireframe' ) # Add the data values to the cell data grid . cell_arrays [ \"Agents\" ] = base_lattice . flatten ( order = \"F\" ) . astype ( int ) # Flatten the array! # filtering the voxels threshed = grid . threshold ([ 0 , 21 ]) # add a legend sargs = dict ( interactive = True , label_font_size = 6 , shadow = True ) p . add_mesh ( threshed , name = 'sphere' , show_edges = True , opacity = 1.0 , show_scalar_bar = True , annotations = space_list , scalar_bar_args = sargs , cmap = \"tab20b\" ) p . camera_position = 'xy' p . camera . zoom ( 3.0 ) p . show ( use_ipyvtk = False ) #p.show(screenshot=\"../data/floor_plan_legend.png\")","title":"Create floor plans"},{"location":"Scripts/grow_agents/#credits","text":"1 2 3 4 5 __author__ = \"Shervin Azadi \" __license__ = \"MIT\" __version__ = \"1.0\" __url__ = \"https://github.com/shervinazadi/spatial_computing_workshops\" __summary__ = \"Spatial Computing Design Studio Workshop on Agent Based Models for Generative Spaces\"","title":"Credits"},{"location":"Scripts/noise/","text":"Noise Initialization Load required libraries 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 import os import topogenesis as tg import pyvista as pv import trimesh as tm import numpy as np import scipy as sp from scipy.interpolate import RegularGridInterpolator import resources.functions as f # convert mesh to pv_mesh def tri_to_pv ( tri_mesh ): faces = np . pad ( tri_mesh . faces , (( 0 , 0 ),( 1 , 0 )), 'constant' , constant_values = 3 ) pv_mesh = pv . PolyData ( tri_mesh . vertices , faces ) return pv_mesh Load envelope lattice as the availability lattice 1 2 3 4 5 6 7 8 9 # loading the lattice from csv lattice_path = os . path . relpath ( '../data/envelope_lowres.csv' ) avail_lattice = tg . lattice_from_csv ( lattice_path ) init_avail_lattice = tg . to_lattice ( np . copy ( avail_lattice ), avail_lattice ) init_avail_lattice_one = init_avail_lattice * 0 + 1 # loading the context mesh context_path = os . path . relpath ( '../data/immediate_context.obj' ) context_mesh = tm . load ( context_path ) Load noise sources 1 2 3 # loading noise source points from CSV noise_source_path = os . path . relpath ( '../data/streetpoints.xyz.txt' ) noise_sources = np . genfromtxt ( noise_source_path , delimiter = ',' ) Visualize noise source points 1 2 3 4 5 6 7 8 9 10 11 12 13 14 pv . set_plot_theme ( \"Document\" ) p = pv . Plotter ( notebook = True ) # adding the avilability lattice init_avail_lattice . fast_vis ( p ) # adding axes p . add_axes () # add the meshes p . add_mesh ( noise_sources , point_size = 8 ) p . add_mesh ( tri_to_pv ( context_mesh ), opacity = 0.1 , style = 'wireframe' ) #p.show(use_ipyvtk=True) Creation of noise field Load noise sources 1 2 3 # loading noise source points from CSV noise_source_path = os . path . relpath ( '../data/streetpoints.xyz.txt' ) noise_sources = np . genfromtxt ( noise_source_path , delimiter = ',' ) Visualize the noise lattices 1 f . visualize ( agg_noise_lat , \"Noise\" , \"../data/noise_lowres.png\" ) Interpolate lowres lattice to highres Visualize the noise lattices 1 2 3 # loading highres lattice highres_lattice_path = os . path . relpath ( '../data/envelope_highres.csv' ) highres_lattice = tg . lattice_from_csv ( highres_lattice_path ) Define interpolation function 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 def interpolate ( lowres_field ): # loading highres lattice highres_lattice_path = os . path . relpath ( '../data/envelope_highres.csv' ) highres_lat = tg . lattice_from_csv ( highres_lattice_path ) highres_lattice = highres_lat * 0 + 1 # line spaces x_space = np . linspace ( lowres_field . minbound [ 0 ], lowres_field . maxbound [ 0 ], lowres_field . shape [ 0 ]) y_space = np . linspace ( lowres_field . minbound [ 1 ], lowres_field . maxbound [ 1 ], lowres_field . shape [ 1 ]) z_space = np . linspace ( lowres_field . minbound [ 2 ], lowres_field . maxbound [ 2 ], lowres_field . shape [ 2 ]) # interpolation function interpolating_function = RegularGridInterpolator (( x_space , y_space , z_space ), lowres_field , bounds_error = False , fill_value = None ) # high_res lattice full_lattice = highres_lattice + 1 # sample point sample_points = full_lattice . centroids # interpolation interpolated_values = interpolating_function ( sample_points ) # lattice construction interpolated_lattice = tg . to_lattice ( interpolated_values . reshape ( highres_lattice . shape ), highres_lattice ) # nulling the unavailable cells interpolated_lattice *= highres_lattice return interpolated_lattice Interpolate closeness lattice 1 2 highres_noise = interpolate ( agg_noise_lat ) highres_noise_field = highres_noise * highres_lattice Save interpolated field to csv 1 2 3 # save the interpolated distance field to csv csv_path = os . path . relpath ( \"../data/noise.csv\" ) highres_noise_field . to_csv ( csv_path ) Visualize highres field 1 f . visualize ( highres_noise , \"Noise\" , \"../data/noise_highres.png\" ) Credits Visualize highres field 1 2 3 4 5 __author__ = \"Shervin Azadi\" __license__ = \"MIT\" __version__ = \"1.0\" __url__ = \"https://github.com/shervinazadi/spatial_computing_workshops\" __summary__ = \"Spatial Computing Design Studio Workshop on Noise Fields\"","title":"Noise"},{"location":"Scripts/noise/#noise","text":"","title":"Noise"},{"location":"Scripts/noise/#initialization","text":"Load required libraries 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 import os import topogenesis as tg import pyvista as pv import trimesh as tm import numpy as np import scipy as sp from scipy.interpolate import RegularGridInterpolator import resources.functions as f # convert mesh to pv_mesh def tri_to_pv ( tri_mesh ): faces = np . pad ( tri_mesh . faces , (( 0 , 0 ),( 1 , 0 )), 'constant' , constant_values = 3 ) pv_mesh = pv . PolyData ( tri_mesh . vertices , faces ) return pv_mesh Load envelope lattice as the availability lattice 1 2 3 4 5 6 7 8 9 # loading the lattice from csv lattice_path = os . path . relpath ( '../data/envelope_lowres.csv' ) avail_lattice = tg . lattice_from_csv ( lattice_path ) init_avail_lattice = tg . to_lattice ( np . copy ( avail_lattice ), avail_lattice ) init_avail_lattice_one = init_avail_lattice * 0 + 1 # loading the context mesh context_path = os . path . relpath ( '../data/immediate_context.obj' ) context_mesh = tm . load ( context_path ) Load noise sources 1 2 3 # loading noise source points from CSV noise_source_path = os . path . relpath ( '../data/streetpoints.xyz.txt' ) noise_sources = np . genfromtxt ( noise_source_path , delimiter = ',' ) Visualize noise source points 1 2 3 4 5 6 7 8 9 10 11 12 13 14 pv . set_plot_theme ( \"Document\" ) p = pv . Plotter ( notebook = True ) # adding the avilability lattice init_avail_lattice . fast_vis ( p ) # adding axes p . add_axes () # add the meshes p . add_mesh ( noise_sources , point_size = 8 ) p . add_mesh ( tri_to_pv ( context_mesh ), opacity = 0.1 , style = 'wireframe' ) #p.show(use_ipyvtk=True)","title":"Initialization"},{"location":"Scripts/noise/#creation-of-noise-field","text":"Load noise sources 1 2 3 # loading noise source points from CSV noise_source_path = os . path . relpath ( '../data/streetpoints.xyz.txt' ) noise_sources = np . genfromtxt ( noise_source_path , delimiter = ',' ) Visualize the noise lattices 1 f . visualize ( agg_noise_lat , \"Noise\" , \"../data/noise_lowres.png\" )","title":"Creation of noise field"},{"location":"Scripts/noise/#interpolate-lowres-lattice-to-highres","text":"Visualize the noise lattices 1 2 3 # loading highres lattice highres_lattice_path = os . path . relpath ( '../data/envelope_highres.csv' ) highres_lattice = tg . lattice_from_csv ( highres_lattice_path ) Define interpolation function 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 def interpolate ( lowres_field ): # loading highres lattice highres_lattice_path = os . path . relpath ( '../data/envelope_highres.csv' ) highres_lat = tg . lattice_from_csv ( highres_lattice_path ) highres_lattice = highres_lat * 0 + 1 # line spaces x_space = np . linspace ( lowres_field . minbound [ 0 ], lowres_field . maxbound [ 0 ], lowres_field . shape [ 0 ]) y_space = np . linspace ( lowres_field . minbound [ 1 ], lowres_field . maxbound [ 1 ], lowres_field . shape [ 1 ]) z_space = np . linspace ( lowres_field . minbound [ 2 ], lowres_field . maxbound [ 2 ], lowres_field . shape [ 2 ]) # interpolation function interpolating_function = RegularGridInterpolator (( x_space , y_space , z_space ), lowres_field , bounds_error = False , fill_value = None ) # high_res lattice full_lattice = highres_lattice + 1 # sample point sample_points = full_lattice . centroids # interpolation interpolated_values = interpolating_function ( sample_points ) # lattice construction interpolated_lattice = tg . to_lattice ( interpolated_values . reshape ( highres_lattice . shape ), highres_lattice ) # nulling the unavailable cells interpolated_lattice *= highres_lattice return interpolated_lattice Interpolate closeness lattice 1 2 highres_noise = interpolate ( agg_noise_lat ) highres_noise_field = highres_noise * highres_lattice Save interpolated field to csv 1 2 3 # save the interpolated distance field to csv csv_path = os . path . relpath ( \"../data/noise.csv\" ) highres_noise_field . to_csv ( csv_path ) Visualize highres field 1 f . visualize ( highres_noise , \"Noise\" , \"../data/noise_highres.png\" )","title":"Interpolate lowres lattice to highres"},{"location":"Scripts/noise/#credits","text":"Visualize highres field 1 2 3 4 5 __author__ = \"Shervin Azadi\" __license__ = \"MIT\" __version__ = \"1.0\" __url__ = \"https://github.com/shervinazadi/spatial_computing_workshops\" __summary__ = \"Spatial Computing Design Studio Workshop on Noise Fields\"","title":"Credits"},{"location":"Scripts/shadow/","text":"Solar envelope Initialization Importing the packages 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 #!pip install ipynb import os import topogenesis as tg import pyvista as pv import trimesh as tm import numpy as np from ladybug.sunpath import Sunpath from scipy.interpolate import RegularGridInterpolator import resources.functions as f # convert mesh to pv_mesh def tri_to_pv ( tri_mesh ): faces = np . pad ( tri_mesh . faces , (( 0 , 0 ),( 1 , 0 )), 'constant' , constant_values = 3 ) pv_mesh = pv . PolyData ( tri_mesh . vertices , faces ) return pv_mesh Importing meshes 1 2 3 4 5 6 7 8 9 10 envelope_path = os . path . relpath ( '../data/new_envelope.obj' ) context_path = os . path . relpath ( '../data/immediate_context.obj' ) # load the mesh from file envelope_mesh = tm . load ( envelope_path ) context_mesh = tm . load ( context_path ) # Check if the mesh is watertight print ( envelope_mesh . is_watertight ) print ( context_mesh . is_watertight ) Importing envelope lattice 1 2 3 4 # loading the lattice from csv lattice_path = os . path . relpath ( '../data/envelope_lowres.csv' ) envelope_lattice = tg . lattice_from_csv ( lattice_path ) envelope_lattice_one = envelope_lattice * 0 + 1 Sun vectors Importing envelope lattice 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 # initiate sunpath sp = Sunpath ( longitude = 4.3571 , latitude = 52.0116 ) # define sun hours : A list of hours of the year for each sun vector # there are 8760 hours in a year, so the following integers refer to specific hours throughout the year hoys = [] sun_vectors = [] day_multiples = 100 # for each day of the year ... for d in range ( 365 ): # if it is one of the multiples if d % day_multiples == 0 : # for each hour of the day ... for h in range ( 24 ): # compute the hoy (hour of the year) hoy = d * 24 + h # compute the sun object sun = sp . calculate_sun_from_hoy ( hoy ) # extract the sun vector (the direction that the sun ray travels toward) sun_vector = sun . sun_vector . to_array () # evidently, if the Z component of sun vector is positive, # the sun is under the horizon if sun_vector [ 2 ] < 0.0 : hoys . append ( hoy ) sun_vectors . append ( sun_vector ) sun_vectors = np . array ( sun_vectors ) # compute the rotation matrix Rz = tm . transformations . rotation_matrix ( np . radians ( 36.324 ), [ 0 , 0 , 1 ]) # Rotate the sun vectors to match the site rotation sun_vectors = tm . transform_points ( sun_vectors , Rz ) print ( sun_vectors . shape ) # initiating the plotter pv . set_plot_theme ( \"document\" ) p = pv . Plotter ( notebook = True ) # fast visualization of the lattice envelope_lattice_one . fast_vis ( p ) # adding the meshes p . add_mesh ( tri_to_pv ( context_mesh ), opacity = 0.1 , style = 'wireframe' ) # add the sun locations, color orange p . add_points ( - sun_vectors * 300 , color = '#ffa500' ) # plotting #p.show(use_ipyvtk=True) Compute intersection of sun rays with context mesh Preparing the list of ray directions and origins 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 # constructing the sun direction from the sun vectors in a numpy array sun_dirs = - np . array ( sun_vectors ) # exract the centroids of the envelope voxels vox_cens = envelope_lattice_one . centroids # next step we need to shoot in all of the sun directions from all of the voxels, todo so, we need repeat the sun direction for the number of voxels to construct the ray_dir (which is the list of all ray directions). We need to repeat the voxels for the ray_dir = [] ray_src = [] for v_cen in vox_cens : for s_dir in sun_dirs : ray_dir . append ( s_dir ) ray_src . append ( v_cen ) # converting the list of directions and sources to numpy array ray_dir = np . array ( ray_dir ) ray_src = np . array ( ray_src ) \"\"\" # Further info: this is the vectorised version of nested for loops ray_dir = np.tile(sun_dirs, [len(vox_cens),1]) ray_src = np.tile(vox_cens, [1, len(sun_dirs)]).reshape(-1, 3) \"\"\" print ( \"number of voxels to shoot rays from :\" , vox_cens . shape ) print ( \"number of rays per each voxel :\" , sun_dirs . shape ) print ( \"number of rays to be shooted :\" , ray_src . shape ) Computing the intersection 1 2 3 4 tri_id , ray_id = context_mesh . ray . intersects_id ( ray_origins = ray_src , ray_directions = ray_dir , multiple_hits = False ) # computing the intersections of rays with the context mesh tri_invert_id , ray_invert_id = context_mesh . ray . intersects_id ( ray_origins = ray_src , ray_directions = - ray_dir , multiple_hits = False ) Aggregate simulation result in the sun access lattice Computing the percentage of time that each voxel sees the sun 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 # initializing the hits list full of zeros hits = [ 0 ] * len ( ray_dir ) invert_hits = [ 0 ] * len ( ray_dir ) # setting the rays that had an intersection to 1 for id in ray_id : hits [ id ] = 1 for id in ray_invert_id : invert_hits [ id ] = 1 sun_count = len ( sun_dirs ) vox_count = len ( vox_cens ) # initiating the list of ratio vox_shadow = [] # iterate over the voxels for v_id in range ( vox_count ): # counter for the intersection int_count = 0 invert_int_count = 0 # iterate over the sun rays for s_id in range ( sun_count ): # computing the ray id from voxel id and sun id r_id = v_id * sun_count + s_id # summing the intersections int_count += hits [ r_id ] if hits [ r_id ] == 0 : invert_int_count += invert_hits [ r_id ] # computing the percentage of the rays that DID NOT have # an intersection (aka could see the sun) sun_access = int_count / sun_count shadowing = invert_int_count / sun_count # add the ratio to list vox_shadow . append ( shadowing ) hits = np . array ( hits ) invert_hits = np . array ( invert_hits ) vox_shadow = np . array ( vox_shadow ) Store sun access information in a lattice 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 # getting the condition of all voxels: are they inside the envelop or not env_all_vox = envelope_lattice_one . flatten () # all voxels sun access all_vox_shadow = [] # v_id: voxel id in the list of only interior voxels v_id = 0 # for all the voxels, place the interiority condition of each voxel in \"vox_in\" for vox_in in env_all_vox : # if the voxel was outside... if vox_in == True : # read its value of sun access and append it to the list of all voxel sun access all_vox_shadow . append ( vox_shadow [ v_id ]) # add one to the voxel id so the next time we read the next voxel v_id += 1 # if the voxel was not inside... else : # add 0.0 for its sun access all_vox_shadow . append ( 0.0 ) # convert to array shadow_array = np . array ( all_vox_shadow ) # reshape to lattice shape shadow_array = shadow_array . reshape ( envelope_lattice_one . shape ) # convert to lattice shadow_lattice = tg . to_lattice ( shadow_array , envelope_lattice_one ) Visualize the sun access lattice 1 f . visualize ( shadow_lattice , \"Shadowing\" , \"../data/shadowing_lowres.png\" ) Interpolate lowres lattice to highres Import highres lattice 1 2 highres_lattice_path = os . path . relpath ( '../data/envelope_highres.csv' ) highres_lattice = tg . lattice_from_csv ( highres_lattice_path ) Define interpolation function 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 def interpolate ( lowres_field ): # loading highres lattice highres_lattice_path = os . path . relpath ( '../data/envelope_highres.csv' ) highres_lat = tg . lattice_from_csv ( highres_lattice_path ) highres_lattice = highres_lat * 0 + 1 # line spaces x_space = np . linspace ( lowres_field . minbound [ 0 ], lowres_field . maxbound [ 0 ], lowres_field . shape [ 0 ]) y_space = np . linspace ( lowres_field . minbound [ 1 ], lowres_field . maxbound [ 1 ], lowres_field . shape [ 1 ]) z_space = np . linspace ( lowres_field . minbound [ 2 ], lowres_field . maxbound [ 2 ], lowres_field . shape [ 2 ]) # interpolation function interpolating_function = RegularGridInterpolator (( x_space , y_space , z_space ), lowres_field , bounds_error = False , fill_value = None ) # high_res lattice full_lattice = highres_lattice + 1 # sample point sample_points = full_lattice . centroids # interpolation interpolated_values = interpolating_function ( sample_points ) # lattice construction interpolated_lattice = tg . to_lattice ( interpolated_values . reshape ( highres_lattice . shape ), highres_lattice ) # nulling the unavailable cells interpolated_lattice *= highres_lattice return interpolated_lattice Interpolate closeness lattice 1 2 highres_shadowing = interpolate ( shadow_lattice ) highres_shadowing_lattice = highres_shadowing * highres_lattice Save interpolated field to csv 1 2 3 # save the interpolated distance field to csv csv_path = os . path . relpath ( \"../data/shadowing.csv\" ) highres_shadowing_lattice . to_csv ( csv_path ) Visualize highres field 1 f . visualize ( highres_shadowing , \"Shadowing\" , \"../data/shadowing_highres.png\" ) Generate configuration Set conditions for the voxels 1 2 3 # the voxels with a higher shadow factor than 0.2 will be excluded highres_shadow_minmax = ( highres_shadowing_lattice <= 0.2 ) * ( highres_shadowing_lattice != 0 ) highres_shadow_minmax . sum () Visualize the solar envelope 1 2 base_lattice = highres_shadow_minmax * highres_shadowing_lattice f . visualize ( base_lattice , \"Shadowing\" , \"../data/shadow_conf.png\" ) Save solar envelope into a csv 1 2 3 # save the solar envelope to csv csv_path = os . path . relpath ( '../data/solar_envelope.csv' ) base_lattice . to_csv ( csv_path ) Credits 1 2 3 4 5 __author__ = \"Shervin Azadi and Pirouz Nourian\" __license__ = \"MIT\" __version__ = \"1.0\" __url__ = \"https://github.com/shervinazadi/spatial_computing_workshops\" __summary__ = \"Spatial Computing Design Studio Workshop on Solar Envelope\"","title":"Shadow"},{"location":"Scripts/shadow/#solar-envelope","text":"","title":"Solar envelope"},{"location":"Scripts/shadow/#initialization","text":"Importing the packages 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 #!pip install ipynb import os import topogenesis as tg import pyvista as pv import trimesh as tm import numpy as np from ladybug.sunpath import Sunpath from scipy.interpolate import RegularGridInterpolator import resources.functions as f # convert mesh to pv_mesh def tri_to_pv ( tri_mesh ): faces = np . pad ( tri_mesh . faces , (( 0 , 0 ),( 1 , 0 )), 'constant' , constant_values = 3 ) pv_mesh = pv . PolyData ( tri_mesh . vertices , faces ) return pv_mesh Importing meshes 1 2 3 4 5 6 7 8 9 10 envelope_path = os . path . relpath ( '../data/new_envelope.obj' ) context_path = os . path . relpath ( '../data/immediate_context.obj' ) # load the mesh from file envelope_mesh = tm . load ( envelope_path ) context_mesh = tm . load ( context_path ) # Check if the mesh is watertight print ( envelope_mesh . is_watertight ) print ( context_mesh . is_watertight ) Importing envelope lattice 1 2 3 4 # loading the lattice from csv lattice_path = os . path . relpath ( '../data/envelope_lowres.csv' ) envelope_lattice = tg . lattice_from_csv ( lattice_path ) envelope_lattice_one = envelope_lattice * 0 + 1","title":"Initialization"},{"location":"Scripts/shadow/#sun-vectors","text":"Importing envelope lattice 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 # initiate sunpath sp = Sunpath ( longitude = 4.3571 , latitude = 52.0116 ) # define sun hours : A list of hours of the year for each sun vector # there are 8760 hours in a year, so the following integers refer to specific hours throughout the year hoys = [] sun_vectors = [] day_multiples = 100 # for each day of the year ... for d in range ( 365 ): # if it is one of the multiples if d % day_multiples == 0 : # for each hour of the day ... for h in range ( 24 ): # compute the hoy (hour of the year) hoy = d * 24 + h # compute the sun object sun = sp . calculate_sun_from_hoy ( hoy ) # extract the sun vector (the direction that the sun ray travels toward) sun_vector = sun . sun_vector . to_array () # evidently, if the Z component of sun vector is positive, # the sun is under the horizon if sun_vector [ 2 ] < 0.0 : hoys . append ( hoy ) sun_vectors . append ( sun_vector ) sun_vectors = np . array ( sun_vectors ) # compute the rotation matrix Rz = tm . transformations . rotation_matrix ( np . radians ( 36.324 ), [ 0 , 0 , 1 ]) # Rotate the sun vectors to match the site rotation sun_vectors = tm . transform_points ( sun_vectors , Rz ) print ( sun_vectors . shape ) # initiating the plotter pv . set_plot_theme ( \"document\" ) p = pv . Plotter ( notebook = True ) # fast visualization of the lattice envelope_lattice_one . fast_vis ( p ) # adding the meshes p . add_mesh ( tri_to_pv ( context_mesh ), opacity = 0.1 , style = 'wireframe' ) # add the sun locations, color orange p . add_points ( - sun_vectors * 300 , color = '#ffa500' ) # plotting #p.show(use_ipyvtk=True)","title":"Sun vectors"},{"location":"Scripts/shadow/#compute-intersection-of-sun-rays-with-context-mesh","text":"Preparing the list of ray directions and origins 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 # constructing the sun direction from the sun vectors in a numpy array sun_dirs = - np . array ( sun_vectors ) # exract the centroids of the envelope voxels vox_cens = envelope_lattice_one . centroids # next step we need to shoot in all of the sun directions from all of the voxels, todo so, we need repeat the sun direction for the number of voxels to construct the ray_dir (which is the list of all ray directions). We need to repeat the voxels for the ray_dir = [] ray_src = [] for v_cen in vox_cens : for s_dir in sun_dirs : ray_dir . append ( s_dir ) ray_src . append ( v_cen ) # converting the list of directions and sources to numpy array ray_dir = np . array ( ray_dir ) ray_src = np . array ( ray_src ) \"\"\" # Further info: this is the vectorised version of nested for loops ray_dir = np.tile(sun_dirs, [len(vox_cens),1]) ray_src = np.tile(vox_cens, [1, len(sun_dirs)]).reshape(-1, 3) \"\"\" print ( \"number of voxels to shoot rays from :\" , vox_cens . shape ) print ( \"number of rays per each voxel :\" , sun_dirs . shape ) print ( \"number of rays to be shooted :\" , ray_src . shape ) Computing the intersection 1 2 3 4 tri_id , ray_id = context_mesh . ray . intersects_id ( ray_origins = ray_src , ray_directions = ray_dir , multiple_hits = False ) # computing the intersections of rays with the context mesh tri_invert_id , ray_invert_id = context_mesh . ray . intersects_id ( ray_origins = ray_src , ray_directions = - ray_dir , multiple_hits = False )","title":"Compute intersection of sun rays with context mesh"},{"location":"Scripts/shadow/#aggregate-simulation-result-in-the-sun-access-lattice","text":"Computing the percentage of time that each voxel sees the sun 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 # initializing the hits list full of zeros hits = [ 0 ] * len ( ray_dir ) invert_hits = [ 0 ] * len ( ray_dir ) # setting the rays that had an intersection to 1 for id in ray_id : hits [ id ] = 1 for id in ray_invert_id : invert_hits [ id ] = 1 sun_count = len ( sun_dirs ) vox_count = len ( vox_cens ) # initiating the list of ratio vox_shadow = [] # iterate over the voxels for v_id in range ( vox_count ): # counter for the intersection int_count = 0 invert_int_count = 0 # iterate over the sun rays for s_id in range ( sun_count ): # computing the ray id from voxel id and sun id r_id = v_id * sun_count + s_id # summing the intersections int_count += hits [ r_id ] if hits [ r_id ] == 0 : invert_int_count += invert_hits [ r_id ] # computing the percentage of the rays that DID NOT have # an intersection (aka could see the sun) sun_access = int_count / sun_count shadowing = invert_int_count / sun_count # add the ratio to list vox_shadow . append ( shadowing ) hits = np . array ( hits ) invert_hits = np . array ( invert_hits ) vox_shadow = np . array ( vox_shadow ) Store sun access information in a lattice 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 # getting the condition of all voxels: are they inside the envelop or not env_all_vox = envelope_lattice_one . flatten () # all voxels sun access all_vox_shadow = [] # v_id: voxel id in the list of only interior voxels v_id = 0 # for all the voxels, place the interiority condition of each voxel in \"vox_in\" for vox_in in env_all_vox : # if the voxel was outside... if vox_in == True : # read its value of sun access and append it to the list of all voxel sun access all_vox_shadow . append ( vox_shadow [ v_id ]) # add one to the voxel id so the next time we read the next voxel v_id += 1 # if the voxel was not inside... else : # add 0.0 for its sun access all_vox_shadow . append ( 0.0 ) # convert to array shadow_array = np . array ( all_vox_shadow ) # reshape to lattice shape shadow_array = shadow_array . reshape ( envelope_lattice_one . shape ) # convert to lattice shadow_lattice = tg . to_lattice ( shadow_array , envelope_lattice_one ) Visualize the sun access lattice 1 f . visualize ( shadow_lattice , \"Shadowing\" , \"../data/shadowing_lowres.png\" )","title":"Aggregate simulation result in the sun access lattice"},{"location":"Scripts/shadow/#interpolate-lowres-lattice-to-highres","text":"Import highres lattice 1 2 highres_lattice_path = os . path . relpath ( '../data/envelope_highres.csv' ) highres_lattice = tg . lattice_from_csv ( highres_lattice_path ) Define interpolation function 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 def interpolate ( lowres_field ): # loading highres lattice highres_lattice_path = os . path . relpath ( '../data/envelope_highres.csv' ) highres_lat = tg . lattice_from_csv ( highres_lattice_path ) highres_lattice = highres_lat * 0 + 1 # line spaces x_space = np . linspace ( lowres_field . minbound [ 0 ], lowres_field . maxbound [ 0 ], lowres_field . shape [ 0 ]) y_space = np . linspace ( lowres_field . minbound [ 1 ], lowres_field . maxbound [ 1 ], lowres_field . shape [ 1 ]) z_space = np . linspace ( lowres_field . minbound [ 2 ], lowres_field . maxbound [ 2 ], lowres_field . shape [ 2 ]) # interpolation function interpolating_function = RegularGridInterpolator (( x_space , y_space , z_space ), lowres_field , bounds_error = False , fill_value = None ) # high_res lattice full_lattice = highres_lattice + 1 # sample point sample_points = full_lattice . centroids # interpolation interpolated_values = interpolating_function ( sample_points ) # lattice construction interpolated_lattice = tg . to_lattice ( interpolated_values . reshape ( highres_lattice . shape ), highres_lattice ) # nulling the unavailable cells interpolated_lattice *= highres_lattice return interpolated_lattice Interpolate closeness lattice 1 2 highres_shadowing = interpolate ( shadow_lattice ) highres_shadowing_lattice = highres_shadowing * highres_lattice Save interpolated field to csv 1 2 3 # save the interpolated distance field to csv csv_path = os . path . relpath ( \"../data/shadowing.csv\" ) highres_shadowing_lattice . to_csv ( csv_path ) Visualize highres field 1 f . visualize ( highres_shadowing , \"Shadowing\" , \"../data/shadowing_highres.png\" )","title":"Interpolate lowres lattice to highres"},{"location":"Scripts/shadow/#generate-configuration","text":"Set conditions for the voxels 1 2 3 # the voxels with a higher shadow factor than 0.2 will be excluded highres_shadow_minmax = ( highres_shadowing_lattice <= 0.2 ) * ( highres_shadowing_lattice != 0 ) highres_shadow_minmax . sum () Visualize the solar envelope 1 2 base_lattice = highres_shadow_minmax * highres_shadowing_lattice f . visualize ( base_lattice , \"Shadowing\" , \"../data/shadow_conf.png\" ) Save solar envelope into a csv 1 2 3 # save the solar envelope to csv csv_path = os . path . relpath ( '../data/solar_envelope.csv' ) base_lattice . to_csv ( csv_path )","title":"Generate configuration"},{"location":"Scripts/shadow/#credits","text":"1 2 3 4 5 __author__ = \"Shervin Azadi and Pirouz Nourian\" __license__ = \"MIT\" __version__ = \"1.0\" __url__ = \"https://github.com/shervinazadi/spatial_computing_workshops\" __summary__ = \"Spatial Computing Design Studio Workshop on Solar Envelope\"","title":"Credits"},{"location":"Scripts/shafts_corridors/","text":"Generative relations: corridor generation Initialization Load required libraries 1 2 3 4 5 6 7 8 9 10 11 # !pip install scikit-learn import os import topogenesis as tg import pyvista as pv import numpy as np import networkx as nx import pandas as pd import trimesh as tm from sklearn.cluster import KMeans np . random . seed ( 0 ) Define the neighbourhood (stencil) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 # creating neighbourhood definition stencil = tg . create_stencil ( \"von_neumann\" , 1 , 1 ) # setting the center to zero stencil . set_index ([ 0 , 0 , 0 ], 0 ) stencil . set_index ([ 0 , 0 , 1 ], 0 ) stencil . set_index ([ 0 , 0 , - 1 ], 0 ) print ( stencil ) # creating neighbourhood definition v_stencil = tg . create_stencil ( \"von_neumann\" , 1 , 1 ) # setting the center to zero v_stencil . set_index ([ 0 , 0 , 0 ], 0 ) v_stencil . set_index ([ 0 , - 1 , 0 ], 0 ) v_stencil . set_index ([ 0 , 1 , 0 ], 0 ) v_stencil . set_index ([ - 1 , 0 , 0 ], 0 ) v_stencil . set_index ([ 1 , 0 , 0 ], 0 ) print ( v_stencil ) Load the envelope lattice as the availability lattice 1 2 3 4 # loading the lattice from csv lattice_path = os . path . relpath ( '../data/envelope_highres.csv' ) avail_lattice = tg . lattice_from_csv ( lattice_path ) init_avail_lattice = tg . to_lattice ( np . copy ( avail_lattice ), avail_lattice ) Load agents information 1 2 3 # loading program (agents information) from CSV program_complete = pd . read_csv ( \"../data/program_req.csv\" ) # program_complete Creation of vertical shaft Agent initialization 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 # Finding the index of the available voxels in avail_lattice avail_flat = avail_lattice . flatten () avail_index = np . array ( np . where ( avail_lattice == 1 )) . T field_path = os . path . relpath ( \"../data/cluster_center_lattice.csv\" ) occ_lattice = tg . lattice_from_csv ( field_path ) agn_num = len ( program_complete ) select_id = np . where ( occ_lattice . flatten () != - 1 ) program_complete [[ \"OX\" , \"OY\" , \"OZ\" ]] = avail_index [ select_id ] # adding the origins to the agents locations agn_locs = [] # for each agent origin ... for a_id , a_info in program_complete . iterrows (): a_origin = a_info [[ \"OX\" , \"OY\" , \"OZ\" ]] . to_list () # add the origin to the list of agent locations agn_locs . append ( a_origin ) # set the origin in availability lattice as 0 (UNavailable) avail_lattice [ tuple ( a_origin )] = 0 Visualizing the agent seeds 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 p = pv . Plotter ( notebook = True ) base_lattice = occ_lattice # Set the grid dimensions: shape + 1 because we want to inject our values on the CELL data grid = pv . UniformGrid () grid . dimensions = np . array ( base_lattice . shape ) + 1 # The bottom left corner of the data set grid . origin = base_lattice . minbound - base_lattice . unit * 0.5 # These are the cell sizes along each axis grid . spacing = base_lattice . unit # adding the boundingbox wireframe p . add_mesh ( grid . outline (), color = \"grey\" , label = \"Domain\" ) # adding axes p . add_axes () p . show_bounds ( grid = \"back\" , location = \"back\" , color = \"#aaaaaa\" ) # Add the data values to the cell data grid . cell_arrays [ \"Agents\" ] = base_lattice . flatten ( order = \"F\" ) . astype ( int ) # Flatten the array! # filtering the voxels threshed = grid . threshold ([ - 0.1 , agn_num - 0.9 ]) # adding the voxels p . add_mesh ( threshed , name = 'sphere' , show_edges = True , opacity = 1.0 , show_scalar_bar = False ) #p.show(use_ipyvtk=True) Cluster the existing voxels and set the vertical column of cluster centers as vertical shafts 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 def grow_shafts ( occ_lattice , avail_lattice ): # extract the address of all occupied voxels occ_ind = np . array ( np . where ( occ_lattice > - 1 )) . T # construct kmeans model and fit it to find the clustering kmeans_model = KMeans ( n_clusters = 4 , random_state = 0 ) . fit ( occ_ind ) # extract cluster centers cluster_centers = np . round ( kmeans_model . cluster_centers_ ) . astype ( np . int8 ) print ( cluster_centers ) # init shaft lattice shft_lattice = occ_lattice * 0 # set the shafts for cl_cen in cluster_centers : shft_lattice [ cl_cen [ 0 ], cl_cen [ 1 ], :] = 1 return shft_lattice shft_lattice = grow_shafts ( occ_lattice , avail_lattice ) Visualize vertical shafts 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 pv . set_plot_theme ( \"document\" ) p = pv . Plotter ( notebook = True ) base_lattice = shft_lattice # Set the grid dimensions: shape + 1 because we want to inject our values on the CELL data grid = pv . UniformGrid () grid . dimensions = np . array ( base_lattice . shape ) + 1 # The bottom left corner of the data set grid . origin = base_lattice . minbound - base_lattice . unit * 0.5 # These are the cell sizes along each axis grid . spacing = base_lattice . unit # adding the boundingbox wireframe p . add_mesh ( grid . outline (), color = \"grey\" , label = \"Domain\" ) # adding axes p . add_axes () p . show_bounds ( grid = \"back\" , location = \"back\" , color = \"#aaaaaa\" ) # Add the data values to the cell data grid . cell_arrays [ \"Agents\" ] = base_lattice . flatten ( order = \"F\" ) . astype ( int ) # Flatten the array! # filtering the voxels threshed = grid . threshold ([ 0.9 , 1.1 ]) # adding the voxels p . add_mesh ( threshed , name = 'sphere' , show_edges = True , opacity = 1.0 , show_scalar_bar = False ) #p.show(use_ipyvtk=True) p . show ( screenshot = \"../data/shafts.png\" ) Save shafts to csv 1 2 3 # save the distance latice to csv csv_path = os . path . relpath ( \"../data/shafts.csv\" ) shft_lattice . to_csv ( csv_path ) Select the entrance voxel (highres) Make envelope padded 1 2 3 env_padded_array = np . pad ( avail_lattice , 1 ) padded_minbound = avail_lattice . minbound - avail_lattice . unit env_padded_lattice = tg . to_lattice ( env_padded_array , minbound = padded_minbound , unit = avail_lattice . unit ) Importing the street points and public transport points 1 2 street_transport_path = os . path . relpath ( '../data/mainstreet_publictransport.xyz.txt' ) street_transport = np . genfromtxt ( street_transport_path , delimiter = ',' ) Distance matrix 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 # extracting the centroid of all voxels env_cens = env_padded_lattice . centroids_threshold ( - 1 ) # initializing the distance matrix dist_m = [] # for each voxel ... for voxel_cen in env_cens : # initializing the distance vector (per each voxel) dist_v = [] # for each street point ... for street_transport_point in street_transport : # find the difference vector diff = voxel_cen - street_transport_point # raise the components to the power of two diff_p2 = diff ** 2 # sum the components diff_p2s = diff_p2 . sum () # compute the square root dist = diff_p2s ** 0.5 # add the distance to the distance vector dist_v . append ( dist ) # add the distance vector to the distance matrix dist_m . append ( dist_v ) # change the distance matrix type, from list to array dist_m = np . array ( dist_m ) Finding min distance to street and public transport 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 # amount of points in the list (street points and public transport points) print ( len ( street_transport )) # average of the distances to each point per voxel av_dist = [] for str_trans_points in dist_m : av_dist_vox = str_trans_points . sum () / len ( street_transport ) av_dist . append ( av_dist_vox ) #print(av_dist) # Find the voxel with the minimum average distance min_dist = np . min ( av_dist ) print ( min_dist ) # Find the index of this voxel min_index_ent = np . argmin ( av_dist ) ent_index_3d = np . unravel_index ( min_index_ent , env_padded_lattice . shape ) ent_ar_3d = np . array ( ent_index_3d ) print ( ent_ar_3d ) Creation of horizontal corridors Find shortest paths 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 # find the number of all voxels vox_count = avail_lattice . size # initialize the adjacency matrix adj_mtrx = np . zeros (( vox_count , vox_count )) # Finding the index of the available voxels in avail_lattice avail_index = np . array ( np . where ( avail_lattice == 1 )) . T # fill the adjacency matrix using the list of all neighbours for vox_loc in avail_index : # find the 1D id vox_id = np . ravel_multi_index ( vox_loc , avail_lattice . shape ) # retrieve the list of neighbours of the voxel based on the stencil vox_neighs = avail_lattice . find_neighbours_masked ( stencil , loc = vox_loc ) # iterating over the neighbours for neigh in vox_neighs : # setting the entry to one adj_mtrx [ vox_id , neigh ] = 1.0 # construct the graph g = nx . from_numpy_array ( adj_mtrx ) # initialize corridor lattice cor_lattice = shft_lattice * 0 cor_flat = cor_lattice . flatten () # for each voxel that needs to have access to shafts occ_ind = np . array ( np . where ( occ_lattice > - 1 )) . T for a_vox in occ_ind : # slice the corridor lattice horizontally cor_floor = shft_lattice [:,:, a_vox [ 2 ]] # find the vertical shaft voxel indices shaft_vox_inds = np . array ( np . where ( cor_floor > 0 )) . T paths = [] path_lens = [] paths_entrance = [] for shft_ind in shaft_vox_inds : dst_vox_ent = np . array ([ shft_ind [ 0 ], shft_ind [ 1 ], ent_index_3d [ 2 ]]) # construct 1-dimensional indices src_ind_ent = np . ravel_multi_index ( ent_ar_3d , shft_lattice . shape ) dst_ind_ent = np . ravel_multi_index ( dst_vox_ent , shft_lattice . shape ) path_ent = nx . algorithms . shortest_paths . astar . astar_path ( g , src_ind_ent , dst_ind_ent ) paths_entrance . append ( path_ent ) for p in range ( len ( paths_entrance )): cor_flat [ paths_entrance [ p ]] = 1 for shft_ind in shaft_vox_inds : # construct the destination address dst_vox = np . array ([ shft_ind [ 0 ], shft_ind [ 1 ], a_vox [ 2 ]]) # construct 1-dimensional indices src_ind = np . ravel_multi_index ( a_vox , shft_lattice . shape ) dst_ind = np . ravel_multi_index ( dst_vox , shft_lattice . shape ) # find the shortest path path = nx . algorithms . shortest_paths . astar . astar_path ( g , src_ind , dst_ind ) paths . append ( path ) path_lens . append ( len ( path )) # find the shortest path shortest_path = paths [ np . array ( path_lens ) . argmin ()] print ( shortest_path ) # set the shortest path occupied in the cor_flat [ shortest_path ] = 1 # reshape the flat lattice cor_lattice = cor_flat . reshape ( cor_lattice . shape ) Visualize the corridors 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 p = pv . Plotter ( notebook = True ) base_lattice = cor_lattice # Set the grid dimensions: shape + 1 because we want to inject our values on the CELL data grid = pv . UniformGrid () grid . dimensions = np . array ( base_lattice . shape ) + 1 # The bottom left corner of the data set grid . origin = base_lattice . minbound - base_lattice . unit * 0.5 # These are the cell sizes along each axis grid . spacing = base_lattice . unit # adding the boundingbox wireframe p . add_mesh ( grid . outline (), color = \"grey\" , label = \"Domain\" ) # adding the availability lattice #init_avail_lattice.fast_vis(p) # adding axes p . add_axes () p . show_bounds ( grid = \"back\" , location = \"back\" , color = \"#aaaaaa\" ) # Add the data values to the cell data grid . cell_arrays [ \"Agents\" ] = base_lattice . flatten ( order = \"F\" ) . astype ( int ) # Flatten the array! # filtering the voxels threshed = grid . threshold ([ 0.9 , 2.1 ]) # adding the voxels p . add_mesh ( threshed , name = 'sphere' , show_edges = True , opacity = 1.0 , show_scalar_bar = False ) #p.show(use_ipyvtk=True) #p.show(screenshot=\"../data/corridors.png\") Save corridors to csv 1 2 3 #save the distance latice to csv csv_path = os . path . relpath ( \"../data/corridors.csv\" ) cor_lattice . to_csv ( csv_path ) Combine shafts and corridors 1 2 3 4 5 path_lattice = shft_lattice + cor_lattice # save the distance latice to csv csv_path = os . path . relpath ( \"../data/shafts_corridors.csv\" ) path_lattice . to_csv ( csv_path ) Credits 1 2 3 4 5 __author__ = \"Shervin Azadi and Pirouz Nourian\" __license__ = \"MIT\" __version__ = \"1.0\" __url__ = \"https://github.com/shervinazadi/spatial_computing_workshops\" __summary__ = \"Spatial Computing Design Studio Workshop on Path Finding and Corridorfor Generative Spatial Relations\"","title":"Shafts"},{"location":"Scripts/shafts_corridors/#generative-relations-corridor-generation","text":"","title":"Generative relations: corridor generation"},{"location":"Scripts/shafts_corridors/#initialization","text":"Load required libraries 1 2 3 4 5 6 7 8 9 10 11 # !pip install scikit-learn import os import topogenesis as tg import pyvista as pv import numpy as np import networkx as nx import pandas as pd import trimesh as tm from sklearn.cluster import KMeans np . random . seed ( 0 ) Define the neighbourhood (stencil) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 # creating neighbourhood definition stencil = tg . create_stencil ( \"von_neumann\" , 1 , 1 ) # setting the center to zero stencil . set_index ([ 0 , 0 , 0 ], 0 ) stencil . set_index ([ 0 , 0 , 1 ], 0 ) stencil . set_index ([ 0 , 0 , - 1 ], 0 ) print ( stencil ) # creating neighbourhood definition v_stencil = tg . create_stencil ( \"von_neumann\" , 1 , 1 ) # setting the center to zero v_stencil . set_index ([ 0 , 0 , 0 ], 0 ) v_stencil . set_index ([ 0 , - 1 , 0 ], 0 ) v_stencil . set_index ([ 0 , 1 , 0 ], 0 ) v_stencil . set_index ([ - 1 , 0 , 0 ], 0 ) v_stencil . set_index ([ 1 , 0 , 0 ], 0 ) print ( v_stencil ) Load the envelope lattice as the availability lattice 1 2 3 4 # loading the lattice from csv lattice_path = os . path . relpath ( '../data/envelope_highres.csv' ) avail_lattice = tg . lattice_from_csv ( lattice_path ) init_avail_lattice = tg . to_lattice ( np . copy ( avail_lattice ), avail_lattice ) Load agents information 1 2 3 # loading program (agents information) from CSV program_complete = pd . read_csv ( \"../data/program_req.csv\" ) # program_complete","title":"Initialization"},{"location":"Scripts/shafts_corridors/#creation-of-vertical-shaft","text":"Agent initialization 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 # Finding the index of the available voxels in avail_lattice avail_flat = avail_lattice . flatten () avail_index = np . array ( np . where ( avail_lattice == 1 )) . T field_path = os . path . relpath ( \"../data/cluster_center_lattice.csv\" ) occ_lattice = tg . lattice_from_csv ( field_path ) agn_num = len ( program_complete ) select_id = np . where ( occ_lattice . flatten () != - 1 ) program_complete [[ \"OX\" , \"OY\" , \"OZ\" ]] = avail_index [ select_id ] # adding the origins to the agents locations agn_locs = [] # for each agent origin ... for a_id , a_info in program_complete . iterrows (): a_origin = a_info [[ \"OX\" , \"OY\" , \"OZ\" ]] . to_list () # add the origin to the list of agent locations agn_locs . append ( a_origin ) # set the origin in availability lattice as 0 (UNavailable) avail_lattice [ tuple ( a_origin )] = 0 Visualizing the agent seeds 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 p = pv . Plotter ( notebook = True ) base_lattice = occ_lattice # Set the grid dimensions: shape + 1 because we want to inject our values on the CELL data grid = pv . UniformGrid () grid . dimensions = np . array ( base_lattice . shape ) + 1 # The bottom left corner of the data set grid . origin = base_lattice . minbound - base_lattice . unit * 0.5 # These are the cell sizes along each axis grid . spacing = base_lattice . unit # adding the boundingbox wireframe p . add_mesh ( grid . outline (), color = \"grey\" , label = \"Domain\" ) # adding axes p . add_axes () p . show_bounds ( grid = \"back\" , location = \"back\" , color = \"#aaaaaa\" ) # Add the data values to the cell data grid . cell_arrays [ \"Agents\" ] = base_lattice . flatten ( order = \"F\" ) . astype ( int ) # Flatten the array! # filtering the voxels threshed = grid . threshold ([ - 0.1 , agn_num - 0.9 ]) # adding the voxels p . add_mesh ( threshed , name = 'sphere' , show_edges = True , opacity = 1.0 , show_scalar_bar = False ) #p.show(use_ipyvtk=True) Cluster the existing voxels and set the vertical column of cluster centers as vertical shafts 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 def grow_shafts ( occ_lattice , avail_lattice ): # extract the address of all occupied voxels occ_ind = np . array ( np . where ( occ_lattice > - 1 )) . T # construct kmeans model and fit it to find the clustering kmeans_model = KMeans ( n_clusters = 4 , random_state = 0 ) . fit ( occ_ind ) # extract cluster centers cluster_centers = np . round ( kmeans_model . cluster_centers_ ) . astype ( np . int8 ) print ( cluster_centers ) # init shaft lattice shft_lattice = occ_lattice * 0 # set the shafts for cl_cen in cluster_centers : shft_lattice [ cl_cen [ 0 ], cl_cen [ 1 ], :] = 1 return shft_lattice shft_lattice = grow_shafts ( occ_lattice , avail_lattice ) Visualize vertical shafts 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 pv . set_plot_theme ( \"document\" ) p = pv . Plotter ( notebook = True ) base_lattice = shft_lattice # Set the grid dimensions: shape + 1 because we want to inject our values on the CELL data grid = pv . UniformGrid () grid . dimensions = np . array ( base_lattice . shape ) + 1 # The bottom left corner of the data set grid . origin = base_lattice . minbound - base_lattice . unit * 0.5 # These are the cell sizes along each axis grid . spacing = base_lattice . unit # adding the boundingbox wireframe p . add_mesh ( grid . outline (), color = \"grey\" , label = \"Domain\" ) # adding axes p . add_axes () p . show_bounds ( grid = \"back\" , location = \"back\" , color = \"#aaaaaa\" ) # Add the data values to the cell data grid . cell_arrays [ \"Agents\" ] = base_lattice . flatten ( order = \"F\" ) . astype ( int ) # Flatten the array! # filtering the voxels threshed = grid . threshold ([ 0.9 , 1.1 ]) # adding the voxels p . add_mesh ( threshed , name = 'sphere' , show_edges = True , opacity = 1.0 , show_scalar_bar = False ) #p.show(use_ipyvtk=True) p . show ( screenshot = \"../data/shafts.png\" ) Save shafts to csv 1 2 3 # save the distance latice to csv csv_path = os . path . relpath ( \"../data/shafts.csv\" ) shft_lattice . to_csv ( csv_path )","title":"Creation of vertical shaft"},{"location":"Scripts/shafts_corridors/#select-the-entrance-voxel-highres","text":"Make envelope padded 1 2 3 env_padded_array = np . pad ( avail_lattice , 1 ) padded_minbound = avail_lattice . minbound - avail_lattice . unit env_padded_lattice = tg . to_lattice ( env_padded_array , minbound = padded_minbound , unit = avail_lattice . unit ) Importing the street points and public transport points 1 2 street_transport_path = os . path . relpath ( '../data/mainstreet_publictransport.xyz.txt' ) street_transport = np . genfromtxt ( street_transport_path , delimiter = ',' ) Distance matrix 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 # extracting the centroid of all voxels env_cens = env_padded_lattice . centroids_threshold ( - 1 ) # initializing the distance matrix dist_m = [] # for each voxel ... for voxel_cen in env_cens : # initializing the distance vector (per each voxel) dist_v = [] # for each street point ... for street_transport_point in street_transport : # find the difference vector diff = voxel_cen - street_transport_point # raise the components to the power of two diff_p2 = diff ** 2 # sum the components diff_p2s = diff_p2 . sum () # compute the square root dist = diff_p2s ** 0.5 # add the distance to the distance vector dist_v . append ( dist ) # add the distance vector to the distance matrix dist_m . append ( dist_v ) # change the distance matrix type, from list to array dist_m = np . array ( dist_m ) Finding min distance to street and public transport 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 # amount of points in the list (street points and public transport points) print ( len ( street_transport )) # average of the distances to each point per voxel av_dist = [] for str_trans_points in dist_m : av_dist_vox = str_trans_points . sum () / len ( street_transport ) av_dist . append ( av_dist_vox ) #print(av_dist) # Find the voxel with the minimum average distance min_dist = np . min ( av_dist ) print ( min_dist ) # Find the index of this voxel min_index_ent = np . argmin ( av_dist ) ent_index_3d = np . unravel_index ( min_index_ent , env_padded_lattice . shape ) ent_ar_3d = np . array ( ent_index_3d ) print ( ent_ar_3d )","title":"Select the entrance voxel (highres)"},{"location":"Scripts/shafts_corridors/#creation-of-horizontal-corridors","text":"Find shortest paths 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 # find the number of all voxels vox_count = avail_lattice . size # initialize the adjacency matrix adj_mtrx = np . zeros (( vox_count , vox_count )) # Finding the index of the available voxels in avail_lattice avail_index = np . array ( np . where ( avail_lattice == 1 )) . T # fill the adjacency matrix using the list of all neighbours for vox_loc in avail_index : # find the 1D id vox_id = np . ravel_multi_index ( vox_loc , avail_lattice . shape ) # retrieve the list of neighbours of the voxel based on the stencil vox_neighs = avail_lattice . find_neighbours_masked ( stencil , loc = vox_loc ) # iterating over the neighbours for neigh in vox_neighs : # setting the entry to one adj_mtrx [ vox_id , neigh ] = 1.0 # construct the graph g = nx . from_numpy_array ( adj_mtrx ) # initialize corridor lattice cor_lattice = shft_lattice * 0 cor_flat = cor_lattice . flatten () # for each voxel that needs to have access to shafts occ_ind = np . array ( np . where ( occ_lattice > - 1 )) . T for a_vox in occ_ind : # slice the corridor lattice horizontally cor_floor = shft_lattice [:,:, a_vox [ 2 ]] # find the vertical shaft voxel indices shaft_vox_inds = np . array ( np . where ( cor_floor > 0 )) . T paths = [] path_lens = [] paths_entrance = [] for shft_ind in shaft_vox_inds : dst_vox_ent = np . array ([ shft_ind [ 0 ], shft_ind [ 1 ], ent_index_3d [ 2 ]]) # construct 1-dimensional indices src_ind_ent = np . ravel_multi_index ( ent_ar_3d , shft_lattice . shape ) dst_ind_ent = np . ravel_multi_index ( dst_vox_ent , shft_lattice . shape ) path_ent = nx . algorithms . shortest_paths . astar . astar_path ( g , src_ind_ent , dst_ind_ent ) paths_entrance . append ( path_ent ) for p in range ( len ( paths_entrance )): cor_flat [ paths_entrance [ p ]] = 1 for shft_ind in shaft_vox_inds : # construct the destination address dst_vox = np . array ([ shft_ind [ 0 ], shft_ind [ 1 ], a_vox [ 2 ]]) # construct 1-dimensional indices src_ind = np . ravel_multi_index ( a_vox , shft_lattice . shape ) dst_ind = np . ravel_multi_index ( dst_vox , shft_lattice . shape ) # find the shortest path path = nx . algorithms . shortest_paths . astar . astar_path ( g , src_ind , dst_ind ) paths . append ( path ) path_lens . append ( len ( path )) # find the shortest path shortest_path = paths [ np . array ( path_lens ) . argmin ()] print ( shortest_path ) # set the shortest path occupied in the cor_flat [ shortest_path ] = 1 # reshape the flat lattice cor_lattice = cor_flat . reshape ( cor_lattice . shape ) Visualize the corridors 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 p = pv . Plotter ( notebook = True ) base_lattice = cor_lattice # Set the grid dimensions: shape + 1 because we want to inject our values on the CELL data grid = pv . UniformGrid () grid . dimensions = np . array ( base_lattice . shape ) + 1 # The bottom left corner of the data set grid . origin = base_lattice . minbound - base_lattice . unit * 0.5 # These are the cell sizes along each axis grid . spacing = base_lattice . unit # adding the boundingbox wireframe p . add_mesh ( grid . outline (), color = \"grey\" , label = \"Domain\" ) # adding the availability lattice #init_avail_lattice.fast_vis(p) # adding axes p . add_axes () p . show_bounds ( grid = \"back\" , location = \"back\" , color = \"#aaaaaa\" ) # Add the data values to the cell data grid . cell_arrays [ \"Agents\" ] = base_lattice . flatten ( order = \"F\" ) . astype ( int ) # Flatten the array! # filtering the voxels threshed = grid . threshold ([ 0.9 , 2.1 ]) # adding the voxels p . add_mesh ( threshed , name = 'sphere' , show_edges = True , opacity = 1.0 , show_scalar_bar = False ) #p.show(use_ipyvtk=True) #p.show(screenshot=\"../data/corridors.png\") Save corridors to csv 1 2 3 #save the distance latice to csv csv_path = os . path . relpath ( \"../data/corridors.csv\" ) cor_lattice . to_csv ( csv_path ) Combine shafts and corridors 1 2 3 4 5 path_lattice = shft_lattice + cor_lattice # save the distance latice to csv csv_path = os . path . relpath ( \"../data/shafts_corridors.csv\" ) path_lattice . to_csv ( csv_path )","title":"Creation of horizontal corridors"},{"location":"Scripts/shafts_corridors/#credits","text":"1 2 3 4 5 __author__ = \"Shervin Azadi and Pirouz Nourian\" __license__ = \"MIT\" __version__ = \"1.0\" __url__ = \"https://github.com/shervinazadi/spatial_computing_workshops\" __summary__ = \"Spatial Computing Design Studio Workshop on Path Finding and Corridorfor Generative Spatial Relations\"","title":"Credits"},{"location":"Scripts/sun_acc/","text":"Solar envelope Initialization 1 #!pip install ipynb Importing the packages 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 import os import topogenesis as tg import pyvista as pv import trimesh as tm import numpy as np from ladybug.sunpath import Sunpath from scipy.interpolate import RegularGridInterpolator import resources.functions as f # convert mesh to pv_mesh def tri_to_pv ( tri_mesh ): faces = np . pad ( tri_mesh . faces , (( 0 , 0 ),( 1 , 0 )), 'constant' , constant_values = 3 ) pv_mesh = pv . PolyData ( tri_mesh . vertices , faces ) return pv_mesh Import meshes 1 2 3 4 5 6 7 8 9 10 envelope_path = os . path . relpath ( '../data/new_envelope.obj' ) context_path = os . path . relpath ( '../data/immediate_context.obj' ) # load the mesh from file envelope_mesh = tm . load ( envelope_path ) context_mesh = tm . load ( context_path ) # Check if the mesh is watertight print ( envelope_mesh . is_watertight ) print ( context_mesh . is_watertight ) Importing the envelope lattice 1 2 3 4 # loading the lattice from csv lattice_path = os . path . relpath ( '../data/envelope_lowres.csv' ) envelope_lattice = tg . lattice_from_csv ( lattice_path ) envelope_lattice_one = envelope_lattice * 0 + 1 Sun vectors Compute sun vectors 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 # initiate sunpath sp = Sunpath ( longitude = 4.3571 , latitude = 52.0116 ) # define sun hours : A list of hours of the year for each sun vector # there are 8760 hours in a year, so the following integers refer to specific hours throughout the year hoys = [] sun_vectors = [] day_multiples = 80 # for each day of the year ... for d in range ( 365 ): # if it is one of the multiples if d % day_multiples == 0 : # for each hour of the day ... for h in range ( 24 ): # compute the hoy (hour of the year) hoy = d * 24 + h # compute the sun object sun = sp . calculate_sun_from_hoy ( hoy ) # extract the sun vector (the direction that the sun ray travels toward) sun_vector = sun . sun_vector . to_array () # evidently, if the Z component of sun vector is positive, # the sun is under the horizon if sun_vector [ 2 ] < 0.0 : hoys . append ( hoy ) sun_vectors . append ( sun_vector ) sun_vectors = np . array ( sun_vectors ) # compute the rotation matrix Rz = tm . transformations . rotation_matrix ( np . radians ( 36.324 ), [ 0 , 0 , 1 ]) # Rotate the sun vectors to match the site rotation sun_vectors = tm . transform_points ( sun_vectors , Rz ) Visualize sun points 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # initiating the plotter p = pv . Plotter ( notebook = True ) pv . set_plot_theme ( \"document\" ) # fast visualization of the lattice envelope_lattice . fast_vis ( p ) # adding the meshes p . add_mesh ( tri_to_pv ( context_mesh ), opacity = 0.1 , style = 'wireframe' ) # add the sun locations, color orange p . add_points ( - sun_vectors * 300 , color = '#ffa500' ) # plotting #p.show(use_ipyvtk=True) Compute intersection of sun rays with context mesh Preparing the list of ray directions and origins 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 # constructing the sun direction from the sun vectors in a numpy array sun_dirs = - np . array ( sun_vectors ) # exract the centroids of the envelope voxels vox_cens = envelope_lattice_one . centroids # next step we need to shoot in all of the sun directions from all of the voxels, todo so, we need repeat the sun direction for the number of voxels to construct the ray_dir (which is the list of all ray directions). We need to repeat the voxels for the ray_dir = [] ray_src = [] for v_cen in vox_cens : for s_dir in sun_dirs : ray_dir . append ( s_dir ) ray_src . append ( v_cen ) # converting the list of directions and sources to numpy array ray_dir = np . array ( ray_dir ) ray_src = np . array ( ray_src ) print ( \"number of voxels to shoot rays from :\" , vox_cens . shape ) print ( \"number of rays per each voxel :\" , sun_dirs . shape ) print ( \"number of rays to be shooted :\" , ray_src . shape ) Computing the intersection 1 2 # computing the intersections of rays with the context mesh tri_id , ray_id = context_mesh . ray . intersects_id ( ray_origins = ray_src , ray_directions = ray_dir , multiple_hits = False ) Aggregate simulation result in the sun access lattice Compute the percentage of time that each voxel sees the sun 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 # initializing the hits list full of zeros hits = [ 0 ] * len ( ray_dir ) # setting the rays that had an intersection to 1 for id in ray_id : hits [ id ] = 1 sun_count = len ( sun_dirs ) vox_count = len ( vox_cens ) # initiating the list of ratio vox_sun_acc = [] # iterate over the voxels for v_id in range ( vox_count ): # counter for the intersection int_count = 0 invert_int_count = 0 # iterate over the sun rays for s_id in range ( sun_count ): # computing the ray id from voxel id and sun id r_id = v_id * sun_count + s_id # summing the intersections int_count += hits [ r_id ] # computing the percentage of the rays that DID NOT have # an intersection (aka could see the sun) sun_access = int_count / sun_count # add the ratio to list vox_sun_acc . append ( sun_access ) hits = np . array ( hits ) vox_sun_acc = np . array ( vox_sun_acc ) Store sun access information in a lattice 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 # getting the condition of all voxels: are they inside the envelop or not env_all_vox = envelope_lattice_one . flatten () # all voxels sun access all_vox_sun_acc = [] # v_id: voxel id in the list of only interior voxels v_id = 0 # for all the voxels, place the interiority condition of each voxel in \"vox_in\" for vox_in in env_all_vox : # if the voxel was outside... if vox_in == True : # read its value of sun access and append it to the list of all voxel sun access all_vox_sun_acc . append ( vox_sun_acc [ v_id ]) # add one to the voxel id so the next time we read the next voxel v_id += 1 # if the voxel was not inside... else : # add 0.0 for its sun access all_vox_sun_acc . append ( 0.0 ) # convert to array sunacc_array = np . array ( all_vox_sun_acc ) # reshape to lattice shape sunacc_array = sunacc_array . reshape ( envelope_lattice_one . shape ) # convert to lattice sun_lattice = tg . to_lattice ( sunacc_array , envelope_lattice_one ) # invert the values of the lattice (1 = a lot of sun, 0 = no sun) sunacc_lattice = ( 1 - sun_lattice ) * envelope_lattice Visualize the sun access lattice 1 f . visualize (( 1 - sun_lattice ), \"Sun access\" , \"../data/sun_acc_lowres\" ) Interpolate lowres lattice to highres Import highres lattice 1 2 3 # loading highres lattice highres_lattice_path = os . path . relpath ( '../data/envelope_highres.csv' ) highres_lattice = tg . lattice_from_csv ( highres_lattice_path ) Define interpolation function 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 def interpolate ( lowres_field ): # loading highres lattice highres_lattice_path = os . path . relpath ( '../data/envelope_highres.csv' ) highres_lat = tg . lattice_from_csv ( highres_lattice_path ) highres_lattice = highres_lat * 0 + 1 # line spaces x_space = np . linspace ( lowres_field . minbound [ 0 ], lowres_field . maxbound [ 0 ], lowres_field . shape [ 0 ]) y_space = np . linspace ( lowres_field . minbound [ 1 ], lowres_field . maxbound [ 1 ], lowres_field . shape [ 1 ]) z_space = np . linspace ( lowres_field . minbound [ 2 ], lowres_field . maxbound [ 2 ], lowres_field . shape [ 2 ]) # interpolation function interpolating_function = RegularGridInterpolator (( x_space , y_space , z_space ), lowres_field , bounds_error = False , fill_value = None ) # high_res lattice full_lattice = highres_lattice + 1 # sample point sample_points = full_lattice . centroids # interpolation interpolated_values = interpolating_function ( sample_points ) # lattice construction interpolated_lattice = tg . to_lattice ( interpolated_values . reshape ( highres_lattice . shape ), highres_lattice ) # nulling the unavailable cells interpolated_lattice *= highres_lattice return interpolated_lattice Interpolate closeness lattice 1 2 3 4 highres_sunacc = interpolate ( 1 - sun_lattice ) # multipy by lattice to exclude the voxels which are outside the envelope highres_sunacc_lattice = highres_sunacc * highres_lattice Save interpolated field to csv 1 2 3 # save the sun access latice to csv csv_path = os . path . relpath ( '../data/sun_acc.csv' ) highres_sunacc_lattice . to_csv ( csv_path ) Visualize highres field 1 f . visualize ( highres_sunacc , \"Sun access\" , \"../data/sun_acc_highres.png\" ) Credits 1 2 3 4 5 __author__ = \"Shervin Azadi and Pirouz Nourian\" __license__ = \"MIT\" __version__ = \"1.0\" __url__ = \"https://github.com/shervinazadi/spatial_computing_workshops\" __summary__ = \"Spatial Computing Design Studio Workshop on Solar Envelope\"","title":"Sun"},{"location":"Scripts/sun_acc/#solar-envelope","text":"Initialization 1 #!pip install ipynb Importing the packages 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 import os import topogenesis as tg import pyvista as pv import trimesh as tm import numpy as np from ladybug.sunpath import Sunpath from scipy.interpolate import RegularGridInterpolator import resources.functions as f # convert mesh to pv_mesh def tri_to_pv ( tri_mesh ): faces = np . pad ( tri_mesh . faces , (( 0 , 0 ),( 1 , 0 )), 'constant' , constant_values = 3 ) pv_mesh = pv . PolyData ( tri_mesh . vertices , faces ) return pv_mesh Import meshes 1 2 3 4 5 6 7 8 9 10 envelope_path = os . path . relpath ( '../data/new_envelope.obj' ) context_path = os . path . relpath ( '../data/immediate_context.obj' ) # load the mesh from file envelope_mesh = tm . load ( envelope_path ) context_mesh = tm . load ( context_path ) # Check if the mesh is watertight print ( envelope_mesh . is_watertight ) print ( context_mesh . is_watertight ) Importing the envelope lattice 1 2 3 4 # loading the lattice from csv lattice_path = os . path . relpath ( '../data/envelope_lowres.csv' ) envelope_lattice = tg . lattice_from_csv ( lattice_path ) envelope_lattice_one = envelope_lattice * 0 + 1","title":"Solar envelope"},{"location":"Scripts/sun_acc/#sun-vectors","text":"Compute sun vectors 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 # initiate sunpath sp = Sunpath ( longitude = 4.3571 , latitude = 52.0116 ) # define sun hours : A list of hours of the year for each sun vector # there are 8760 hours in a year, so the following integers refer to specific hours throughout the year hoys = [] sun_vectors = [] day_multiples = 80 # for each day of the year ... for d in range ( 365 ): # if it is one of the multiples if d % day_multiples == 0 : # for each hour of the day ... for h in range ( 24 ): # compute the hoy (hour of the year) hoy = d * 24 + h # compute the sun object sun = sp . calculate_sun_from_hoy ( hoy ) # extract the sun vector (the direction that the sun ray travels toward) sun_vector = sun . sun_vector . to_array () # evidently, if the Z component of sun vector is positive, # the sun is under the horizon if sun_vector [ 2 ] < 0.0 : hoys . append ( hoy ) sun_vectors . append ( sun_vector ) sun_vectors = np . array ( sun_vectors ) # compute the rotation matrix Rz = tm . transformations . rotation_matrix ( np . radians ( 36.324 ), [ 0 , 0 , 1 ]) # Rotate the sun vectors to match the site rotation sun_vectors = tm . transform_points ( sun_vectors , Rz ) Visualize sun points 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # initiating the plotter p = pv . Plotter ( notebook = True ) pv . set_plot_theme ( \"document\" ) # fast visualization of the lattice envelope_lattice . fast_vis ( p ) # adding the meshes p . add_mesh ( tri_to_pv ( context_mesh ), opacity = 0.1 , style = 'wireframe' ) # add the sun locations, color orange p . add_points ( - sun_vectors * 300 , color = '#ffa500' ) # plotting #p.show(use_ipyvtk=True)","title":"Sun vectors"},{"location":"Scripts/sun_acc/#compute-intersection-of-sun-rays-with-context-mesh","text":"Preparing the list of ray directions and origins 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 # constructing the sun direction from the sun vectors in a numpy array sun_dirs = - np . array ( sun_vectors ) # exract the centroids of the envelope voxels vox_cens = envelope_lattice_one . centroids # next step we need to shoot in all of the sun directions from all of the voxels, todo so, we need repeat the sun direction for the number of voxels to construct the ray_dir (which is the list of all ray directions). We need to repeat the voxels for the ray_dir = [] ray_src = [] for v_cen in vox_cens : for s_dir in sun_dirs : ray_dir . append ( s_dir ) ray_src . append ( v_cen ) # converting the list of directions and sources to numpy array ray_dir = np . array ( ray_dir ) ray_src = np . array ( ray_src ) print ( \"number of voxels to shoot rays from :\" , vox_cens . shape ) print ( \"number of rays per each voxel :\" , sun_dirs . shape ) print ( \"number of rays to be shooted :\" , ray_src . shape ) Computing the intersection 1 2 # computing the intersections of rays with the context mesh tri_id , ray_id = context_mesh . ray . intersects_id ( ray_origins = ray_src , ray_directions = ray_dir , multiple_hits = False )","title":"Compute intersection of sun rays with context mesh"},{"location":"Scripts/sun_acc/#aggregate-simulation-result-in-the-sun-access-lattice","text":"Compute the percentage of time that each voxel sees the sun 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 # initializing the hits list full of zeros hits = [ 0 ] * len ( ray_dir ) # setting the rays that had an intersection to 1 for id in ray_id : hits [ id ] = 1 sun_count = len ( sun_dirs ) vox_count = len ( vox_cens ) # initiating the list of ratio vox_sun_acc = [] # iterate over the voxels for v_id in range ( vox_count ): # counter for the intersection int_count = 0 invert_int_count = 0 # iterate over the sun rays for s_id in range ( sun_count ): # computing the ray id from voxel id and sun id r_id = v_id * sun_count + s_id # summing the intersections int_count += hits [ r_id ] # computing the percentage of the rays that DID NOT have # an intersection (aka could see the sun) sun_access = int_count / sun_count # add the ratio to list vox_sun_acc . append ( sun_access ) hits = np . array ( hits ) vox_sun_acc = np . array ( vox_sun_acc ) Store sun access information in a lattice 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 # getting the condition of all voxels: are they inside the envelop or not env_all_vox = envelope_lattice_one . flatten () # all voxels sun access all_vox_sun_acc = [] # v_id: voxel id in the list of only interior voxels v_id = 0 # for all the voxels, place the interiority condition of each voxel in \"vox_in\" for vox_in in env_all_vox : # if the voxel was outside... if vox_in == True : # read its value of sun access and append it to the list of all voxel sun access all_vox_sun_acc . append ( vox_sun_acc [ v_id ]) # add one to the voxel id so the next time we read the next voxel v_id += 1 # if the voxel was not inside... else : # add 0.0 for its sun access all_vox_sun_acc . append ( 0.0 ) # convert to array sunacc_array = np . array ( all_vox_sun_acc ) # reshape to lattice shape sunacc_array = sunacc_array . reshape ( envelope_lattice_one . shape ) # convert to lattice sun_lattice = tg . to_lattice ( sunacc_array , envelope_lattice_one ) # invert the values of the lattice (1 = a lot of sun, 0 = no sun) sunacc_lattice = ( 1 - sun_lattice ) * envelope_lattice Visualize the sun access lattice 1 f . visualize (( 1 - sun_lattice ), \"Sun access\" , \"../data/sun_acc_lowres\" )","title":"Aggregate simulation result in the sun access lattice"},{"location":"Scripts/sun_acc/#interpolate-lowres-lattice-to-highres","text":"Import highres lattice 1 2 3 # loading highres lattice highres_lattice_path = os . path . relpath ( '../data/envelope_highres.csv' ) highres_lattice = tg . lattice_from_csv ( highres_lattice_path ) Define interpolation function 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 def interpolate ( lowres_field ): # loading highres lattice highres_lattice_path = os . path . relpath ( '../data/envelope_highres.csv' ) highres_lat = tg . lattice_from_csv ( highres_lattice_path ) highres_lattice = highres_lat * 0 + 1 # line spaces x_space = np . linspace ( lowres_field . minbound [ 0 ], lowres_field . maxbound [ 0 ], lowres_field . shape [ 0 ]) y_space = np . linspace ( lowres_field . minbound [ 1 ], lowres_field . maxbound [ 1 ], lowres_field . shape [ 1 ]) z_space = np . linspace ( lowres_field . minbound [ 2 ], lowres_field . maxbound [ 2 ], lowres_field . shape [ 2 ]) # interpolation function interpolating_function = RegularGridInterpolator (( x_space , y_space , z_space ), lowres_field , bounds_error = False , fill_value = None ) # high_res lattice full_lattice = highres_lattice + 1 # sample point sample_points = full_lattice . centroids # interpolation interpolated_values = interpolating_function ( sample_points ) # lattice construction interpolated_lattice = tg . to_lattice ( interpolated_values . reshape ( highres_lattice . shape ), highres_lattice ) # nulling the unavailable cells interpolated_lattice *= highres_lattice return interpolated_lattice Interpolate closeness lattice 1 2 3 4 highres_sunacc = interpolate ( 1 - sun_lattice ) # multipy by lattice to exclude the voxels which are outside the envelope highres_sunacc_lattice = highres_sunacc * highres_lattice Save interpolated field to csv 1 2 3 # save the sun access latice to csv csv_path = os . path . relpath ( '../data/sun_acc.csv' ) highres_sunacc_lattice . to_csv ( csv_path ) Visualize highres field 1 f . visualize ( highres_sunacc , \"Sun access\" , \"../data/sun_acc_highres.png\" )","title":"Interpolate lowres lattice to highres"},{"location":"Scripts/sun_acc/#credits","text":"1 2 3 4 5 __author__ = \"Shervin Azadi and Pirouz Nourian\" __license__ = \"MIT\" __version__ = \"1.0\" __url__ = \"https://github.com/shervinazadi/spatial_computing_workshops\" __summary__ = \"Spatial Computing Design Studio Workshop on Solar Envelope\"","title":"Credits"},{"location":"Scripts/svf/","text":"Sky view factor Import 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 import os import topogenesis as tg import pyvista as pv import trimesh as tm import numpy as np import pickle from scipy.interpolate import RegularGridInterpolator import resources.functions as f # convert mesh to pv_mesh def tri_to_pv ( tri_mesh ): faces = np . pad ( tri_mesh . faces , (( 0 , 0 ),( 1 , 0 )), 'constant' , constant_values = 3 ) pv_mesh = pv . PolyData ( tri_mesh . vertices , faces ) return pv_mesh Import meshes 1 2 3 4 5 6 7 8 9 envelope_path = os . path . relpath ( \"../data/new_envelope.obj\" ) context_path = os . path . relpath ( \"../data/immediate_context.obj\" ) # load the mesh from file envelope_mesh = tm . load ( envelope_path ) context_mesh = tm . load ( context_path ) # Check if the mesh is watertight print ( envelope_mesh . is_watertight ) Importing the envelope lattice 1 2 3 4 5 6 # loading the lattice from csv lattice_path = os . path . relpath ( \"../data/envelope_lowres.csv\" ) envelope_lattice = tg . lattice_from_csv ( lattice_path ) # creating the full lattice full_lattice = envelope_lattice * 0 + 1 Importing the skydome 1 2 3 4 # loading the skydome skydome_path = os . path . relpath ( \"../data/skydome.obj\" ) skydome_mesh = tm . load ( skydome_path ) sky_sphere = tm . primitives . Sphere ( radius = 1 , center = [ 0 , 0 , 0 ], subdivisions = 1 ) Sun vectors Computing SVF vectors with skydome 1 2 3 4 5 #adding normals of the dome to a numpy list svf_vectors = np . array ( sky_sphere . face_normals ) svf_vectors = svf_vectors [ svf_vectors [:, 2 ] > 0 ] #checking how many rays to calculate print ( len ( svf_vectors )) Visualize the skydome 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # initiating the plotter p = pv . Plotter ( notebook = True ) # fast visualization of the lattice full_lattice . fast_vis ( p ) # adding the meshes p . add_mesh ( tri_to_pv ( context_mesh ), opacity = 0.1 , style = 'wireframe' ) # add the sun locations, color orange for loc in ( svf_vectors * 250 ): p . add_mesh ( pv . Sphere ( radius = 2 , center = loc ), color = \"#ffa500\" , show_edges = False , lighting = False ) # plotting #p.show(use_ipyvtk=True) Compute intersection of sun ray with context mesh Computing SVF vectors with skydome 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 # Creating list of directions and rays for the SVF converted_svf_vectors = svf_vectors . astype ( 'float16' ) sun_dirs2 = np . array ( converted_svf_vectors ) vox_cens = full_lattice . centroids ray_dir3 = [] ray_src3 = [] for v_cen in vox_cens : for s_dir in sun_dirs2 : ray_src3 . append ( v_cen ) ray_dir3 . append ( s_dir ) # converting the list of directions and sources to numpy array ray_dir3 = np . array ( ray_dir3 ) ray_src3 = np . array ( ray_src3 ) # checking how many calculations to do for SVF print ( \"number of voxels to shoot rays from :\" , vox_cens . shape ) print ( \"number of rays per each voxel :\" , sun_dirs2 . shape ) print ( \"number of rays to be shot :\" , ray_src3 . shape ) Computing intersection 1 2 # computing the intersections of rays with the context mesh for the SVF tri_id3 , ray_id3 = context_mesh . ray . intersects_id ( ray_origins = ray_src3 , ray_directions = ray_dir3 , multiple_hits = False ) Aggregate simulation result in the sun access lattice Compute percentage of time that each voxel sees sun 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 # Same calculations, but for the SVF # initializing the hits list full of zeros hits4 = [ 0 ] * len ( ray_dir3 ) for id in ray_id3 : hits4 [ id ] = 1 sun_count = len ( sun_dirs2 ) vox_count = len ( vox_cens ) # initiating the list of ratio vox_sky_acc = [] # iterate over the voxels for v_id in range ( vox_count ): # counter for the intersection int_count = 0 # iterate over the sun rays for s_id in range ( sun_count ): # computing the ray id from voxel id and sun id r_id = s_id + v_id * sun_count # summing the intersections int_count += hits4 [ r_id ] # computing the percentage of the rays that DID NOT have # an intersection (aka could see the skydome) sky_access = 1.0 - int_count / sun_count # add the ratio to list vox_sky_acc . append ( sky_access ) # converting the list of directions and sources to numpy array vox_sky_acc = np . array ( vox_sky_acc ) Store sun acces information in a lattice 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 # Same calculation, but for SVF # getting the condition of all voxels: are they inside the envelop or not env_all_vox = full_lattice . flatten () # all voxels sky access all_vox_sky_acc = [] # v_id: voxel id in the list of only interior voxels v_id = 0 # for all the voxels, place the interiority condition of each voxel in \"vox_in\" for vox_in in env_all_vox : # if the voxel was outside... if vox_in == True : # read its value of sky acces and append it to the list of all voxel sky access all_vox_sky_acc . append ( vox_sky_acc [ v_id ]) # add one to the voxel id so the next time we read the next voxel v_id += 1 # if the voxel was not inside... else : # add 0.0 for its sun access all_vox_sky_acc . append ( 0.0 ) # convert to array sky_acc_array = np . array ( all_vox_sky_acc ) # Further info: for vectorized version of this code check: https://github.com/shervinazadi/spatial_computing_workshops/blob/master/notebooks/w2_solar_envelope.ipynb # reshape to lattice shape sky_acc_array = sky_acc_array . reshape ( full_lattice . shape ) # convert to lattice sky_acc_lattice = tg . to_lattice ( sky_acc_array , full_lattice ) Computing intersection 1 f . visualize ( sky_acc_lattice , \"Sky view\" , \"../data/sky_view_lowres.png\" ) Write sky view field to csv 1 2 3 # save the SVF latice to csv csv_path = os . path . relpath ( '../data/sky_view_lowres.csv' ) sky_acc_lattice . to_csv ( csv_path ) Interpolate lowres lattices to highres Computing intersection 1 2 3 # loading the lattice from csv lattice_path = os . path . relpath ( '../data/envelope_highres.csv' ) highres_lattice = tg . lattice_from_csv ( lattice_path ) Define interpolation function 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 def interpolate ( lowres_field ): # loading highres lattice highres_lattice_path = os . path . relpath ( '../data/envelope_highres.csv' ) highres_lat = tg . lattice_from_csv ( highres_lattice_path ) highres_lattice = highres_lat * 0 + 1 # line spaces x_space = np . linspace ( lowres_field . minbound [ 0 ], lowres_field . maxbound [ 0 ], lowres_field . shape [ 0 ]) y_space = np . linspace ( lowres_field . minbound [ 1 ], lowres_field . maxbound [ 1 ], lowres_field . shape [ 1 ]) z_space = np . linspace ( lowres_field . minbound [ 2 ], lowres_field . maxbound [ 2 ], lowres_field . shape [ 2 ]) # interpolation function interpolating_function = RegularGridInterpolator (( x_space , y_space , z_space ), lowres_field , bounds_error = False , fill_value = None ) # high_res lattice full_lattice = highres_lattice + 1 # sample point sample_points = full_lattice . centroids # interpolation interpolated_values = interpolating_function ( sample_points ) # lattice construction interpolated_lattice = tg . to_lattice ( interpolated_values . reshape ( highres_lattice . shape ), highres_lattice ) # nulling the unavailable cells interpolated_lattice *= highres_lattice return interpolated_lattice Interpolate closeness lattice 1 2 3 4 sky_acc_highres = interpolate ( sky_acc_lattice ) # multiply with the original lattice to exclude the voxels outside the envelope sky_acc_highres_lattice = sky_acc_highres * highres_lattice Save interpolated field to csv 1 2 3 # save the SVF latice to csv csv_path = os . path . relpath ( '../data/sky_view.csv' ) sky_acc_highres_lattice . to_csv ( csv_path ) Visualize highres field 1 f . visualize ( sky_acc_highres , \"Sky view\" , \"../data/sky_view_highres.png\" ) Credits 1 2 3 4 5 __author__ = \"Shervin Azadi and Pirouz Nourian\" __license__ = \"MIT\" __version__ = \"1.0\" __url__ = \"https://github.com/shervinazadi/spatial_computing_workshops\" __summary__ = \"Spatial Computing Design Studio Workshop on Solar Envelope\"","title":"SVF"},{"location":"Scripts/svf/#sky-view-factor","text":"Import 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 import os import topogenesis as tg import pyvista as pv import trimesh as tm import numpy as np import pickle from scipy.interpolate import RegularGridInterpolator import resources.functions as f # convert mesh to pv_mesh def tri_to_pv ( tri_mesh ): faces = np . pad ( tri_mesh . faces , (( 0 , 0 ),( 1 , 0 )), 'constant' , constant_values = 3 ) pv_mesh = pv . PolyData ( tri_mesh . vertices , faces ) return pv_mesh Import meshes 1 2 3 4 5 6 7 8 9 envelope_path = os . path . relpath ( \"../data/new_envelope.obj\" ) context_path = os . path . relpath ( \"../data/immediate_context.obj\" ) # load the mesh from file envelope_mesh = tm . load ( envelope_path ) context_mesh = tm . load ( context_path ) # Check if the mesh is watertight print ( envelope_mesh . is_watertight ) Importing the envelope lattice 1 2 3 4 5 6 # loading the lattice from csv lattice_path = os . path . relpath ( \"../data/envelope_lowres.csv\" ) envelope_lattice = tg . lattice_from_csv ( lattice_path ) # creating the full lattice full_lattice = envelope_lattice * 0 + 1 Importing the skydome 1 2 3 4 # loading the skydome skydome_path = os . path . relpath ( \"../data/skydome.obj\" ) skydome_mesh = tm . load ( skydome_path ) sky_sphere = tm . primitives . Sphere ( radius = 1 , center = [ 0 , 0 , 0 ], subdivisions = 1 )","title":"Sky view factor"},{"location":"Scripts/svf/#sun-vectors","text":"Computing SVF vectors with skydome 1 2 3 4 5 #adding normals of the dome to a numpy list svf_vectors = np . array ( sky_sphere . face_normals ) svf_vectors = svf_vectors [ svf_vectors [:, 2 ] > 0 ] #checking how many rays to calculate print ( len ( svf_vectors )) Visualize the skydome 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # initiating the plotter p = pv . Plotter ( notebook = True ) # fast visualization of the lattice full_lattice . fast_vis ( p ) # adding the meshes p . add_mesh ( tri_to_pv ( context_mesh ), opacity = 0.1 , style = 'wireframe' ) # add the sun locations, color orange for loc in ( svf_vectors * 250 ): p . add_mesh ( pv . Sphere ( radius = 2 , center = loc ), color = \"#ffa500\" , show_edges = False , lighting = False ) # plotting #p.show(use_ipyvtk=True)","title":"Sun vectors"},{"location":"Scripts/svf/#compute-intersection-of-sun-ray-with-context-mesh","text":"Computing SVF vectors with skydome 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 # Creating list of directions and rays for the SVF converted_svf_vectors = svf_vectors . astype ( 'float16' ) sun_dirs2 = np . array ( converted_svf_vectors ) vox_cens = full_lattice . centroids ray_dir3 = [] ray_src3 = [] for v_cen in vox_cens : for s_dir in sun_dirs2 : ray_src3 . append ( v_cen ) ray_dir3 . append ( s_dir ) # converting the list of directions and sources to numpy array ray_dir3 = np . array ( ray_dir3 ) ray_src3 = np . array ( ray_src3 ) # checking how many calculations to do for SVF print ( \"number of voxels to shoot rays from :\" , vox_cens . shape ) print ( \"number of rays per each voxel :\" , sun_dirs2 . shape ) print ( \"number of rays to be shot :\" , ray_src3 . shape ) Computing intersection 1 2 # computing the intersections of rays with the context mesh for the SVF tri_id3 , ray_id3 = context_mesh . ray . intersects_id ( ray_origins = ray_src3 , ray_directions = ray_dir3 , multiple_hits = False )","title":"Compute intersection of sun ray with context mesh"},{"location":"Scripts/svf/#aggregate-simulation-result-in-the-sun-access-lattice","text":"Compute percentage of time that each voxel sees sun 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 # Same calculations, but for the SVF # initializing the hits list full of zeros hits4 = [ 0 ] * len ( ray_dir3 ) for id in ray_id3 : hits4 [ id ] = 1 sun_count = len ( sun_dirs2 ) vox_count = len ( vox_cens ) # initiating the list of ratio vox_sky_acc = [] # iterate over the voxels for v_id in range ( vox_count ): # counter for the intersection int_count = 0 # iterate over the sun rays for s_id in range ( sun_count ): # computing the ray id from voxel id and sun id r_id = s_id + v_id * sun_count # summing the intersections int_count += hits4 [ r_id ] # computing the percentage of the rays that DID NOT have # an intersection (aka could see the skydome) sky_access = 1.0 - int_count / sun_count # add the ratio to list vox_sky_acc . append ( sky_access ) # converting the list of directions and sources to numpy array vox_sky_acc = np . array ( vox_sky_acc ) Store sun acces information in a lattice 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 # Same calculation, but for SVF # getting the condition of all voxels: are they inside the envelop or not env_all_vox = full_lattice . flatten () # all voxels sky access all_vox_sky_acc = [] # v_id: voxel id in the list of only interior voxels v_id = 0 # for all the voxels, place the interiority condition of each voxel in \"vox_in\" for vox_in in env_all_vox : # if the voxel was outside... if vox_in == True : # read its value of sky acces and append it to the list of all voxel sky access all_vox_sky_acc . append ( vox_sky_acc [ v_id ]) # add one to the voxel id so the next time we read the next voxel v_id += 1 # if the voxel was not inside... else : # add 0.0 for its sun access all_vox_sky_acc . append ( 0.0 ) # convert to array sky_acc_array = np . array ( all_vox_sky_acc ) # Further info: for vectorized version of this code check: https://github.com/shervinazadi/spatial_computing_workshops/blob/master/notebooks/w2_solar_envelope.ipynb # reshape to lattice shape sky_acc_array = sky_acc_array . reshape ( full_lattice . shape ) # convert to lattice sky_acc_lattice = tg . to_lattice ( sky_acc_array , full_lattice ) Computing intersection 1 f . visualize ( sky_acc_lattice , \"Sky view\" , \"../data/sky_view_lowres.png\" ) Write sky view field to csv 1 2 3 # save the SVF latice to csv csv_path = os . path . relpath ( '../data/sky_view_lowres.csv' ) sky_acc_lattice . to_csv ( csv_path )","title":"Aggregate simulation result in the sun access lattice"},{"location":"Scripts/svf/#interpolate-lowres-lattices-to-highres","text":"Computing intersection 1 2 3 # loading the lattice from csv lattice_path = os . path . relpath ( '../data/envelope_highres.csv' ) highres_lattice = tg . lattice_from_csv ( lattice_path ) Define interpolation function 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 def interpolate ( lowres_field ): # loading highres lattice highres_lattice_path = os . path . relpath ( '../data/envelope_highres.csv' ) highres_lat = tg . lattice_from_csv ( highres_lattice_path ) highres_lattice = highres_lat * 0 + 1 # line spaces x_space = np . linspace ( lowres_field . minbound [ 0 ], lowres_field . maxbound [ 0 ], lowres_field . shape [ 0 ]) y_space = np . linspace ( lowres_field . minbound [ 1 ], lowres_field . maxbound [ 1 ], lowres_field . shape [ 1 ]) z_space = np . linspace ( lowres_field . minbound [ 2 ], lowres_field . maxbound [ 2 ], lowres_field . shape [ 2 ]) # interpolation function interpolating_function = RegularGridInterpolator (( x_space , y_space , z_space ), lowres_field , bounds_error = False , fill_value = None ) # high_res lattice full_lattice = highres_lattice + 1 # sample point sample_points = full_lattice . centroids # interpolation interpolated_values = interpolating_function ( sample_points ) # lattice construction interpolated_lattice = tg . to_lattice ( interpolated_values . reshape ( highres_lattice . shape ), highres_lattice ) # nulling the unavailable cells interpolated_lattice *= highres_lattice return interpolated_lattice Interpolate closeness lattice 1 2 3 4 sky_acc_highres = interpolate ( sky_acc_lattice ) # multiply with the original lattice to exclude the voxels outside the envelope sky_acc_highres_lattice = sky_acc_highres * highres_lattice Save interpolated field to csv 1 2 3 # save the SVF latice to csv csv_path = os . path . relpath ( '../data/sky_view.csv' ) sky_acc_highres_lattice . to_csv ( csv_path ) Visualize highres field 1 f . visualize ( sky_acc_highres , \"Sky view\" , \"../data/sky_view_highres.png\" )","title":"Interpolate lowres lattices to highres"},{"location":"Scripts/svf/#credits","text":"1 2 3 4 5 __author__ = \"Shervin Azadi and Pirouz Nourian\" __license__ = \"MIT\" __version__ = \"1.0\" __url__ = \"https://github.com/shervinazadi/spatial_computing_workshops\" __summary__ = \"Spatial Computing Design Studio Workshop on Solar Envelope\"","title":"Credits"},{"location":"Scripts/voxelization/","text":"Voxelization Initialization Visualize highres field 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 #!conda env update -f ../environment.yml import os import topogenesis as tg import trimesh as tm import numpy as np import pyvista as pv # convert trimesh to pv_mesh def tri_to_pv ( tri_mesh ): faces = np . pad ( tri_mesh . faces , (( 0 , 0 ),( 1 , 0 )), 'constant' , constant_values = 3 ) pv_mesh = pv . PolyData ( tri_mesh . vertices , faces ) return pv_mesh # set the size of the voxels vs = 3.6 unit = [ vs , vs , vs ] mesh_path = os . path . relpath ( '../data/new_envelope.obj' ) Input mesh 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 # load the mesh from file mesh = tm . load ( mesh_path ) # Check if the mesh is watertight print ( mesh . is_watertight ) # loading the context mesh context_path = os . path . relpath ( '../data/immediate_context.obj' ) context_mesh = tm . load ( context_path ) # initiating the plotter p = pv . Plotter () pv . set_plot_theme ( \"document\" ) # adding the base mesh: light blue p . add_mesh ( tri_to_pv ( mesh ), color = '#abd8ff' ) # adding the meshes p . add_mesh ( tri_to_pv ( context_mesh ), opacity = 0.1 , style = 'wireframe' ) # plotting #p.show(screenshot=\"plot.png\") Voxelize the mesh 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 # initialize the base lattice base_lattice = tg . lattice ( mesh . bounds , unit = unit , default_value = 1 , dtype = int ) # check which voxel centroids is inside the mesh interior_condition = mesh . contains ( base_lattice . centroids ) # reshape the interior condition to the shape of the base_lattice interior_array = interior_condition . reshape ( base_lattice . shape ) # convert the interior array into a lattice interior_lattice = tg . to_lattice ( interior_array , base_lattice . minbound , base_lattice . unit ) interior_lattice . shape # initiating the plotter p = pv . Plotter () pv . set_plot_theme ( \"document\" ) # fast visualization of the lattice interior_lattice . fast_vis ( p ) # adding the base mesh: light blue p . add_mesh ( tri_to_pv ( mesh ), color = '#abd8ff' , opacity = 0.1 ) # adding the meshes p . add_mesh ( tri_to_pv ( context_mesh ), opacity = 0.1 , style = 'wireframe' ) # plotting # p.show(screenshot=\"highres_lattice.png\") Saving the lattice to csv 1 2 csv_path = os . path . relpath ( '../data/envelope_highres.csv' ) interior_lattice . to_csv ( csv_path ) Credits 1 2 3 4 5 __author__ = \"Shervin Azadi\" __license__ = \"MIT\" __version__ = \"1.0\" __url__ = \"https://github.com/shervinazadi/spatial_computing_workshops\" __summary__ = \"Spatial Computing Design Studio Workshop on Voxelization\"","title":"Voxelization"},{"location":"Scripts/voxelization/#voxelization","text":"","title":"Voxelization"},{"location":"Scripts/voxelization/#initialization","text":"Visualize highres field 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 #!conda env update -f ../environment.yml import os import topogenesis as tg import trimesh as tm import numpy as np import pyvista as pv # convert trimesh to pv_mesh def tri_to_pv ( tri_mesh ): faces = np . pad ( tri_mesh . faces , (( 0 , 0 ),( 1 , 0 )), 'constant' , constant_values = 3 ) pv_mesh = pv . PolyData ( tri_mesh . vertices , faces ) return pv_mesh # set the size of the voxels vs = 3.6 unit = [ vs , vs , vs ] mesh_path = os . path . relpath ( '../data/new_envelope.obj' )","title":"Initialization"},{"location":"Scripts/voxelization/#input-mesh","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 # load the mesh from file mesh = tm . load ( mesh_path ) # Check if the mesh is watertight print ( mesh . is_watertight ) # loading the context mesh context_path = os . path . relpath ( '../data/immediate_context.obj' ) context_mesh = tm . load ( context_path ) # initiating the plotter p = pv . Plotter () pv . set_plot_theme ( \"document\" ) # adding the base mesh: light blue p . add_mesh ( tri_to_pv ( mesh ), color = '#abd8ff' ) # adding the meshes p . add_mesh ( tri_to_pv ( context_mesh ), opacity = 0.1 , style = 'wireframe' ) # plotting #p.show(screenshot=\"plot.png\")","title":"Input mesh"},{"location":"Scripts/voxelization/#voxelize-the-mesh","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 # initialize the base lattice base_lattice = tg . lattice ( mesh . bounds , unit = unit , default_value = 1 , dtype = int ) # check which voxel centroids is inside the mesh interior_condition = mesh . contains ( base_lattice . centroids ) # reshape the interior condition to the shape of the base_lattice interior_array = interior_condition . reshape ( base_lattice . shape ) # convert the interior array into a lattice interior_lattice = tg . to_lattice ( interior_array , base_lattice . minbound , base_lattice . unit ) interior_lattice . shape # initiating the plotter p = pv . Plotter () pv . set_plot_theme ( \"document\" ) # fast visualization of the lattice interior_lattice . fast_vis ( p ) # adding the base mesh: light blue p . add_mesh ( tri_to_pv ( mesh ), color = '#abd8ff' , opacity = 0.1 ) # adding the meshes p . add_mesh ( tri_to_pv ( context_mesh ), opacity = 0.1 , style = 'wireframe' ) # plotting # p.show(screenshot=\"highres_lattice.png\")","title":"Voxelize the mesh"},{"location":"Scripts/voxelization/#saving-the-lattice-to-csv","text":"1 2 csv_path = os . path . relpath ( '../data/envelope_highres.csv' ) interior_lattice . to_csv ( csv_path )","title":"Saving the lattice to csv"},{"location":"Scripts/voxelization/#credits","text":"1 2 3 4 5 __author__ = \"Shervin Azadi\" __license__ = \"MIT\" __version__ = \"1.0\" __url__ = \"https://github.com/shervinazadi/spatial_computing_workshops\" __summary__ = \"Spatial Computing Design Studio Workshop on Voxelization\"","title":"Credits"},{"location":"documenting/folder_structure/","text":"Folder Structure The folders in student projects should strictly follow the structure of the folders in this repository. The main folders are four assignment folder (corresponding to each assignment) and one folder for final deliverables of your project. In general, the process sub-folders include all the necessary code, notebook, files, and models that you have used to achieve the final product of that assignment. It also includes document that represent the process of the assignment such as flowcharts, diagrams and pseudo-codes. The product sub-folder sh Here is run down of the overall structure: A1_Planning Process Product A2_Configuring Process Product A3_Massing Process Product A4_Forming Process Product Final_Deliverables Here you will include all the final deliverables of your project. docs Here you will write and edit the source of your documentation in MarkDown . An example is included in the template to help you begin documenting your project. site you should leave this directory empty. It will be filled by automatic documentation generator MkDocs","title":"Folder Structure"},{"location":"documenting/folder_structure/#folder-structure","text":"The folders in student projects should strictly follow the structure of the folders in this repository. The main folders are four assignment folder (corresponding to each assignment) and one folder for final deliverables of your project. In general, the process sub-folders include all the necessary code, notebook, files, and models that you have used to achieve the final product of that assignment. It also includes document that represent the process of the assignment such as flowcharts, diagrams and pseudo-codes. The product sub-folder sh Here is run down of the overall structure: A1_Planning Process Product A2_Configuring Process Product A3_Massing Process Product A4_Forming Process Product Final_Deliverables Here you will include all the final deliverables of your project. docs Here you will write and edit the source of your documentation in MarkDown . An example is included in the template to help you begin documenting your project. site you should leave this directory empty. It will be filled by automatic documentation generator MkDocs","title":"Folder Structure"},{"location":"documenting/guidelines/","text":"Guidelines File Size : No file bigger than 50mb is recommended. No file bigger than 100mb is allowed. Folder Structure : Do not change the folder structure. You can sub-folders to the existing folders if you want but you shall not change the existing overall structure Duplicates : Do NOT include duplicates in your files. Naming Convention : Avoid using special characters or spaces in file and folder names. Instead, use \"_\" to separate words in the names. Geometric Models (.3dm, .obj, etc) should be compressed before being added to repository. Video and Animation files should not be included the repository. They should be uploaded to online video services (YouTube, Vimeo, etc). You should embed those video link in your documentation. (GIF files are allowed in your repo)","title":"Guidelines"},{"location":"documenting/guidelines/#guidelines","text":"File Size : No file bigger than 50mb is recommended. No file bigger than 100mb is allowed. Folder Structure : Do not change the folder structure. You can sub-folders to the existing folders if you want but you shall not change the existing overall structure Duplicates : Do NOT include duplicates in your files. Naming Convention : Avoid using special characters or spaces in file and folder names. Instead, use \"_\" to separate words in the names. Geometric Models (.3dm, .obj, etc) should be compressed before being added to repository. Video and Animation files should not be included the repository. They should be uploaded to online video services (YouTube, Vimeo, etc). You should embed those video link in your documentation. (GIF files are allowed in your repo)","title":"Guidelines"},{"location":"documenting/instructions/","text":"Documenting Instructions Installation Install Conda You can install Anaconda or Miniconda to install conda package manager (if you don't know the difference you should install anaconda). Create documentation environment Now we need to create the appropriate environment for documenting by installing all the necessary tools. To do so we have provided you an environment droplet, which is a recipe for a series of installations that create the aforementioned environment. For that, after directing to the root folder of this project where the environment droplet ( environment.yml ) is located, you need to run the following command: conda env create -f environment.yml Start Work on Documentation After finishing your work on documentation you need to shutdown the server and deactivate the environment. Activate the Environment Now that you have created the appropriate environment, you need to activate the environment to be able to work inside it. For that, as you are in the root folder of this project, you need to run the following command: conda activate spatial_computing_docs If the command line is now indicating the name of the environment in parenthesis, it means that the environment is activated. Similar to this ( spatial_computing_docs ) { your username } @ { your computer name } spatial_computing_project_template % Run the Local Server Now that the environment is activated, we need to run the local server to be able to see the result of changes in the local version of the documentation website. For that, run the following command: mkdocs serve After running this command, if the server has started to work successfully, you should see the following line in the command line: INFO - Serving on http://127.0.0.1:8000 This means that the server is accessible at http://127.0.0.1:8000 . If you open your browser and go this link you should see a local version of the site. Writing Your Documentation In the documenting process you need to head to the docs folder and edit the .md (markdown) files, since the website is build from these files. In the root of this project, you can edit the configurations of your project in mkdocs.yml file: Adding o removing pages Add markdown extensions . Some of the useful extensions: arithmatex for writing mathematics highlight for code highlighting Customizing the looks of your documentation Adding MkDocs Plugins , such as: mknotebooks for including python notebooks in the documentations Finish Work on Documentation Server Shut Down To shutdown the server, you need to press Ctrl + C in the command line. The following should appear in the command line: INFO - Shutting down... Deactivate Environment After shutting down your server the command line is back to the normal state and you can run commands again. To deactivate your environment you need to run the following command: conda deactivate Deployment of the Documentation Site Build and Deploy to deploy your documentation website, you need to run the following command in the root of this repository: mkdocs gh-deploy This command will create a new branch in your repository called gh-pages and build your site in it. It will then push the new branch to your remote repository automatically. It will also create a site folder in your root directory containing all of your site files. Since this folder is added .gitignore file, it won't be committed or pushed to the remote repository. Setup GitHub Pages For the first time, you need to configure the GitHub Pages service on your GitHub repository so it wil automatically build your documentation website whenever you deploy your site. To do this: Go to your repository setting, got GitHub Pages section, select gh-pages branch, select /(root) location, click on the save button. The setting page will refresh, and now if you go to the address that is provided at the GitHub Pages section, Wola, here is your documentation!","title":"Instructions"},{"location":"documenting/instructions/#documenting-instructions","text":"","title":"Documenting Instructions"},{"location":"documenting/instructions/#installation","text":"","title":"Installation"},{"location":"documenting/instructions/#install-conda","text":"You can install Anaconda or Miniconda to install conda package manager (if you don't know the difference you should install anaconda).","title":"Install Conda"},{"location":"documenting/instructions/#create-documentation-environment","text":"Now we need to create the appropriate environment for documenting by installing all the necessary tools. To do so we have provided you an environment droplet, which is a recipe for a series of installations that create the aforementioned environment. For that, after directing to the root folder of this project where the environment droplet ( environment.yml ) is located, you need to run the following command: conda env create -f environment.yml","title":"Create documentation environment"},{"location":"documenting/instructions/#start-work-on-documentation","text":"After finishing your work on documentation you need to shutdown the server and deactivate the environment.","title":"Start Work on Documentation"},{"location":"documenting/instructions/#activate-the-environment","text":"Now that you have created the appropriate environment, you need to activate the environment to be able to work inside it. For that, as you are in the root folder of this project, you need to run the following command: conda activate spatial_computing_docs If the command line is now indicating the name of the environment in parenthesis, it means that the environment is activated. Similar to this ( spatial_computing_docs ) { your username } @ { your computer name } spatial_computing_project_template %","title":"Activate the Environment"},{"location":"documenting/instructions/#run-the-local-server","text":"Now that the environment is activated, we need to run the local server to be able to see the result of changes in the local version of the documentation website. For that, run the following command: mkdocs serve After running this command, if the server has started to work successfully, you should see the following line in the command line: INFO - Serving on http://127.0.0.1:8000 This means that the server is accessible at http://127.0.0.1:8000 . If you open your browser and go this link you should see a local version of the site.","title":"Run the Local Server"},{"location":"documenting/instructions/#writing-your-documentation","text":"In the documenting process you need to head to the docs folder and edit the .md (markdown) files, since the website is build from these files. In the root of this project, you can edit the configurations of your project in mkdocs.yml file: Adding o removing pages Add markdown extensions . Some of the useful extensions: arithmatex for writing mathematics highlight for code highlighting Customizing the looks of your documentation Adding MkDocs Plugins , such as: mknotebooks for including python notebooks in the documentations","title":"Writing Your Documentation"},{"location":"documenting/instructions/#finish-work-on-documentation","text":"","title":"Finish Work on Documentation"},{"location":"documenting/instructions/#server-shut-down","text":"To shutdown the server, you need to press Ctrl + C in the command line. The following should appear in the command line: INFO - Shutting down...","title":"Server Shut Down"},{"location":"documenting/instructions/#deactivate-environment","text":"After shutting down your server the command line is back to the normal state and you can run commands again. To deactivate your environment you need to run the following command: conda deactivate","title":"Deactivate Environment"},{"location":"documenting/instructions/#deployment-of-the-documentation-site","text":"","title":"Deployment of the Documentation Site"},{"location":"documenting/instructions/#build-and-deploy","text":"to deploy your documentation website, you need to run the following command in the root of this repository: mkdocs gh-deploy This command will create a new branch in your repository called gh-pages and build your site in it. It will then push the new branch to your remote repository automatically. It will also create a site folder in your root directory containing all of your site files. Since this folder is added .gitignore file, it won't be committed or pushed to the remote repository.","title":"Build and Deploy"},{"location":"documenting/instructions/#setup-github-pages","text":"For the first time, you need to configure the GitHub Pages service on your GitHub repository so it wil automatically build your documentation website whenever you deploy your site. To do this: Go to your repository setting, got GitHub Pages section, select gh-pages branch, select /(root) location, click on the save button. The setting page will refresh, and now if you go to the address that is provided at the GitHub Pages section, Wola, here is your documentation!","title":"Setup GitHub Pages"}]}